{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goal_rec_utils.plan import Plan\n",
    "from goal_rec_utils.plan_generator import PlanGeneratorMultiPerc\n",
    "from utils_unibs.files import load_from_folder\n",
    "import numpy as np\n",
    "import goal_rec_utils\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from incremental_model_training import SaveBestModelCallback, run_tests, Custom_Hamming_Loss1\n",
    "from tensorflow.keras.models import load_model\n",
    "import incremental_model_training\n",
    "import numpy as np\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanGeneratorMultiPerc(Sequence):\n",
    "    def __getitem__(self, index):\n",
    "        batches = self.plans[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X = np.zeros((int(self.batch_size), int(self.max_dim)))\n",
    "        Y = np.zeros((int(self.batch_size), len(self.dizionario_goal)))\n",
    "        for i, plan in enumerate(batches):\n",
    "            seed = plan.plan_name.rsplit('-p',1)[1]\n",
    "            seed = seed.split('_', 1)[0]\n",
    "            seed = seed.rsplit('.', 1)[0]\n",
    "            np.random.seed(int(seed))\n",
    "            p = np.random.uniform(self.min_perc, self.perc)\n",
    "            actions = get_actions(plan.actions, p, self.dizionario)\n",
    "            fill_action_sequence(X, self.max_dim, actions, i)\n",
    "            Y[i] = get_goal(plan.goals, self.dizionario_goal)\n",
    "        return X, Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.plans) // self.batch_size\n",
    "\n",
    "    def __init__(self, plans, dizionario, dizionario_goal, dizionario_new_goal, batch_size, max_dim, min_perc, max_perc, shuffle=True):\n",
    "        self.plans = plans\n",
    "        self.dizionario_goal = dizionario_goal\n",
    "        self.fizionario_new_goal = dizionario_new_goal\n",
    "        self.dizionario = dizionario\n",
    "        self.batch_size = batch_size\n",
    "        self.max_dim = max_dim\n",
    "        self.min_perc = min_perc\n",
    "        self.perc = max_perc\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        '''Updates indexes after each epoch'''\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.plans)\n",
    "\n",
    "def get_actions(actions: list, perc: float, dizionario: dict):\n",
    "    '''\n",
    "    Get a sub-sequence made by a given percentage of elements in action.\n",
    "    Args:\n",
    "        actions: a list that contains the actions as strings\n",
    "        perc: a float that represents the percentage of actions to keep. It must be from 0 to 1 included.\n",
    "        dizionario: a dictionary that contains all the action labels and their corresponding unique indexes\n",
    "    Returns:\n",
    "        A list that contains the indexes of the actions in the sub-sequence\n",
    "    '''\n",
    "    if actions is None or len(actions) == 0:\n",
    "        return []\n",
    "    if perc > 1:\n",
    "        perc = 1\n",
    "    elif perc < 0:\n",
    "        perc = 0\n",
    "    size = int(np.ceil(len(actions) * perc))\n",
    "    if size == 0:\n",
    "        size = 1\n",
    "    indexes = np.ones(size, dtype=int) * -1\n",
    "    i = 0\n",
    "    ind_list = list(range(len(actions)))\n",
    "    np.random.shuffle(ind_list)\n",
    "    while i < size:\n",
    "        ind = ind_list.pop(0)\n",
    "        if ind not in indexes:\n",
    "            indexes[i] = ind\n",
    "            i += 1\n",
    "    indexes = np.sort(indexes)\n",
    "    return [dizionario[a.name] for a in np.take(actions, indexes)]\n",
    "\n",
    "\n",
    "def fill_action_sequence(X, max_dim, actions, i):\n",
    "    for j in range(max_dim):\n",
    "        if j < len(actions):\n",
    "            X[i][j] = actions[j]\n",
    "        else:\n",
    "            if type(actions[0]) == int:\n",
    "                X[i][j] = 0\n",
    "            else:\n",
    "                X[i][j] = np.zeros(shape=(len(actions[0]),))\n",
    "\n",
    "def get_goal(g, dizionario_goal):\n",
    "    goal = np.zeros(len(dizionario_goal))\n",
    "    for subgoal in g:\n",
    "        if subgoal in dizionario_goal:\n",
    "            goal = goal + dizionario_goal[subgoal]\n",
    "    return goal\n",
    "\n",
    "def get_seed(string: str):\n",
    "    '''\n",
    "    Turns a string into an int that can be used as a seed\n",
    "    Args:\n",
    "        string: the string to transform in seed\n",
    "    Returns:\n",
    "        an integer containing the seed\n",
    "    '''\n",
    "    seed = 0\n",
    "    for c in string:\n",
    "        seed += ord(c)\n",
    "    return seed\n",
    "\n",
    "\n",
    "incremental_model_training.PlanGeneratorMultiPerc = PlanGeneratorMultiPerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_plans loaded from /data/users/mchiari/WMCA/datasets/satellite/optimal_plans/plans_max-plan-dim=30_train_percentage=0.8\n",
      "dizionario_goal loaded from /data/users/mchiari/WMCA/datasets/satellite/optimal_plans/dictionaries_and_plans\n",
      "dizionario loaded from /data/users/mchiari/WMCA/datasets/satellite/optimal_plans/dictionaries_and_plans\n"
     ]
    }
   ],
   "source": [
    "[plans] = load_from_folder('/data/users/mchiari/WMCA/datasets/satellite/optimal_plans/plans_max-plan-dim=30_train_percentage=0.8', ['train_plans'])\n",
    "[goals_dict, actions_dict] = load_from_folder('/data/users/mchiari/WMCA/datasets/satellite/optimal_plans/dictionaries_and_plans', ['dizionario_goal', 'dizionario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(generator: PlanGeneratorMultiPerc, lr: float):\n",
    "    \n",
    "    \n",
    "\n",
    "    input_layer = Input(shape=(generator.max_dim,))\n",
    "    embedding_layer = Embedding(input_dim=len(generator.dizionario)+1,\n",
    "                                input_length=generator.max_dim, \n",
    "                                output_dim=82,\n",
    "                                mask_zero=True,\n",
    "                                name='embedding')(input_layer)\n",
    "    lstm_layer = LSTM(363, return_sequences=True, dropout=0, recurrent_dropout=0.21543712857716188, activation='linear', name='lstm')(embedding_layer)\n",
    "    attention_weights = AttentionWeights(generator.max_dim, name='attention_weights')(lstm_layer)\n",
    "    context_vector = ContextVector()([lstm_layer, attention_weights])\n",
    "    output_layer = Dense(len(generator.dizionario_goal), activation='sigmoid', name='dense')(context_vector)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', Custom_Hamming_Loss1, metrics.Precision(name='precision')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_goals_dict(goals: list, goals_dict: dict = {}):\n",
    "    new_goals_dict = goals_dict.copy()\n",
    "    new_goals = set(goals).difference(set(goals_dict.keys()))\n",
    "    for k in new_goals_dict:\n",
    "        new_goals_dict[k] = np.append(new_goals_dict[k], np.zeros([len(new_goals),])) \n",
    "    for g in new_goals:\n",
    "        l = np.zeros([len(goals_dict)+len(new_goals),])\n",
    "        l[len(new_goals_dict)] = 1\n",
    "        new_goals_dict[g] = l\n",
    "    print(f'{len(new_goals_dict) = }')\n",
    "    return new_goals_dict\n",
    "\n",
    "def create_actions_dict(subplans: list, actions_dict: dict = {}):\n",
    "    for p in subplans:\n",
    "        for a in p.actions:\n",
    "            if a.name not in actions_dict:\n",
    "                actions_dict[a.name] = len(actions_dict)+1\n",
    "    print(f'{len(actions_dict) = }')\n",
    "    return actions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subplans(all_plans: list, sub_goals_dict: dict, old_sub_goals_dict: dict):\n",
    "    subplans = set()\n",
    "    count = 0\n",
    "    print(f'{sub_goals_dict.keys() = }, {old_sub_goals_dict.keys() = }')\n",
    "    new_sub_goals = set(sub_goals_dict.keys()).difference(set(old_sub_goals_dict.keys()))\n",
    "    for goal_fact in new_sub_goals:\n",
    "        for p in all_plans:\n",
    "            if goal_fact in p.goals:\n",
    "                subplans.add(p)\n",
    "                count += 1\n",
    "    print(f'{len(subplans) = }, {count = }')  \n",
    "    return subplans\n",
    "\n",
    "def extend_subplans(subplans: set, old_subplans: set, old_goals: list):\n",
    "    to_add = set()\n",
    "    for g in old_goals:\n",
    "        count = 0\n",
    "        for p in list(old_subplans):\n",
    "            if count == 100:\n",
    "                break\n",
    "            if g in p.goals and p not in subplans and p not in to_add:\n",
    "                to_add.add(p)\n",
    "                count += 1\n",
    "            elif g in p.goals and p not in subplans:\n",
    "                count += 1\n",
    "        print(f'{g} : {len(to_add) = }, {count = }')\n",
    "    return to_add      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_val_plans(subplans: list, perc: float = 0.85):\n",
    "    np.random.seed(420)\n",
    "    np.random.shuffle(subplans)\n",
    "    train_plans = subplans[:int(len(subplans)*perc)]\n",
    "    val_plans = subplans[int(len(subplans)*perc):]\n",
    "    print(f'{len(train_plans) = }, {len(val_plans) = }')\n",
    "    return train_plans, val_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "target_dir = path.join('/data/users/mchiari/WMCA/satellite/transfer_learning/', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "temp_dir = path.join(target_dir, f'temp_dir')\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "models_dir = path.join(target_dir, f'models')\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sub_goals: list, old_sub_plans: set, old_sub_goals_dict: dict, old_sub_actions_dict: dict):\n",
    "    sub_goals_dict = create_goals_dict(sub_goals, old_sub_goals_dict)\n",
    "    sub_plans = create_subplans(plans, sub_goals_dict, old_sub_goals_dict)\n",
    "    to_add = extend_subplans(sub_plans, old_sub_plans, list(old_sub_goals_dict.keys()))\n",
    "    sub_plans = sub_plans.union(to_add)\n",
    "    sub_actions_dict = create_actions_dict(sub_plans, old_sub_actions_dict)\n",
    "    train_plans, val_plans = create_test_val_plans(list(sub_plans), 0.85)\n",
    "    train_generator = PlanGeneratorMultiPerc(train_plans, sub_actions_dict, sub_goals_dict, 64, 30, 0.3, 1)\n",
    "    val_generator = PlanGeneratorMultiPerc(val_plans, sub_actions_dict, sub_goals_dict, 64, 30, 0.3, 1)\n",
    "    return train_generator, val_generator, sub_goals_dict, sub_actions_dict, train_plans, val_plans\n",
    "\n",
    "def test_model(model, sub_goals_dict, sub_actions_dict, val_plans, iteration: int):\n",
    "    run_tests(model, val_plans, sub_actions_dict, sub_goals_dict, 64, 30, 0.3, 1, None)\n",
    "    model.save(path.join(models_dir, f'model_{iteration}.h5'))\n",
    "\n",
    "def run(iteration: int, sub_goals: list, old_sub_plans: set, old_sub_goals_dict: dict, old_sub_actions_dict: dict):\n",
    "    print(f'{old_sub_goals_dict.keys() = }')\n",
    "    train_generator, val_generator, sub_goals_dict, sub_actions_dict, train_plans, val_plans = preprocess(sub_goals, old_sub_plans, old_sub_goals_dict, old_sub_actions_dict)\n",
    "    model = create_model(train_generator, 0.001)\n",
    "    model.fit(train_generator, epochs=100, validation_data=val_generator, callbacks=[SaveBestModelCallback(temp_dir, 5, 0)])\n",
    "    model = load_model(path.join(temp_dir, 'model.h5'), custom_objects = {'AttentionWeights' : goal_rec_utils.attention_layers.AttentionWeights, 'ContextVector' : goal_rec_utils.attention_layers.ContextVector, 'Custom_Hamming_Loss1' : Custom_Hamming_Loss1})\n",
    "    test_model(model, sub_goals_dict, sub_actions_dict, val_plans, iteration)\n",
    "    return train_plans, val_plans, sub_goals_dict, sub_actions_dict\n",
    "\n",
    "def transfer_model(model: Model, old_model: Model):\n",
    "    old_w = old_model.get_layer('embedding').get_weights()[0]\n",
    "    w = model.get_layer('embedding').get_weights()[0]\n",
    "    for i in range(len(old_w)):\n",
    "        w[i] = old_w[i]\n",
    "    model.get_layer('embedding').set_weights([w])\n",
    "    model.get_layer('lstm').set_weights(old_model.get_layer('lstm').get_weights())\n",
    "    model.get_layer('attention_weights').set_weights(old_model.get_layer('attention_weights').get_weights())\n",
    "    w = model.get_layer('dense').get_weights()\n",
    "    old_w = old_model.get_layer('dense').get_weights()\n",
    "    for i in range(len(w[0])):\n",
    "        w[0][i, :-5] = old_w[0][i]\n",
    "    w[1][:-5] = old_w[1]\n",
    "    model.get_layer('dense').set_weights(w)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_sub_goals_dict.keys() = dict_keys([])\n",
      "len(new_goals_dict) = 5\n",
      "sub_goals_dict.keys() = dict_keys(['have_image planet3 infrared0', 'have_image planet5 infrared3', 'have_image phenomenon14 infrared0', 'have_image phenomenon4 infrared0', 'have_image star5 infrared3']), old_sub_goals_dict.keys() = dict_keys([])\n",
      "len(subplans) = 2576, count = 2660\n",
      "len(actions_dict) = 15973\n",
      "len(train_plans) = 2189, len(val_plans) = 387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 13:33:07.396940: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 13:33:07.875510: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-05-09 13:33:07.876606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294605000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 9s 177ms/step - loss: 0.6375 - accuracy: 0.2134 - Custom_Hamming_Loss1: 0.2443 - precision: 0.2164 - val_loss: 0.5321 - val_accuracy: 0.2005 - val_Custom_Hamming_Loss1: 0.2068 - val_precision: 0.0000e+00\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.5215 - accuracy: 0.2348 - Custom_Hamming_Loss1: 0.2073 - precision: 0.0000e+00 - val_loss: 0.5136 - val_accuracy: 0.2031 - val_Custom_Hamming_Loss1: 0.2068 - val_precision: 0.0000e+00\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.5021 - accuracy: 0.3485 - Custom_Hamming_Loss1: 0.2064 - precision: 0.3657 - val_loss: 0.4991 - val_accuracy: 0.3724 - val_Custom_Hamming_Loss1: 0.2068 - val_precision: 0.0000e+00\n",
      "New best model found with loss 0.4991004467010498\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.3970 - accuracy: 0.8050 - Custom_Hamming_Loss1: 0.1775 - precision: 0.7288 - val_loss: 0.5127 - val_accuracy: 0.4531 - val_Custom_Hamming_Loss1: 0.1875 - val_precision: 0.6242\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.1994 - accuracy: 0.9448 - Custom_Hamming_Loss1: 0.0476 - precision: 0.9610 - val_loss: 0.4289 - val_accuracy: 0.5599 - val_Custom_Hamming_Loss1: 0.1687 - val_precision: 0.6388\n",
      "New best model found with loss 0.4288958013057709\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.1020 - accuracy: 0.9780 - Custom_Hamming_Loss1: 0.0138 - precision: 0.9886 - val_loss: 0.3801 - val_accuracy: 0.5911 - val_Custom_Hamming_Loss1: 0.1557 - val_precision: 0.6899\n",
      "New best model found with loss 0.3800559341907501\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0397 - accuracy: 0.9730 - Custom_Hamming_Loss1: 0.0050 - precision: 0.9970 - val_loss: 0.3987 - val_accuracy: 0.5938 - val_Custom_Hamming_Loss1: 0.1583 - val_precision: 0.6598\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0174 - accuracy: 0.9886 - Custom_Hamming_Loss1: 0.0017 - precision: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.5677 - val_Custom_Hamming_Loss1: 0.1698 - val_precision: 0.6073\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0100 - accuracy: 0.9814 - Custom_Hamming_Loss1: 0.0012 - precision: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.5755 - val_Custom_Hamming_Loss1: 0.1714 - val_precision: 0.5977\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0069 - accuracy: 0.9854 - Custom_Hamming_Loss1: 0.0011 - precision: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.5729 - val_Custom_Hamming_Loss1: 0.1750 - val_precision: 0.5840\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0045 - accuracy: 0.9780 - Custom_Hamming_Loss1: 6.5196e-04 - precision: 0.9993 - val_loss: 0.8433 - val_accuracy: 0.5495 - val_Custom_Hamming_Loss1: 0.1802 - val_precision: 0.5710\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0281 - accuracy: 0.9891 - Custom_Hamming_Loss1: 0.0020 - precision: 0.9961 - val_loss: 0.4173 - val_accuracy: 0.5729 - val_Custom_Hamming_Loss1: 0.1729 - val_precision: 0.5942\n",
      "Accuracy: 0.4270833333333333\n",
      "\n",
      "Hamming Loss: 0.15625\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "     have_image planet3 infrared0       0.61      0.51      0.55        79\n",
      "     have_image planet5 infrared3       0.92      0.31      0.46        71\n",
      "have_image phenomenon14 infrared0       0.76      0.47      0.58        83\n",
      " have_image phenomenon4 infrared0       0.69      0.44      0.54        77\n",
      "       have_image star5 infrared3       0.63      0.48      0.55        87\n",
      "\n",
      "                        micro avg       0.69      0.45      0.54       397\n",
      "                        macro avg       0.72      0.44      0.54       397\n",
      "                     weighted avg       0.72      0.45      0.54       397\n",
      "                      samples avg       0.45      0.45      0.45       397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/envs/goal_rec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sub_goals = list(goals_dict.keys())[0:5]\n",
    "train_plans, val_plans, sub_goals_dict, sub_actions_dict = run(iteration, sub_goals, {}, {}, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_sub_goals_dict = sub_goals_dict\n",
    "old_sub_actions_dict = sub_actions_dict\n",
    "old_train_plans = train_plans\n",
    "old_val_plans = val_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(new_goals_dict) = 10\n",
      "sub_goals_dict.keys() = dict_keys(['have_image planet3 infrared0', 'have_image planet5 infrared3', 'have_image phenomenon14 infrared0', 'have_image phenomenon4 infrared0', 'have_image star5 infrared3', 'have_image planet3 image3', 'have_image phenomenon4 image3', 'have_image groundstation2 image0', 'pointing satellite4 planet5', 'pointing satellite3 planet9']), old_sub_goals_dict.keys() = dict_keys(['have_image planet3 infrared0', 'have_image planet5 infrared3', 'have_image phenomenon14 infrared0', 'have_image phenomenon4 infrared0', 'have_image star5 infrared3'])\n",
      "len(subplans) = 2439, count = 2495\n",
      "have_image planet3 infrared0 : len(to_add) = 100, count = 100\n",
      "have_image planet5 infrared3 : len(to_add) = 200, count = 100\n",
      "have_image phenomenon14 infrared0 : len(to_add) = 294, count = 100\n",
      "have_image phenomenon4 infrared0 : len(to_add) = 385, count = 100\n",
      "have_image star5 infrared3 : len(to_add) = 478, count = 100\n",
      "len(actions_dict) = 22478\n",
      "len(train_plans) = 2479, len(val_plans) = 438\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 8s 144ms/step - loss: 0.4755 - accuracy: 0.3052 - Custom_Hamming_Loss1: 0.1998 - precision: 0.2437 - val_loss: 0.3840 - val_accuracy: 0.3125 - val_Custom_Hamming_Loss1: 0.1148 - val_precision: 0.4444\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.3544 - accuracy: 0.3169 - Custom_Hamming_Loss1: 0.1023 - precision: 0.5673 - val_loss: 0.3012 - val_accuracy: 0.3177 - val_Custom_Hamming_Loss1: 0.0974 - val_precision: 0.8182\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.2882 - accuracy: 0.3484 - Custom_Hamming_Loss1: 0.0935 - precision: 0.8795 - val_loss: 0.2843 - val_accuracy: 0.3438 - val_Custom_Hamming_Loss1: 0.0966 - val_precision: 0.8947\n",
      "New best model found with loss 0.2842908203601837\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.2688 - accuracy: 0.4011 - Custom_Hamming_Loss1: 0.0936 - precision: 0.9293 - val_loss: 0.2740 - val_accuracy: 0.3646 - val_Custom_Hamming_Loss1: 0.0948 - val_precision: 0.9500\n",
      "New best model found with loss 0.27395251393318176\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.2613 - accuracy: 0.3968 - Custom_Hamming_Loss1: 0.0931 - precision: 0.9643 - val_loss: 0.2709 - val_accuracy: 0.3542 - val_Custom_Hamming_Loss1: 0.0969 - val_precision: 0.9091\n",
      "New best model found with loss 0.2708914577960968\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.2561 - accuracy: 0.4202 - Custom_Hamming_Loss1: 0.0937 - precision: 0.9422 - val_loss: 0.2651 - val_accuracy: 0.3854 - val_Custom_Hamming_Loss1: 0.0943 - val_precision: 0.9365\n",
      "New best model found with loss 0.265080988407135\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.2464 - accuracy: 0.4403 - Custom_Hamming_Loss1: 0.0915 - precision: 0.9845 - val_loss: 0.2675 - val_accuracy: 0.3698 - val_Custom_Hamming_Loss1: 0.0969 - val_precision: 0.8667\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.2425 - accuracy: 0.4470 - Custom_Hamming_Loss1: 0.0907 - precision: 0.9681 - val_loss: 0.2655 - val_accuracy: 0.3672 - val_Custom_Hamming_Loss1: 0.0966 - val_precision: 0.8548\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.2438 - accuracy: 0.4592 - Custom_Hamming_Loss1: 0.0919 - precision: 0.9658 - val_loss: 0.2636 - val_accuracy: 0.3932 - val_Custom_Hamming_Loss1: 0.0964 - val_precision: 0.8833\n",
      "New best model found with loss 0.2636313736438751\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.2327 - accuracy: 0.4996 - Custom_Hamming_Loss1: 0.0895 - precision: 0.9663 - val_loss: 0.2654 - val_accuracy: 0.3802 - val_Custom_Hamming_Loss1: 0.0979 - val_precision: 0.7639\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.2264 - accuracy: 0.5076 - Custom_Hamming_Loss1: 0.0900 - precision: 0.9210 - val_loss: 0.2730 - val_accuracy: 0.3776 - val_Custom_Hamming_Loss1: 0.0995 - val_precision: 0.7215\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.2147 - accuracy: 0.5525 - Custom_Hamming_Loss1: 0.0881 - precision: 0.8529 - val_loss: 0.2749 - val_accuracy: 0.4062 - val_Custom_Hamming_Loss1: 0.1000 - val_precision: 0.6602\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.2064 - accuracy: 0.5680 - Custom_Hamming_Loss1: 0.0844 - precision: 0.8693 - val_loss: 0.2749 - val_accuracy: 0.3958 - val_Custom_Hamming_Loss1: 0.0979 - val_precision: 0.6827\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.1981 - accuracy: 0.6094 - Custom_Hamming_Loss1: 0.0802 - precision: 0.8735 - val_loss: 0.2830 - val_accuracy: 0.3932 - val_Custom_Hamming_Loss1: 0.1005 - val_precision: 0.6058\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.1878 - accuracy: 0.6575 - Custom_Hamming_Loss1: 0.0760 - precision: 0.8705 - val_loss: 0.2923 - val_accuracy: 0.3880 - val_Custom_Hamming_Loss1: 0.1042 - val_precision: 0.5608\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.1775 - accuracy: 0.6799 - Custom_Hamming_Loss1: 0.0706 - precision: 0.8718 - val_loss: 0.3050 - val_accuracy: 0.3776 - val_Custom_Hamming_Loss1: 0.1065 - val_precision: 0.5260\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.1652 - accuracy: 0.7050 - Custom_Hamming_Loss1: 0.0658 - precision: 0.8807 - val_loss: 0.3277 - val_accuracy: 0.3906 - val_Custom_Hamming_Loss1: 0.1060 - val_precision: 0.5222\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.1599 - accuracy: 0.7317 - Custom_Hamming_Loss1: 0.0629 - precision: 0.8868 - val_loss: 0.3126 - val_accuracy: 0.3672 - val_Custom_Hamming_Loss1: 0.1062 - val_precision: 0.5294\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.1468 - accuracy: 0.7781 - Custom_Hamming_Loss1: 0.0584 - precision: 0.9000 - val_loss: 0.3115 - val_accuracy: 0.3932 - val_Custom_Hamming_Loss1: 0.1055 - val_precision: 0.5224\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.1383 - accuracy: 0.7914 - Custom_Hamming_Loss1: 0.0536 - precision: 0.9121 - val_loss: 0.3868 - val_accuracy: 0.3854 - val_Custom_Hamming_Loss1: 0.1141 - val_precision: 0.4500\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.1221 - accuracy: 0.8225 - Custom_Hamming_Loss1: 0.0479 - precision: 0.9103 - val_loss: 0.3696 - val_accuracy: 0.3854 - val_Custom_Hamming_Loss1: 0.1091 - val_precision: 0.4918\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.1136 - accuracy: 0.8396 - Custom_Hamming_Loss1: 0.0431 - precision: 0.9208 - val_loss: 0.4258 - val_accuracy: 0.3906 - val_Custom_Hamming_Loss1: 0.1156 - val_precision: 0.4405\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.1050 - accuracy: 0.8654 - Custom_Hamming_Loss1: 0.0391 - precision: 0.9317 - val_loss: 0.4238 - val_accuracy: 0.4036 - val_Custom_Hamming_Loss1: 0.1141 - val_precision: 0.4586\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0999 - accuracy: 0.8735 - Custom_Hamming_Loss1: 0.0369 - precision: 0.9434 - val_loss: 0.4089 - val_accuracy: 0.4115 - val_Custom_Hamming_Loss1: 0.1120 - val_precision: 0.4721\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0903 - accuracy: 0.8797 - Custom_Hamming_Loss1: 0.0350 - precision: 0.9456 - val_loss: 0.4333 - val_accuracy: 0.4193 - val_Custom_Hamming_Loss1: 0.1135 - val_precision: 0.4650\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0845 - accuracy: 0.9024 - Custom_Hamming_Loss1: 0.0325 - precision: 0.9408 - val_loss: 0.4724 - val_accuracy: 0.4036 - val_Custom_Hamming_Loss1: 0.1161 - val_precision: 0.4478\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0811 - accuracy: 0.9015 - Custom_Hamming_Loss1: 0.0318 - precision: 0.9466 - val_loss: 0.5047 - val_accuracy: 0.4167 - val_Custom_Hamming_Loss1: 0.1174 - val_precision: 0.4379\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0733 - accuracy: 0.9064 - Custom_Hamming_Loss1: 0.0294 - precision: 0.9507 - val_loss: 0.4798 - val_accuracy: 0.4115 - val_Custom_Hamming_Loss1: 0.1188 - val_precision: 0.4331\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0651 - accuracy: 0.9162 - Custom_Hamming_Loss1: 0.0253 - precision: 0.9612 - val_loss: 0.6054 - val_accuracy: 0.3984 - val_Custom_Hamming_Loss1: 0.1201 - val_precision: 0.4312\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0653 - accuracy: 0.9277 - Custom_Hamming_Loss1: 0.0245 - precision: 0.9535 - val_loss: 0.5868 - val_accuracy: 0.3880 - val_Custom_Hamming_Loss1: 0.1237 - val_precision: 0.4127\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0599 - accuracy: 0.9206 - Custom_Hamming_Loss1: 0.0227 - precision: 0.9661 - val_loss: 0.5099 - val_accuracy: 0.3984 - val_Custom_Hamming_Loss1: 0.1195 - val_precision: 0.4330\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0512 - accuracy: 0.9485 - Custom_Hamming_Loss1: 0.0190 - precision: 0.9673 - val_loss: 0.5539 - val_accuracy: 0.3958 - val_Custom_Hamming_Loss1: 0.1208 - val_precision: 0.4228\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0526 - accuracy: 0.9426 - Custom_Hamming_Loss1: 0.0181 - precision: 0.9733 - val_loss: 0.6382 - val_accuracy: 0.3932 - val_Custom_Hamming_Loss1: 0.1227 - val_precision: 0.4154\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0503 - accuracy: 0.9370 - Custom_Hamming_Loss1: 0.0186 - precision: 0.9656 - val_loss: 0.6055 - val_accuracy: 0.4141 - val_Custom_Hamming_Loss1: 0.1211 - val_precision: 0.4303\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0459 - accuracy: 0.9414 - Custom_Hamming_Loss1: 0.0178 - precision: 0.9725 - val_loss: 0.6431 - val_accuracy: 0.4089 - val_Custom_Hamming_Loss1: 0.1219 - val_precision: 0.4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/envs/goal_rec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13363486842105263\n",
      "\n",
      "Hamming Loss: 0.09013157894736842\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "     have_image planet3 infrared0       1.00      0.72      0.83        95\n",
      "     have_image planet5 infrared3       0.98      0.85      0.91       113\n",
      "have_image phenomenon14 infrared0       0.99      0.79      0.88       102\n",
      " have_image phenomenon4 infrared0       0.97      0.75      0.85        99\n",
      "       have_image star5 infrared3       1.00      0.78      0.88       101\n",
      "        have_image planet3 image3       0.00      0.00      0.00       431\n",
      "    have_image phenomenon4 image3       0.68      0.03      0.05       488\n",
      " have_image groundstation2 image0       0.00      0.00      0.00       448\n",
      "      pointing satellite4 planet5       0.33      0.01      0.02       364\n",
      "      pointing satellite3 planet9       0.00      0.00      0.00       345\n",
      "\n",
      "                        micro avg       0.95      0.16      0.27      2586\n",
      "                        macro avg       0.60      0.39      0.44      2586\n",
      "                     weighted avg       0.37      0.16      0.18      2586\n",
      "                      samples avg       0.17      0.15      0.16      2586\n",
      "\n",
      "Accuracy: 0.109375\n",
      "\n",
      "Hamming Loss: 0.09609375\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "     have_image planet3 infrared0       0.89      0.40      0.55        20\n",
      "     have_image planet5 infrared3       1.00      0.67      0.80        15\n",
      "have_image phenomenon14 infrared0       1.00      0.76      0.87        17\n",
      " have_image phenomenon4 infrared0       0.82      0.50      0.62        18\n",
      "       have_image star5 infrared3       0.84      0.84      0.84        19\n",
      "        have_image planet3 image3       0.00      0.00      0.00        75\n",
      "    have_image phenomenon4 image3       0.50      0.02      0.03        66\n",
      " have_image groundstation2 image0       0.00      0.00      0.00        56\n",
      "      pointing satellite4 planet5       0.00      0.00      0.00        72\n",
      "      pointing satellite3 planet9       0.00      0.00      0.00        60\n",
      "\n",
      "                        micro avg       0.88      0.14      0.24       418\n",
      "                        macro avg       0.50      0.32      0.37       418\n",
      "                     weighted avg       0.27      0.14      0.16       418\n",
      "                      samples avg       0.15      0.13      0.14       418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/envs/goal_rec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda/anaconda3/envs/goal_rec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sub_goals = list(goals_dict.keys())[5:10]\n",
    "train_generator, val_generator, sub_goals_dict, sub_actions_dict, train_plans, val_plans = preprocess(sub_goals, set(old_train_plans).union(set(old_val_plans)), old_sub_goals_dict, old_sub_actions_dict)\n",
    "model = create_model(train_generator, 1e-4)\n",
    "old_model = load_model(path.join(models_dir, 'model_0.h5'), custom_objects = {'AttentionWeights' : goal_rec_utils.attention_layers.AttentionWeights, 'ContextVector' : goal_rec_utils.attention_layers.ContextVector, 'Custom_Hamming_Loss1' : Custom_Hamming_Loss1})\n",
    "transfer_model(model, old_model)\n",
    "model.fit(train_generator, epochs=100, validation_data=val_generator, callbacks=[SaveBestModelCallback(temp_dir, 25, 0)])\n",
    "test_model(model, sub_goals_dict, sub_actions_dict, train_plans, 1)\n",
    "test_model(model, sub_goals_dict, sub_actions_dict, val_plans, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'have_image planet5 infrared3': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'have_image planet3 infrared0': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'have_image phenomenon4 infrared0': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'have_image star5 infrared3': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'have_image phenomenon14 infrared0': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'have_image planet3 image3': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'have_image phenomenon4 image3': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'have_image groundstation2 image0': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'pointing satellite4 planet5': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'pointing satellite3 planet9': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n",
      "{'have_image planet5 infrared3': array([1., 0., 0., 0., 0.]), 'have_image planet3 infrared0': array([0., 1., 0., 0., 0.]), 'have_image phenomenon4 infrared0': array([0., 0., 1., 0., 0.]), 'have_image star5 infrared3': array([0., 0., 0., 1., 0.]), 'have_image phenomenon14 infrared0': array([0., 0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "print(sub_goals_dict)\n",
    "print(old_sub_goals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 82)       1843278     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30, 363)      647592      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (AttentionWei (None, 30)           393         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "context_vector_3 (ContextVector (None, 363)          0           lstm[0][0]                       \n",
      "                                                                 attention_weights[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3640        context_vector_3[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 2,494,903\n",
      "Trainable params: 2,494,903\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[-0.06072112 -0.05820167 -0.05302558 -0.03600901 -0.07074687]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_layer('dense').get_weights()[1])\n",
    "print(old_model.get_layer('dense').get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2439 5155\n"
     ]
    }
   ],
   "source": [
    "s = set()\n",
    "goals = list(goals_dict.keys())[5:10]\n",
    "for i in range(5,10):\n",
    "    k = list(goals_dict.keys())[i]\n",
    "    for p in plans:\n",
    "        if k in p.goals:\n",
    "            s.add(p)\n",
    "            count += 1\n",
    "print(len(s), count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "200 100\n",
      "295 100\n",
      "391 100\n",
      "489 100\n",
      "2439 489\n",
      "2928\n"
     ]
    }
   ],
   "source": [
    "old_goals = list(goals_dict.keys())[0:5]\n",
    "to_add = set()\n",
    "for g in old_goals:\n",
    "    count = 0\n",
    "    for p in list(old_set):\n",
    "        if count == 100:\n",
    "            break\n",
    "        if g in p.goals and p not in s and p not in to_add:\n",
    "            to_add.add(p)\n",
    "            count += 1\n",
    "        elif g in p.goals and p not in s:\n",
    "            count += 1\n",
    "    print(len(to_add), count)\n",
    "\n",
    "print(len(s), len(to_add))\n",
    "s = s.union(to_add)\n",
    "print(len(s))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'have_image phenomenon14 infrared0': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'have_image star5 infrared3': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'have_image planet3 infrared0': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'have_image phenomenon4 infrared0': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'have_image planet5 infrared3': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'pointing satellite4 planet5': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'have_image planet3 image3': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'have_image phenomenon4 image3': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'have_image groundstation2 image0': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'pointing satellite3 planet9': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n",
      "18162\n"
     ]
    }
   ],
   "source": [
    "sub_plans = list(s)\n",
    "np.random.shuffle(sub_plans)\n",
    "train_plans = list(s)[:int(len(s)*0.85)]\n",
    "val_plans = list(s)[int(len(s)*0.85):]\n",
    "sub_goals_dict = create_goals_dict(list(goals_dict.keys())[0:10])\n",
    "print(sub_goals_dict)\n",
    "sub_actions_dict = create_actions_dict(list(s))\n",
    "print(len(sub_actions_dict))\n",
    "train_generator = PlanGeneratorMultiPerc(train_plans, sub_actions_dict, sub_goals_dict, 64, 30, 0.3, 1)\n",
    "val_generator = PlanGeneratorMultiPerc(val_plans, sub_actions_dict, sub_goals_dict, 64, 30, 0.3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 82)       1489366     input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30, 363)      647592      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (AttentionWei (None, 30)           393         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "context_vector_10 (ContextVecto (None, 363)          0           lstm[0][0]                       \n",
      "                                                                 attention_weights[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           3640        context_vector_10[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 2,140,991\n",
      "Trainable params: 2,140,991\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 82)       1489366     input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30, 363)      647592      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (AttentionWei (None, 30)           393         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "context_vector_9 (ContextVector (None, 363)          0           lstm[0][0]                       \n",
      "                                                                 attention_weights[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           3640        context_vector_9[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 2,140,991\n",
      "Trainable params: 2,140,991\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(train_generator, 1e-5)\n",
    "old_model = load_model('../model_0.h5', custom_objects = {'AttentionWeights' : goal_rec_utils.attention_layers.AttentionWeights, 'ContextVector' : goal_rec_utils.attention_layers.ContextVector, 'Custom_Hamming_Loss1' : Custom_Hamming_Loss1})\n",
    "model.summary()\n",
    "old_model.summary()\n",
    "#model.fit(train_generator, epochs=100, validation_data=val_generator, callbacks=[SaveBestModelCallback('./', 5, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 8s 147ms/step - loss: 0.8004 - Custom_Hamming_Loss1: 0.1636 - accuracy: 0.1468 - precision: 0.1061 - recall: 0.0696 - val_loss: 5.4640 - val_Custom_Hamming_Loss1: 0.1138 - val_accuracy: 0.1979 - val_precision: 0.0769 - val_recall: 0.0048\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.9375 - Custom_Hamming_Loss1: 0.1079 - accuracy: 0.1918 - precision: 0.1338 - recall: 0.0030 - val_loss: 3.6290 - val_Custom_Hamming_Loss1: 0.1115 - val_accuracy: 0.2057 - val_precision: 0.1905 - val_recall: 0.0096\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 2.3048 - Custom_Hamming_Loss1: 0.1072 - accuracy: 0.3096 - precision: 0.4476 - recall: 0.0226 - val_loss: 0.8685 - val_Custom_Hamming_Loss1: 0.1117 - val_accuracy: 0.3177 - val_precision: 0.2903 - val_recall: 0.0216\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.4502 - Custom_Hamming_Loss1: 0.0978 - accuracy: 0.4449 - precision: 0.7630 - recall: 0.1243 - val_loss: 3.6623 - val_Custom_Hamming_Loss1: 0.1164 - val_accuracy: 0.3229 - val_precision: 0.3152 - val_recall: 0.0702\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 2.0672 - Custom_Hamming_Loss1: 0.0838 - accuracy: 0.5925 - precision: 0.7863 - recall: 0.3026 - val_loss: 3.4753 - val_Custom_Hamming_Loss1: 0.1094 - val_accuracy: 0.3776 - val_precision: 0.4615 - val_recall: 0.1017\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 2.8420 - Custom_Hamming_Loss1: 0.0650 - accuracy: 0.6943 - precision: 0.8526 - recall: 0.4658 - val_loss: 2.6871 - val_Custom_Hamming_Loss1: 0.1076 - val_accuracy: 0.3151 - val_precision: 0.5102 - val_recall: 0.1205\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 5.6232 - Custom_Hamming_Loss1: 0.0722 - accuracy: 0.6594 - precision: 0.7691 - recall: 0.4570 - val_loss: 6.1737 - val_Custom_Hamming_Loss1: 0.1068 - val_accuracy: 0.3281 - val_precision: 0.5200 - val_recall: 0.0944\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 3.2534 - Custom_Hamming_Loss1: 0.0628 - accuracy: 0.7044 - precision: 0.8845 - recall: 0.4630 - val_loss: 3.0363 - val_Custom_Hamming_Loss1: 0.1057 - val_accuracy: 0.3411 - val_precision: 0.5517 - val_recall: 0.1157\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 4.5099 - Custom_Hamming_Loss1: 0.0499 - accuracy: 0.7432 - precision: 0.9236 - recall: 0.5818 - val_loss: 6.9937 - val_Custom_Hamming_Loss1: 0.1016 - val_accuracy: 0.3672 - val_precision: 0.6000 - val_recall: 0.1533\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 3.4538 - Custom_Hamming_Loss1: 0.0468 - accuracy: 0.7550 - precision: 0.8874 - recall: 0.6407 - val_loss: 5.0985 - val_Custom_Hamming_Loss1: 0.1034 - val_accuracy: 0.3490 - val_precision: 0.5565 - val_recall: 0.1679\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 4.9576 - Custom_Hamming_Loss1: 0.0410 - accuracy: 0.8067 - precision: 0.9223 - recall: 0.6699 - val_loss: 4.8517 - val_Custom_Hamming_Loss1: 0.1060 - val_accuracy: 0.3177 - val_precision: 0.5248 - val_recall: 0.1787\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 2.2439 - Custom_Hamming_Loss1: 0.0385 - accuracy: 0.8013 - precision: 0.9289 - recall: 0.6926 - val_loss: 3.0144 - val_Custom_Hamming_Loss1: 0.1018 - val_accuracy: 0.3568 - val_precision: 0.5913 - val_recall: 0.1650\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 1.2132 - Custom_Hamming_Loss1: 0.0379 - accuracy: 0.8090 - precision: 0.9526 - recall: 0.6781 - val_loss: 4.2807 - val_Custom_Hamming_Loss1: 0.1031 - val_accuracy: 0.3620 - val_precision: 0.5471 - val_recall: 0.2257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f838dd45340>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Custom_Hamming_Loss1, 'accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "model.fit(train_generator, epochs=100, validation_data=val_generator, callbacks=[SaveBestModelCallback('./', 10, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19270833333333334\n",
      "\n",
      "Hamming Loss: 0.10416666666666667\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "have_image phenomenon14 infrared0       0.00      0.00      0.00         2\n",
      "       have_image star5 infrared3       0.00      0.00      0.00         4\n",
      "     have_image planet3 infrared0       0.00      0.00      0.00         5\n",
      " have_image phenomenon4 infrared0       0.00      0.00      0.00         4\n",
      "     have_image planet5 infrared3       0.00      0.00      0.00         5\n",
      "      pointing satellite4 planet5       0.44      0.10      0.17        67\n",
      "        have_image planet3 image3       0.58      0.25      0.35        75\n",
      "    have_image phenomenon4 image3       0.55      0.29      0.38        95\n",
      " have_image groundstation2 image0       0.59      0.25      0.35        87\n",
      "      pointing satellite3 planet9       0.50      0.15      0.23        67\n",
      "\n",
      "                        micro avg       0.53      0.21      0.30       411\n",
      "                        macro avg       0.27      0.11      0.15       411\n",
      "                     weighted avg       0.51      0.21      0.29       411\n",
      "                      samples avg       0.22      0.22      0.21       411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/envs/goal_rec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda/anaconda3/envs/goal_rec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "incremental_model_training.PlanGeneratorMultiPerc = PlanGeneratorMultiPerc\n",
    "model = load_model('./model.h5', custom_objects = {'AttentionWeights' : goal_rec_utils.attention_layers.AttentionWeights, 'ContextVector' : goal_rec_utils.attention_layers.ContextVector, 'Custom_Hamming_Loss1' : Custom_Hamming_Loss1})\n",
    "run_tests(model, val_plans, sub_actions_dict, sub_goals_dict, 64, 30, 0.3, 1, None)\n",
    "model.save('../model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros([5,])\n",
    "print(np.append(a, np.zeros([5,])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ab241b9a0e60df6a5edd612c58ee3579256c0ca1b2e4085ba523e8a69342b39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
