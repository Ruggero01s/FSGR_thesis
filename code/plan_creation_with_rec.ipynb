{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667eec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from os.path import  join, isdir\n",
    "from plan import Plan\n",
    "from action import Action\n",
    "from utils import load_from_folder\n",
    "from multiprocess import Pool\n",
    "import random\n",
    "from logging import exception\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d761e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain dir: ../datasets/logistics/optimal_plans/dictionaries_and_plans/\n"
     ]
    }
   ],
   "source": [
    "save_dir = './generated_gr_dataset/'\n",
    "data_base_dir = '../datasets/'\n",
    "domain = 'logistics'\n",
    "results_dir = f\"{save_dir}/{domain}/\"   \n",
    "source_dir = f\"{join(data_base_dir, domain)}/optimal_plans/dictionaries_and_plans/\" \n",
    "print('Domain dir:', source_dir)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "plans_to_process = 10000 # number of plans to process\n",
    "versions_per_plan = 5 # number of versions per each plan\n",
    "number_of_goals = 4 # number of goals per each new plan\n",
    "test = False # test will process only 3 plans\n",
    "#rec_classes = [[0,0.2], [0.2,0.3], [0.3,0.4], [0.4,0.5], [0.5,0.6], [0.6,0.7], [0.7,0.8], [0.8,0.999]] # classes of recognizability\n",
    "rec_classes = [[0,0.2], [0.2,0.4], [0.4,0.6], [0.6,0.8], [0.8, 1]] # classes of recognizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe052be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to clear the results directory\n",
    "for folder in os.listdir(results_dir):\n",
    "    #remove directory if it exists along with its content\n",
    "    if isdir(join(results_dir, folder)):\n",
    "        shutil.rmtree(join(results_dir, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ac5476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plans loaded from ../datasets/logistics/optimal_plans/dictionaries_and_plans/\n",
      "Plans: 47769\n"
     ]
    }
   ],
   "source": [
    "#loading the plans\n",
    "plans = load_from_folder(source_dir,[\"plans\"])[0]\n",
    "print(f\"Plans: {len(plans)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a041db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recognizability(current_goal_state, goal_state_list):\n",
    "    \"\"\"\n",
    "    Compute the difficulty of a plan.\n",
    "    :param current_goal_state: The goal state for which we calculate the recognizability.\n",
    "    :param goal_state_list: The list of goal states to use for the computation.\n",
    "    :return: The recognizability of the plan.\n",
    "    \"\"\"\n",
    "    \n",
    "    #the current goal state must be in the goal state list\n",
    "    if current_goal_state not in goal_state_list:\n",
    "        raise ValueError(f\"current_goal_state {current_goal_state} must be included in goal_state_list {goal_state_list}\")\n",
    "    \n",
    "    #min and max to use for normalization\n",
    "    #teoretical min recognizability is when all the fluent in current are present in each goal state in the goal state list\n",
    "    #the formula becomes 1/n+1/n+1/n+...+1/n = len(current_goal_state) / len(goal_state_list)\n",
    "    #teoretical max recognizability is when all the fluent in current are not present anywhere in the goal state list\n",
    "    #formula is 1/1 + 1/1 + 1/1 ... + 1/1 = 1 * len(current_goal_state)\n",
    "    \n",
    "    #? min max accettabili ovvero\n",
    "    #?  per il min almeno uno deve essere diverso, non vogliamo rec=0 , ok) \n",
    "    #?  per il max invece?   \n",
    "    #?       è accettabile avere tutti i fluenti diversi quindi rec=1, o deve essercene uno in uno dei goal delle versioni che è uguale?\n",
    "    \n",
    "    min_recognizability = 1/(len(goal_state_list)) * (len(current_goal_state)) # tutti i fluenti uguali\n",
    "    #min è quando sono tutti diversi di almeno uno\n",
    "    #min_recognizability  = 1/(len(goal_state_list)) * (len(current_goal_state)-1) + 1/(len(goal_state_list)-1) # tutti fluenti presenti in tutti i goal a parte uno che non è presente da qualche parte\n",
    "    #? (len(current_goal_state)-2) * (len(goal_state_list)+1)/len(goal_state_list) # questa è invece la tua formula per la massima uniqueness\n",
    "    #? perchè la massima uniqueness non è quando i fluenti del base non compaiono da nessun'altra parte? o se quel caso non va bene allora quello in cui ce n'è solo uno uguale?\n",
    "    max_recognizability  = 1*len(current_goal_state) # tutti fluenti diversi\n",
    "    #max_recognizability  = 1*(len(current_goal_state)-1) + 1/2 # tutti fluenti diversi a parte uno che ha un doppione da qualche parte\n",
    "    \n",
    "    #todo sistemare formula hardcodando max e min\n",
    "    #k=2, n=6 = 7/12 \n",
    "    #k=3, n=6 = 3/4\n",
    "    #k=4, n=6 = #da runnare\n",
    "    #todo\n",
    "    \n",
    "    # print(f\"min_recognizability: {min_recognizability}\")\n",
    "    # print(f\"max_recognizability: {max_recognizability}\")\n",
    "    \n",
    "    sum = 0\n",
    "    \n",
    "    # too see the sum of fractions\n",
    "    # debug_string = \"\"\n",
    "    #need to count how many times the current goal fluent is in the goal state list\n",
    "    for current_goal_fluent in current_goal_state:\n",
    "        count = 0\n",
    "        for goal_state in goal_state_list:\n",
    "            for goal_fluent in goal_state:       \n",
    "                if current_goal_fluent==goal_fluent:\n",
    "                    count += 1\n",
    "                    break\n",
    "        sum += 1/count\n",
    "    #     debug_string += f\" + 1/{count}\"\n",
    "    \n",
    "    # debug_string += f\" = {sum}\"\n",
    "    # debug_string = debug_string[3:]\n",
    "    #print(f\"Unscaled recognizability: {sum}\")\n",
    "    \n",
    "    #normalize the recognizability #? should be ok \n",
    "    recognizability = (sum-min_recognizability) / (max_recognizability-min_recognizability)\n",
    "    # print(debug_string)\n",
    "    return round(recognizability, 4)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceab2950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.3333\n"
     ]
    }
   ],
   "source": [
    "# your paper example\n",
    "\n",
    "# If G={G1,G2,G3},  with G∗=\n",
    "# G1={a,b,c}, \n",
    "# G2={a,e,f}, \n",
    "# G3={g,h,i}, \n",
    "# then R(G∗) = 1/2+ 1 + 1 = 5/2 and Rz(G∗) = 0.75(high recognizability). \n",
    "\n",
    "# If G={G1,G2,G3}, with G∗=\n",
    "# G1={a,b,c},\n",
    "# G2={a,b,x},\n",
    "# G3={a,b,y}, \n",
    "# then R(G∗) =1/3+1/3+ 1 =5/3, and so Rz(G∗) = 0.33(low recognizability).\n",
    "\n",
    "#se uso i massimi e minimi teoretici che ho usato fino ad adesso esce giusto, con le altre formule non mi torna\n",
    "    #min_recognizability = 1/(len(goal_state_list)) * (len(current_goal_state)) # tutti i fluenti uguali\n",
    "    #max_recognizability  = 1*len(current_goal_state) # tutti fluenti diversi\n",
    "\n",
    "\n",
    "#test compute_recognizability\n",
    "goal_state_list = [[\"a\", \"b\", \"c\"], \n",
    "                   [\"a\", \"e\", \"f\"], \n",
    "                   [\"g\", \"h\", \"i\"],]\n",
    "print(compute_recognizability(goal_state_list[0], goal_state_list))\n",
    "\n",
    "goal_state_list = [[\"a\", \"b\", \"c\"], \n",
    "                   [\"a\", \"b\", \"x\"], \n",
    "                   [\"a\", \"b\", \"y\"],]\n",
    "print(compute_recognizability(goal_state_list[0], goal_state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a315544",
   "metadata": {},
   "outputs": [],
   "source": [
    " #todo subject to change depending on how we want output\n",
    "def write_and_save_versions(plan, goal_state_list, obj_set_dict={}, rec_class=[0,1]):\n",
    "    \"\"\"Write the plan and its versions to files.\n",
    "    :param plan: The plan to write.\n",
    "    :param goal_state_list: The list of goal states, each state will produce a different version, at index 0 should be the original plan.\n",
    "    :param obj_set_dict: The dictionary of objects.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, goal_state in enumerate(goal_state_list):\n",
    "        \n",
    "        #extract plan name with regex\n",
    "        name = re.search(r\"(p\\d+)(?=\\.)\", plan.plan_name).group(1)\n",
    "        \n",
    "        #definition\n",
    "        new_problem = \"\"\n",
    "        # if i==0:\n",
    "        #     new_problem += f\";;(;metadata (recognizability:{round(compute_recognizability(goal_state_list[0], goal_state_list),2)})\\n\"\n",
    "        \n",
    "        new_problem += f\"(define (problem {domain}_{name}_{i})\\n(:domain {domain})\\n(:objects\\n\\t\"\n",
    "    \n",
    "        \n",
    "        #objects in a dict format, {type: obj_set}\n",
    "        for type, obj_set in obj_set_dict.items():\n",
    "            if len(obj_set) > 0:\n",
    "                for obj in obj_set:\n",
    "                    new_problem += f\"{obj} \"\n",
    "                new_problem += f\"- {type}\\n\\t\"\n",
    "        new_problem += f\")\\n\"\n",
    "        \n",
    "        #initial state\n",
    "        new_problem += f\"(:init\\n\"\n",
    "        for fluent in plan.initial_state:\n",
    "            new_problem += f\"\\t{fluent}\\n\"\n",
    "        new_problem += f\")\\n\"\n",
    "        \n",
    "        #goal state\n",
    "        new_problem += f\"(:goal (and\\n\"\n",
    "        for goal in goal_state:\n",
    "            new_problem += f\"\\t{goal}\\n\"\n",
    "        new_problem += f\"))\\n)\"\n",
    "        #print(new_problem + \"\\n\\n\")\n",
    "        \n",
    "        #save the new problem in a file\n",
    "        #naming convention is {current plan name_version number.pddl}, _0 is the original plan\n",
    "        new_problem_dir = f\"{results_dir}/{name}/\"\n",
    "        class_dir = f\"{results_dir}/{name}/{rec_class[0]}_{rec_class[1]}/\"\n",
    "        os.makedirs(new_problem_dir, exist_ok=True)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        new_problem_file = f\"{class_dir}/{name}_{i}.pddl\"\n",
    "        with open(new_problem_file, \"w\") as f:\n",
    "            f.write(new_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04fbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #todo subject to change depending on how we want output\n",
    "\n",
    "def write_original_plan(plan, goal_state, obj_set_dict):\n",
    "    \n",
    "    #extract plan name with regex\n",
    "    name = re.search(r\"(p\\d+)(?=\\.)\", plan.plan_name).group(1)\n",
    "    \n",
    "    #definition\n",
    "    new_problem = \"\"\n",
    "    \n",
    "    new_problem += f\"(define (problem {domain}_{name}_og)\\n(:domain {domain})\\n(:objects\\n\\t\"\n",
    "\n",
    "    \n",
    "    #objects in a dict format, {type: obj_set}\n",
    "    for type, obj_set in obj_set_dict.items():\n",
    "        if len(obj_set) > 0:\n",
    "            for obj in obj_set:\n",
    "                new_problem += f\"{obj} \"\n",
    "            new_problem += f\"- {type}\\n\\t\"\n",
    "    new_problem += f\")\\n\"\n",
    "    \n",
    "    #initial state\n",
    "    new_problem += f\"(:init\\n\"\n",
    "    for fluent in plan.initial_state:\n",
    "        new_problem += f\"\\t{fluent}\\n\"\n",
    "    new_problem += f\")\\n\"\n",
    "    \n",
    "    #goal state\n",
    "    new_problem += f\"(:goal (and\\n\"\n",
    "    for goal in goal_state:\n",
    "        new_problem += f\"\\t{goal}\\n\"\n",
    "    new_problem += f\"))\\n)\"\n",
    "    #print(new_problem + \"\\n\\n\")\n",
    "    \n",
    "    #save the new problem in a file\n",
    "    #naming convention is {current plan name_version number.pddl}\n",
    "    new_problem_dir = f\"{results_dir}/{name}/\"\n",
    "    os.makedirs(new_problem_dir, exist_ok=True)\n",
    "    new_problem_file = f\"{new_problem_dir}/{name}_og.pddl\"\n",
    "    with open(new_problem_file, \"w\") as f:\n",
    "        f.write(new_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f04baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_if_goal_state_in_init(init, goal_state):\n",
    "    goal_present_in_init = True\n",
    "    for goal_fluent in goal_state:\n",
    "        # print(base_goal_fluent)\n",
    "        # print(problem.og_plan.initial_state)\n",
    "        if goal_fluent in init:\n",
    "            continue\n",
    "        else:\n",
    "            goal_present_in_init = False\n",
    "            break\n",
    "    \n",
    "    return goal_present_in_init\n",
    "\n",
    "def create_goal_state_list(initial_state, package_for_goal_set, pos_for_goal_set, number_of_goals, versions_per_plan):\n",
    "    \"\"\"Create a list of goal states.\n",
    "    :param package_for_goal_set: The set of packages to use for the goal state.\n",
    "    :param pos_for_goal_set: The set of positions to use for the goal state.\n",
    "    :param number_of_goals: The number of goals to generate.\n",
    "    :param versions_per_plan: The number of versions to generate.\n",
    "    :return: A list of goal states.\n",
    "    \"\"\"\t\n",
    "    goal_state_list = []\n",
    "    for i in range(0, versions_per_plan + 1):\n",
    "        # generate a random goal state\n",
    "        goal_state = generate_goal_state(initial_state, package_for_goal_set, pos_for_goal_set, number_of_goals)\n",
    "            \n",
    "        goal_state_list.append(goal_state)\n",
    "        \n",
    "    return goal_state_list\n",
    "        \n",
    "def generate_goal_state(initial_state, package_for_goal_set, pos_for_goal_set, number_of_goals):\n",
    "    \"\"\"Generate a random goal state.\t\n",
    "    :param package_for_goal_set: The set of packages to use for the goal state.\n",
    "    :param pos_for_goal_set: The set of positions to use for the goal state.\n",
    "    :param number_of_goals: The number of fluents to generate for the goal state.\n",
    "    :return: A set of fluents representing a goal state.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        goal_state = set()\n",
    "        package_for_goal_set_copy = package_for_goal_set.copy()\n",
    "        pos_for_goal_set_copy = pos_for_goal_set.copy()\n",
    "        for _ in range(number_of_goals):\n",
    "            random_package = random.choice(list(package_for_goal_set_copy))\n",
    "            package_for_goal_set_copy.remove(random_package)\n",
    "            random_pos = random.choice(list(pos_for_goal_set_copy))\n",
    "            \n",
    "            #? can objects be in same position? assuming yes\n",
    "            #? pos_for_goal_set_copy.remove(random_pos) \n",
    "            goal_state.add(f\"at {random_package} {random_pos}\") \n",
    "        \n",
    "        if not check_if_goal_state_in_init(initial_state, goal_state):\n",
    "            break\n",
    "    return list(goal_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f25e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate how precise the generation is\n",
    "global_counter = 0\n",
    "\n",
    "running_sum_rec_error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89119559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_consistency(goal_state, prefix=\"obj\"):\n",
    "    \"\"\"\t\n",
    "    Check if the goal state is consistent by checking if it has same obj used more than once.\n",
    "    :param goal_state: The goal state to check.\n",
    "    :return: True if the goal state is consistent, False otherwise.\n",
    "    \"\"\"\n",
    "    objects = []\n",
    "    for fluent in goal_state:\n",
    "        obj = re.search(rf\"{prefix}\\d+\", fluent)\n",
    "        objects.append(obj.group(0))\n",
    "    return len(objects) == len(set(objects))\n",
    "        \n",
    "\n",
    "def check_if_fluent_is_usable(fluent_to_add, goal_state):\n",
    "    \"\"\"\n",
    "    Check if the fluent to add is usable in the goal state.\n",
    "    This means checking if fluent is not already in the goal state and if the object in fluent is not already in the goal state.\n",
    "    :param fluent_to_add: The fluent to add.\n",
    "    :param goal_state: The goal state to check.\n",
    "    :return: True if the fluent to add is usable, False otherwise.\n",
    "    \"\"\"\n",
    "    #check if goal state is a list of strings\n",
    "    if isinstance(fluent_to_add, list):\n",
    "        raise ValueError(f\"fluent to add is a list: {fluent_to_add}\")\n",
    "    for fluent in goal_state:\n",
    "        if fluent == fluent_to_add:\n",
    "            return False\n",
    "        elif check_same_object_in_fluents(fluent_to_add, fluent, prefix=\"obj\"):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def check_same_object_in_fluents(fluent1, fluent2, prefix=\"obj\"):\n",
    "    \"\"\"\n",
    "    Check if the object in fluent1 is in fluent2.\n",
    "    :return: True if the object in fluent1 is in fluent2, False otherwise.\n",
    "    \"\"\"\n",
    "    #extract the object from the fluent using regex\n",
    "    obj1 = re.search(rf\"{prefix}\\d+\", fluent1).group(0)\n",
    "    obj2 = re.search(rf\"{prefix}\\d+\", fluent2).group(0)\n",
    "\n",
    "    if obj1 == obj2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_duplicates(goal_state_list):\n",
    "    \"\"\"\n",
    "    Check if the goal state list has duplicates.\n",
    "    :param goal_state_list: The goal state list to check.\n",
    "    :return: True if the goal state list has duplicates, False otherwise.\n",
    "    \"\"\"\n",
    "    #check if goal state is a list of strings\n",
    "    if isinstance(goal_state_list, str):\n",
    "        raise ValueError(f\"goal state list is a string: {goal_state_list}\")\n",
    "    \n",
    "    #check if there are duplicates in the goal state list\n",
    "    return len(goal_state_list) != len(set(tuple(sorted(g)) for g in goal_state_list))\n",
    "\n",
    "def expand_candidates_list(goal_state, base_goal_state, package_for_goal_set, pos_for_goal_set):\n",
    "    \"\"\"\n",
    "    Expand candidates list by generating all possible fluent\n",
    "    \"\"\"\n",
    "    #generate all possible fluents\n",
    "    all_possible_fluents = []\n",
    "    for package in package_for_goal_set:\n",
    "        for pos in pos_for_goal_set:\n",
    "            all_possible_fluents.append(f\"at {package} {pos}\")\n",
    "    \n",
    "    #remove the fluents that are already in the goal state\n",
    "    for fluent in goal_state:\n",
    "        if fluent in all_possible_fluents:\n",
    "            all_possible_fluents.remove(fluent)\n",
    "    \n",
    "    #remove the fluents that are already in the base goal state\n",
    "    for fluent in base_goal_state:\n",
    "        if fluent in all_possible_fluents:\n",
    "            all_possible_fluents.remove(fluent)\n",
    "            \n",
    "    for fluent in all_possible_fluents:\n",
    "        if not check_if_fluent_is_usable(fluent, goal_state):\n",
    "            all_possible_fluents.remove(fluent)\n",
    "    \n",
    "    return all_possible_fluents\n",
    "\n",
    "def adapt_goal_state_list_to_recognizability(initial_state, base_goal_state, goal_state_list, \n",
    "                                             package_for_goal_set, pos_for_goal_set, \n",
    "                                             number_of_goals, rec_target=[0, 1], \n",
    "                                             randomness_patience=5, regeneration_patience=3):\n",
    "    \"\"\"\n",
    "    Adapt the goal state list to the recognizability. \n",
    "    This is done by swapping fluents between the base goal state and the goal state list.\n",
    "    If we have to reduce recognisability, we swap a random fluent in the goal state list with a fluent from the base goal state.\n",
    "    If we have to increase recognisability, we swap a fluent that is in the base goal state and in also in a goal in goal state list with a random possible fluent.\n",
    "    This does not guarantee that the recognizability will be in the target range, but it will be close.\n",
    "    It can happen that a goal state will be stuck in a local minimum, so we regenerate it to try staring from another point.\n",
    "    We keep track of which regenerations we have done and if we reach the patience limit, we will use the one that is closest to the target recognizability.\n",
    "    :param base_goal_state: The base goal state.\n",
    "    :param goal_state_list: The list of goal states to use to compute recognizability, without base goal state.\n",
    "    :param randomness_patience: The number of times we can try to adapt the goal state list before regenerating it. This will usually exhaust if we have many states that are stuck in a local minimum. If we reach this limit, we will regenerate the next stuck goal state.\n",
    "    :param regeneration_patience: The number of times we can regenerate a goal state before giving up.\n",
    "    :param package_for_goal_set: The set of packages to use for the goal state.\n",
    "    :param pos_for_goal_set: The set of positions to use for the goal state.\n",
    "    :param number_of_goals: The number of goals to generate.\n",
    "    :param rec_target: The target range of recognizability.\n",
    "    :return: The adapted goal state list.\n",
    "    \"\"\"\n",
    "    \n",
    "    if rec_target[0] > rec_target[1]:\n",
    "        raise ValueError(f\"rec_target[0] {rec_target[0]} must be less than rec_target[1] {rec_target[1]}\")\n",
    "    \n",
    "    #variables to keep track of errors\n",
    "    global global_counter\n",
    "    global running_sum_rec_error\n",
    "    \n",
    "    \n",
    "    randomness_patience_constant = randomness_patience\n",
    "    \n",
    "    #to keep track of the goal states that we have regenerated\n",
    "    goal_regeneration_dict = {}\n",
    "    \n",
    "    #we identify all the fluents that are in the goal state list    \n",
    "    all_goal_fluents = []\n",
    "    for goal_state in goal_state_list:\n",
    "        for fluent in goal_state:\n",
    "            if fluent not in all_goal_fluents:\n",
    "                all_goal_fluents.append(fluent)\n",
    "    \n",
    "    #we identify all the fluents that are not in the base goal state but are in the goal state list\n",
    "    non_base_goal_fluents = []\n",
    "    for fluent in all_goal_fluents:\n",
    "        if fluent not in base_goal_state:\n",
    "            non_base_goal_fluents.append(fluent)\n",
    "    \n",
    "    #starting recognizability\n",
    "    running_recognizability = compute_recognizability(base_goal_state, [base_goal_state] + goal_state_list)\n",
    "    #print(f\"Starting recognizability: {running_recognizability}, range is {recognizability}\")\n",
    "    \n",
    "    #while the recognizability is not in the target range, we will keep adapting the goal state list\n",
    "    while running_recognizability < rec_target[0] or running_recognizability > rec_target[1]:\n",
    "        #print(f\"Running recognizability start of step: {running_recognizability}, range is {rec_target}\")\n",
    "        \n",
    "        #choose a random goal state from the list\n",
    "        goal_state = random.choice(goal_state_list)\n",
    "        \n",
    "        if running_recognizability > rec_target[1]:\n",
    "            #rec too high: find a goal state in goal_state_list that has a fluent that is not in the base goal state\n",
    "            #swap it with one from base_goal_fluents                \n",
    "            \n",
    "            #builds list of fluents that are in the base goal state but not in this goal state and don't introduce inconsistencies\n",
    "            usable_base_goal_fluents = []\n",
    "            for fluent in base_goal_state:  \n",
    "                if check_if_fluent_is_usable(fluent, goal_state):\n",
    "                    usable_base_goal_fluents.append(fluent)\n",
    "                            \n",
    "            if len(usable_base_goal_fluents) > 0:                \n",
    "                \n",
    "                #builds list of fluents that are in the goal state but not in the base goal state\n",
    "                candidates_list = []\n",
    "                for fluent in goal_state:\n",
    "                    if fluent not in base_goal_state:\n",
    "                        candidates_list.append(fluent)\n",
    "                \n",
    "                fluent_from_base_goal = random.choice(usable_base_goal_fluents)\n",
    "                \n",
    "                store_candidates_list = candidates_list.copy()\n",
    "                \n",
    "                #if there is at least one fluent to swap   \n",
    "                if len(candidates_list) > 0:\n",
    "                    \n",
    "                    #we will do a while sequence to find a swap that does not introduce inconsistencies, creates duplicates or is already satisfied in the initial state\n",
    "                    while True:\n",
    "                        \n",
    "                        # debug_goal_state = goal_state.copy() #debug\n",
    "                        \n",
    "                        if len(candidates_list) > 0:\n",
    "                            random_fluent = random.choice(candidates_list)\n",
    "                        else:\n",
    "                            break\n",
    "                        \n",
    "                        # before = check_consistency(goal_state) #debug\n",
    "                        \n",
    "                        #we create what the state list will look like after the swap\n",
    "                        proposed_goal_state = goal_state.copy()\n",
    "                        proposed_goal_state_list = goal_state_list.copy()\n",
    "                        proposed_goal_state_list[proposed_goal_state_list.index(goal_state)] = proposed_goal_state\n",
    "                        \n",
    "                        proposed_goal_state[proposed_goal_state.index(random_fluent)] = fluent_from_base_goal\n",
    "                        \n",
    "                        #then check if it's ok\n",
    "                        if not check_duplicates(proposed_goal_state_list) and not check_if_goal_state_in_init(initial_state, proposed_goal_state):\n",
    "                            break\n",
    "                        else:\n",
    "                            #if it's not we cannot use this candidate with this fluent\n",
    "                            candidates_list.remove(random_fluent)\n",
    "                            if len(candidates_list) == 0:\n",
    "                                #if we finish the candidates we reset the list and try another usable fluent\n",
    "                                candidates_list = store_candidates_list.copy()\n",
    "                                usable_base_goal_fluents.remove(fluent_from_base_goal)\n",
    "                                if len(usable_base_goal_fluents) == 0:\n",
    "                                    #print(f\"Candidate list is empty because of duplicates, no fluent from base goal is applicable breaking\") # debug\n",
    "                                    break\n",
    "                                else:\n",
    "                                    fluent_from_base_goal = random.choice(usable_base_goal_fluents)\n",
    "                    \n",
    "                    #if all is fine we make the swap in the list                             \n",
    "                    goal_state_list[goal_state_list.index(goal_state)] = proposed_goal_state \n",
    "                    # after = check_consistency(goal_state) #debug\n",
    "                    # if before == True and after == False: #debug\n",
    "                    #     print(f\"|>|Goal state is not consistent: old goal state{debug_goal_state}\\n\\t base_goal_state: {base_goal_state},\\n\\t fluent_to_swap: {fluent_to_swap},\\n\\t random_fluent: {random_fluent}, \\n\\t usable_base_goal_fluents: {usable_base_goal_fluents}\\n\\n\") #debug\n",
    "                                    \n",
    "        elif running_recognizability < rec_target[0]:\n",
    "            #rec too low: choose a goal state that has a fluent from base goal and swap it with a random one\n",
    "            \n",
    "            #builds list of fluents that are in the base goal state and also in this goal state\n",
    "            present_base_goal_fluents = []\n",
    "            for fluent in base_goal_state:\n",
    "                if fluent in goal_state:\n",
    "                    present_base_goal_fluents.append(fluent)\n",
    "            \n",
    "            #if there is at least one fluent to swap                    \n",
    "            if len(present_base_goal_fluents) > 0:\n",
    "                \n",
    "                #builds list of fluents that are in the goal state but not in the base goal state, and don't introduce inconsistencies\n",
    "                # candidates_list = []\n",
    "                # for fluent in non_base_goal_fluents:\n",
    "                #     if check_if_fluent_is_usable(fluent, goal_state):\n",
    "                #         candidates_list.append(fluent)\n",
    "                \n",
    "                #build list of possible fluents to use in the swap\n",
    "                candidates_list = expand_candidates_list(goal_state, base_goal_state, package_for_goal_set, pos_for_goal_set)\n",
    "                \n",
    "                #if there is at least one fluent to swap\n",
    "                if len(candidates_list) > 0:\n",
    "                    \n",
    "                    #we will do a while sequence to find a swap that does not introduce inconsistencies, creates duplicates or is already satisfied in the initial state\n",
    "                    while True:\n",
    "                        random_fluent = random.choice(candidates_list)\n",
    "\n",
    "                        fluent_to_swap = random.choice(present_base_goal_fluents)\n",
    "                        \n",
    "                        #we create what the state list will look like after the swap\n",
    "                        proposed_goal_state = goal_state.copy()\n",
    "                        proposed_goal_state_list = goal_state_list.copy()\n",
    "                        proposed_goal_state_list[proposed_goal_state_list.index(goal_state)] = proposed_goal_state\n",
    "                        \n",
    "                        proposed_goal_state[proposed_goal_state.index(fluent_to_swap)] = random_fluent\n",
    "                        \n",
    "                        #then check if it's ok\n",
    "                        if not check_duplicates(proposed_goal_state_list) and not check_if_goal_state_in_init(initial_state, proposed_goal_state):\n",
    "                            break\n",
    "                        else:\n",
    "                            #if it's not we try another candidate\n",
    "                            candidates_list.remove(random_fluent)\n",
    "                            if len(candidates_list) == 0:\n",
    "                                #print(f\"Candidate list is empty because of duplicates, breaking\") # debug\n",
    "                                break\n",
    "                        #todo some method to expand canditates list if it is empty, will probably need to generate all possible fluents\n",
    "                        \n",
    "                    # before = check_consistency(goal_state) #debug\n",
    "                    \n",
    "                    #we apply the swap\n",
    "                    goal_state_list[goal_state_list.index(goal_state)] = proposed_goal_state\n",
    "                    # after = check_consistency(goal_state) #debug\n",
    "                    # if before == True and after == False: #debug\n",
    "                    #     print(f\"|<| Goal state is not consistent: {goal_state}\\n\\t base_goal_state: {base_goal_state},\\n\\t fluent_to_swap: {fluent_to_swap},\\n\\t random_fluent: {random_fluent}\\n\\n\") #debug\n",
    "                    \n",
    "        #compute the recognizability after the step\n",
    "        new_recognizability = compute_recognizability(base_goal_state, [base_goal_state] + goal_state_list)\n",
    "        # Store the regeneration (the key is the recognizability of the prevoius configuration)\n",
    "        goal_regeneration_dict[running_recognizability] = goal_state_list.copy()\n",
    "        #if we have not changed the recognizability, the randomness patience is reduced\n",
    "        #we will try another random goal state in the next iteration \n",
    "        if new_recognizability == running_recognizability:\n",
    "            randomness_patience -= 1\n",
    "            \n",
    "            #if we have hit too many times stuck goal states, we will regenerate the last we encountered, so the one in this iteration\n",
    "            if randomness_patience == 0 and regeneration_patience > 0:\n",
    "                # Patience reached: regenerate stuck goal_state\n",
    "                regeneration_patience -= 1\n",
    "                randomness_patience = randomness_patience_constant\n",
    "                \n",
    "\n",
    "                #todo some way to make this not use patience and not loop forever without doing all possible combinations?s\n",
    "                duplicate_patience = 10\n",
    "                while duplicate_patience > 0:\n",
    "                    new_goal_state = generate_goal_state(initial_state, package_for_goal_set, pos_for_goal_set, number_of_goals)\n",
    "                    \n",
    "                    proposed_goal_state_list = goal_state_list.copy()\n",
    "                    proposed_goal_state_list[proposed_goal_state_list.index(goal_state)] = new_goal_state\n",
    "                    if not check_duplicates(proposed_goal_state_list):\n",
    "                        break\n",
    "                    else:\n",
    "                        duplicate_patience -= 1\n",
    "                        if duplicate_patience == 0:\n",
    "                            #print(f\"Duplicate patience exhausted, breaking\") # debug\n",
    "                            break\n",
    "            \n",
    "                # Replace the goal state in the list with a new one\n",
    "                goal_state = new_goal_state\n",
    "            \n",
    "            #if we have exhausted the regeneration patience, we will stop trying and take the best configuration we have\n",
    "            elif randomness_patience == 0 and regeneration_patience == 0:\n",
    "                # Patience exhausted; if we have any regenerations, choose the one with recognizability closest to target.\n",
    "                if goal_regeneration_dict:\n",
    "                    # Find the closest recognizability to the target\n",
    "                    # must use midpoint as we could heve rec_scores both above and below the target\n",
    "                    target_recognizability = (rec_target[0] + rec_target[1]) / 2 \n",
    "                    \n",
    "                    #? if we need to restrict certain type of rec implement these lines\n",
    "                    # while True:\n",
    "                    #     closest_recognizability = min(goal_regeneration_dict.keys(), key=lambda x: abs(x - target_recognizability))\n",
    "                    #     #we do not want any problem with rec == 1 or 0, hard coded not to accept \n",
    "                    #     if closest_recognizability == 1 or closest_recognizability == 0:\n",
    "                    #         goal_regeneration_dict.pop(closest_recognizability)\n",
    "                    #     else:\n",
    "                    #         break\n",
    "                    #? else use only this\n",
    "                    closest_recognizability = min(goal_regeneration_dict.keys(), key=lambda x: abs(x - target_recognizability))\n",
    "                    #?\n",
    "                    \n",
    "                    running_recognizability = closest_recognizability\n",
    "                    goal_state_list = goal_regeneration_dict[closest_recognizability]\n",
    "                #print(f\"Patience exhausted, breaking: Best recognizability: {running_recognizability} | Target: {rec_target}\") # debug\n",
    "\n",
    "                # to keep track of errors we do the distace to the target range\n",
    "                error = abs(running_recognizability - rec_target[0]) if running_recognizability < rec_target[0] else abs(running_recognizability - rec_target[1])\n",
    "                running_sum_rec_error += error\n",
    "                global_counter += 1\n",
    "                break\n",
    "        #print(f\"Running recognizability at end of step: {running_recognizability}\")\n",
    "        running_recognizability = new_recognizability\n",
    "    return base_goal_state, goal_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad92ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRProblem:\n",
    "    def __init__(self, name, base_plan, obj_set_dict, base_goal_state, goal_state_list, rec, rec_class=[0,1]):\n",
    "        \n",
    "        self.name = name\n",
    "        self.og_plan = base_plan\n",
    "        self.problem_name = name\n",
    "        # self.actions = base_plan.actions # we don't need as they are the old ones\n",
    "        self.objects = obj_set_dict\n",
    "        self.initial_state = base_plan.initial_state\n",
    "        self.base_goal_state = base_goal_state\n",
    "        self.goal_state_list = goal_state_list\n",
    "        self.recognizability_class = rec_class\n",
    "        self.recognizability = rec\n",
    "    \n",
    "    def __str__(self):\n",
    "        description = f\"Problem: {self.problem_name}, \\n\\tGoals: {self.base_goal_state}, \\n\\t\"\n",
    "        for i, goal_state in enumerate(self.goal_state_list):\n",
    "            description += f\"Goal state {i}: {goal_state}, \\n\\t\"\n",
    "        description += f\"Recognizability: {self.recognizability}, Class: {self.recognizability_class}\"\n",
    "\n",
    "        return description\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99726741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test check_duplicates\n",
    "# goal_state_list = [[\"a\", \"b\"], \n",
    "#                    [\"a\", \"b\"], \n",
    "#                    [\"g\", \"h\"],\n",
    "#                    [\"f\", \"i\"],\n",
    "#                    [\"a\", \"b\", \"c\"],]\n",
    "\n",
    "# print(check_duplicates(goal_state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d220c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(plans, versions_per_plan, rec_classes):\n",
    "    gr_problems_list = []\n",
    "    #duplicate_couter = 0\n",
    "    count = 0\n",
    "    for plan in plans:\n",
    "        if test:\n",
    "            if count >= 3:\n",
    "                break\n",
    "        elif count > plans_to_process:\n",
    "            break\n",
    "        #begin plan processing\n",
    "        \n",
    "        number_of_goals = len(plan.goals)\n",
    "        \n",
    "        all_obj_set = set()\n",
    "        package_for_goal_set = set()\n",
    "        pos_for_goal_set = set()\n",
    "        \n",
    "        #* find all objects in the initial state and actions\n",
    "        for line in plan.initial_state:\n",
    "            for obj in line.split(\" \")[1:]:\n",
    "                all_obj_set.add(obj)\n",
    "        for action in plan.actions:\n",
    "            for fluent in action.positiveEffects:\n",
    "                for obj in fluent.split(\" \")[1:]:\n",
    "                    all_obj_set.add(obj)\n",
    "            for fluent in action.negativeEffects:\n",
    "                for obj in fluent.split(\" \")[1:]:\n",
    "                    all_obj_set.add(obj)\n",
    "            for fluent in action.precondition:\n",
    "                for obj in fluent.split(\" \")[1:]:\n",
    "                    all_obj_set.add(obj)\n",
    "        \n",
    "        #split the objects in their types\n",
    "        pos_set = set()\n",
    "        apn_set = set()\n",
    "        cit_set = set()\n",
    "        apt_set = set()\n",
    "        tru_set = set()\n",
    "        pack_set = set()\n",
    "        obj_set_dict = {}\n",
    "        for obj in all_obj_set:\n",
    "            if obj.startswith(\"pos\"):\n",
    "                pos_set.add(obj)\n",
    "                pos_for_goal_set.add(obj) #these will be used for goal creation\n",
    "            elif obj.startswith(\"obj\"):\n",
    "                pack_set.add(obj)\n",
    "                package_for_goal_set.add(obj) #these will be used for goal creation\n",
    "            elif obj.startswith(\"apn\"):\n",
    "                apn_set.add(obj)\n",
    "            elif obj.startswith(\"cit\"):\n",
    "                cit_set.add(obj)\n",
    "            elif obj.startswith(\"tru\"):\n",
    "                tru_set.add(obj)\n",
    "            elif obj.startswith(\"apt\"):\n",
    "                apt_set.add(obj)\n",
    "        \n",
    "        #useful for printing the plan\n",
    "        if len(pos_set) > 0:\n",
    "            obj_set_dict[\"location\"] = pos_set\n",
    "        if len(apn_set) > 0:\n",
    "            obj_set_dict[\"airplane\"] = apn_set\n",
    "        if len(cit_set) > 0:\n",
    "            obj_set_dict[\"city\"] = cit_set\n",
    "        if len(apt_set) > 0:\n",
    "            obj_set_dict[\"airport\"] = apt_set\n",
    "        if len(tru_set) > 0:\n",
    "            obj_set_dict[\"truck\"] = tru_set\n",
    "        if len(pack_set) > 0:\n",
    "            obj_set_dict[\"package\"] = pack_set\n",
    "        \n",
    "        # raise an exception if number of goals > number of packages or positions\n",
    "        # as we won't be able to generate a goal state with the given number of goals\n",
    "        if number_of_goals > len(package_for_goal_set):\n",
    "            raise exception(f\"Number of goals {number_of_goals} is greater than the number of objects {len(package_for_goal_set)}\")\n",
    "\n",
    "        # in case we want that objects can not be at the same position\n",
    "        # if number_of_goals > len(pos_for_goal_set):\n",
    "        #     raise exception(f\"Number of goals {number_of_goals} is greater than the number of positions {len(pos_for_goal_set)}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        for interval in rec_classes:    \n",
    "            goal_state_list = create_goal_state_list(initial_state=plan.initial_state, package_for_goal_set=package_for_goal_set, \n",
    "                                                    pos_for_goal_set=pos_for_goal_set, \n",
    "                                                    number_of_goals=number_of_goals, \n",
    "                                                    versions_per_plan=versions_per_plan)\n",
    "            \n",
    "            # for goal_state in goal_state_list: # debug\n",
    "            #     #check if any goal state has conflicting fluents # debug\n",
    "            #     for fluent1 in goal_state: # debug\n",
    "            #         for fluent2 in goal_state: # debug\n",
    "            #             if fluent1 != fluent2 and check_same_object_in_fluents(fluent1, fluent2): # debug\n",
    "            #                 raise exception(f\"Goal state {goal_state} has conflicting fluents: {fluent1} and {fluent2}\") # debug\n",
    "            \n",
    "            #print(f\"Goals state list before: {goal_state_list}\") # debug\n",
    "            \n",
    "            #we generate problem and its versions, we keep the original goals\n",
    "            base_goal_state, adapted_goal_state_list = adapt_goal_state_list_to_recognizability(initial_state=plan.initial_state, \n",
    "                                                                                                base_goal_state=plan.goals,         \n",
    "                                                                                                goal_state_list=goal_state_list[1:], \n",
    "                                                                                                package_for_goal_set=package_for_goal_set, pos_for_goal_set=pos_for_goal_set, \n",
    "                                                                                                number_of_goals=number_of_goals, rec_target=interval, \n",
    "                                                                                                randomness_patience=25, \n",
    "                                                                                                regeneration_patience=15)\n",
    "            #print(f\"Goals state list after adapt: {[base_goal_state] + adapted_goal_state_list}\") # debug\n",
    "            \n",
    "            name = re.search(r\"(p\\d+)(?=\\.)\", plan.plan_name).group(1)\n",
    "\n",
    "            new_gr_problem = GRProblem(name=name, base_plan=plan, obj_set_dict=obj_set_dict, base_goal_state=base_goal_state, \n",
    "                                    goal_state_list=adapted_goal_state_list, \n",
    "                                    rec=compute_recognizability(base_goal_state, [base_goal_state] + adapted_goal_state_list),\n",
    "                                    rec_class=interval)\n",
    "            gr_problems_list.append(new_gr_problem) \n",
    "            #checking duplicates, debug\n",
    "            #if check_duplicates(adapted_goal_state_list):\n",
    "            #    duplicate_couter += 1\n",
    "            #    #print(f\"new gr_problem has duplicates: {new_gr_problem}\")\n",
    "        count = count + 1\n",
    "        #print(f\"Process {count} plans\") #debug\n",
    "    return gr_problems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd87d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_dataset(gr_problems_list):\n",
    "    duplicate_counter = 0\n",
    "    running_sum_rec_error = 0\n",
    "    error_counter = 0\n",
    "    for problem in gr_problems_list:\n",
    "        if check_duplicates(problem.goal_state_list):\n",
    "            duplicate_counter += 1\n",
    "        if (\n",
    "            problem.recognizability > problem.recognizability_class[1]\n",
    "            or problem.recognizability < problem.recognizability_class[0]\n",
    "        ):\n",
    "            error_counter += 1\n",
    "            error = (\n",
    "                abs(problem.recognizability - problem.recognizability_class[0])\n",
    "                if problem.recognizability < problem.recognizability_class[0]\n",
    "                else abs(problem.recognizability - problem.recognizability_class[1])\n",
    "            )\n",
    "            running_sum_rec_error += error\n",
    "    print(\"Error counter:\", error_counter)\n",
    "    print(\"Running sum of recognizability error:\", running_sum_rec_error)\n",
    "    print(\n",
    "        \"Average recognizability generation error:\",\n",
    "        running_sum_rec_error / error_counter if error_counter > 0 else 0,\n",
    "    )\n",
    "    print(\n",
    "        \"Average recognizability generation error on whole dataset:\",\n",
    "        running_sum_rec_error / (plans_to_process * versions_per_plan),\n",
    "    )\n",
    "\n",
    "    print(\"Duplicate counter:\", duplicate_counter)\n",
    "    print(\"Duplicate percent: %\", duplicate_counter / len(gr_problems_list) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c334c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting dataset 0:\n",
      "Error counter: 13\n",
      "Running sum of recognizability error: 0.5699999999999998\n",
      "Average recognizability generation error: 0.04384615384615383\n",
      "Average recognizability generation error on whole dataset: 1.1399999999999998e-05\n",
      "Duplicate counter: 3183\n",
      "Duplicate percent: % 6.365363463653635\n",
      "\n",
      "Starting dataset 1:\n",
      "Error counter: 12\n",
      "Running sum of recognizability error: 0.6599999999999999\n",
      "Average recognizability generation error: 0.05499999999999999\n",
      "Average recognizability generation error on whole dataset: 1.3199999999999999e-05\n",
      "Duplicate counter: 3197\n",
      "Duplicate percent: % 6.393360663933606\n",
      "\n",
      "Starting dataset 2:\n",
      "Error counter: 16\n",
      "Running sum of recognizability error: 1.3133\n",
      "Average recognizability generation error: 0.08208125\n",
      "Average recognizability generation error on whole dataset: 2.6266e-05\n",
      "Duplicate counter: 3197\n",
      "Duplicate percent: % 6.393360663933606\n",
      "\n",
      "Starting dataset 3:\n",
      "Error counter: 22\n",
      "Running sum of recognizability error: 0.94\n",
      "Average recognizability generation error: 0.042727272727272725\n",
      "Average recognizability generation error on whole dataset: 1.88e-05\n",
      "Duplicate counter: 3271\n",
      "Duplicate percent: % 6.541345865413459\n",
      "\n",
      "Starting dataset 4:\n",
      "Error counter: 14\n",
      "Running sum of recognizability error: 0.94\n",
      "Average recognizability generation error: 0.06714285714285714\n",
      "Average recognizability generation error on whole dataset: 1.88e-05\n",
      "Duplicate counter: 3334\n",
      "Duplicate percent: % 6.6673332666733325\n",
      "\n",
      "Starting dataset 5:\n",
      "Error counter: 17\n",
      "Running sum of recognizability error: 1.2033000000000003\n",
      "Average recognizability generation error: 0.07078235294117649\n",
      "Average recognizability generation error on whole dataset: 2.4066000000000006e-05\n",
      "Duplicate counter: 3261\n",
      "Duplicate percent: % 6.521347865213478\n",
      "\n",
      "Starting dataset 6:\n",
      "Error counter: 17\n",
      "Running sum of recognizability error: 1.1400000000000001\n",
      "Average recognizability generation error: 0.06705882352941177\n",
      "Average recognizability generation error on whole dataset: 2.2800000000000002e-05\n",
      "Duplicate counter: 3337\n",
      "Duplicate percent: % 6.673332666733327\n",
      "\n",
      "Starting dataset 7:\n",
      "Error counter: 6\n",
      "Running sum of recognizability error: 0.31000000000000005\n",
      "Average recognizability generation error: 0.05166666666666667\n",
      "Average recognizability generation error on whole dataset: 6.200000000000001e-06\n",
      "Duplicate counter: 3185\n",
      "Duplicate percent: % 6.369363063693631\n",
      "\n",
      "Starting dataset 8:\n",
      "Error counter: 15\n",
      "Running sum of recognizability error: 1.02\n",
      "Average recognizability generation error: 0.068\n",
      "Average recognizability generation error on whole dataset: 2.04e-05\n",
      "Duplicate counter: 3279\n",
      "Duplicate percent: % 6.557344265573442\n",
      "\n",
      "Starting dataset 9:\n",
      "Error counter: 21\n",
      "Running sum of recognizability error: 1.4800000000000002\n",
      "Average recognizability generation error: 0.07047619047619048\n",
      "Average recognizability generation error on whole dataset: 2.9600000000000005e-05\n",
      "Duplicate counter: 3291\n",
      "Duplicate percent: % 6.581341865813418\n",
      "Problem: p046760, \n",
      "\tGoals: ['at obj33 pos66', 'at obj13 pos13', 'at obj23 pos55'], \n",
      "\tGoal state 0: ['at obj88 pos44', 'at obj55 pos23', 'at obj00 pos33'], \n",
      "\tGoal state 1: ['at obj00 pos21', 'at obj88 pos21', 'at obj12 pos55'], \n",
      "\tGoal state 2: ['at obj66 pos11', 'at obj44 pos22', 'at obj23 pos22'], \n",
      "\tGoal state 3: ['at obj13 pos66', 'at obj23 pos55', 'at obj33 pos66'], \n",
      "\tGoal state 4: ['at obj23 pos55', 'at obj00 pos66', 'at obj11 pos11'], \n",
      "\tRecognizability: 0.5333, Class: [0.4, 0.6]\n",
      "Problem: p046760, \n",
      "\tGoals: ['at obj33 pos66', 'at obj13 pos13', 'at obj23 pos55'], \n",
      "\tGoal state 0: ['at obj00 pos11', 'at obj13 pos13', 'at obj55 pos23'], \n",
      "\tGoal state 1: ['at obj88 pos66', 'at obj55 pos33', 'at obj13 pos23'], \n",
      "\tGoal state 2: ['at obj23 pos44', 'at obj12 pos66', 'at obj33 pos21'], \n",
      "\tGoal state 3: ['at obj55 pos11', 'at obj23 pos55', 'at obj00 pos23'], \n",
      "\tGoal state 4: ['at obj00 pos11', 'at obj12 pos66', 'at obj44 pos21'], \n",
      "\tRecognizability: 0.6, Class: [0.4, 0.6]\n",
      "Problem: p046760, \n",
      "\tGoals: ['at obj33 pos66', 'at obj13 pos13', 'at obj23 pos55'], \n",
      "\tGoal state 0: ['at obj66 pos55', 'at obj55 pos44', 'at obj33 pos66'], \n",
      "\tGoal state 1: ['at obj12 pos66', 'at obj55 pos33', 'at obj88 pos55'], \n",
      "\tGoal state 2: ['at obj13 pos13', 'at obj33 pos66', 'at obj55 pos13'], \n",
      "\tGoal state 3: ['at obj11 pos66', 'at obj23 pos33', 'at obj55 pos44'], \n",
      "\tGoal state 4: ['at obj55 pos33', 'at obj33 pos44', 'at obj12 pos23'], \n",
      "\tRecognizability: 0.5333, Class: [0.4, 0.6]\n"
     ]
    }
   ],
   "source": [
    "dataset_iterations = 10\n",
    "gr_problem_dict = {}\n",
    "for t in range(0, dataset_iterations):\n",
    "    print(f\"\\nStarting dataset {t}:\")\n",
    "    gr_problems_list = generate_dataset(plans=plans, versions_per_plan=versions_per_plan, rec_classes=rec_classes)\n",
    "    # print(\"gr_problems_list:\")\n",
    "\n",
    "    analyse_dataset(gr_problems_list)\n",
    "\n",
    "    gr_problem_dict[t] = gr_problems_list\n",
    "\n",
    "\n",
    "\n",
    "#check if we have same thing in same orders\n",
    "print(gr_problem_dict[2][2])\n",
    "print(gr_problem_dict[1][2])\n",
    "print(gr_problem_dict[3][2])\n",
    "\n",
    "# runtime with 10k plans\n",
    "#expected runtime at 50k about 30 min\n",
    "#duplicates about 5% per run, after intersection we have 0.13%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f116a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error counter: 0\n",
      "Running sum of recognizability error: 0\n",
      "Average recognizability generation error: 0\n",
      "Average recognizability generation error on whole dataset: 0.0\n",
      "Duplicate counter: 6\n",
      "Duplicate percent: % 0.06\n"
     ]
    }
   ],
   "source": [
    "# todo check again this\n",
    "\n",
    "\n",
    "# we want as little as possible duplicates, so we generate the dataset N times \n",
    "# then we see if we can intersect them into a single dataset, if we have more than one candidate we take the one closer to target rec class\n",
    "# these could be easily modified to expand the dataset, \n",
    "# we could instead of taking original goal state, generate a random one also there, keeping only number of fluent in goal the same\n",
    "final_gr_problem_list = []\n",
    "for i in range(0, plans_to_process):\n",
    "    versions = []\n",
    "    candidates = []\n",
    "    for j in range(0, 5):\n",
    "        versions.append(gr_problem_dict[j][i])\n",
    "        \n",
    "    for problem in versions:\n",
    "        if not check_duplicates(problem.goal_state_list):\n",
    "            candidates.append(problem)\n",
    "\n",
    "    if candidates == []:\n",
    "        candidates = versions\n",
    "\n",
    "    candidates_error_dict = {}\n",
    "    \n",
    "    target = (versions[0].recognizability_class[1]+versions[0].recognizability_class[0])/2\n",
    "    for problem in candidates:\n",
    "        error = error = (\n",
    "            abs(problem.recognizability - target)\n",
    "            )\n",
    "        candidates_error_dict[error] = problem\n",
    "        \n",
    "    min_error_problem = candidates_error_dict[min(candidates_error_dict.keys())]\n",
    "    final_gr_problem_list.append(min_error_problem)\n",
    "\n",
    "analyse_dataset(final_gr_problem_list)\n",
    "\n",
    "#todo\n",
    "#drop_duplicates(final_gr_problem_list)\n",
    "#todo\n",
    "\n",
    "#todo\n",
    "#drop_errors(final_gr_problem_list)\n",
    "#todo\n",
    "\n",
    "# error still high when it happens, happens less, maybe duplicates introduced error because they were stuck, duplicates are pretty much insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95007ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodology test for searching already resolved goals in init\n",
    "# base_goal = [\"f1\", \"f10\", \"f3\"]\n",
    "\n",
    "# init = [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"]\n",
    "\n",
    "    \n",
    "    \n",
    "# base_goal_present_in_init = True\n",
    "# for base_goal_fluent in base_goal:\n",
    "#     if base_goal_fluent in init:\n",
    "#         print(base_goal_fluent)\n",
    "#         continue\n",
    "#     else:\n",
    "#         base_goal_present_in_init = False\n",
    "#         break\n",
    "\n",
    "# if base_goal_present_in_init:\n",
    "#     print(f\"Base Goal present in init: {base_goal} \\n Problem init: {init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "354c3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem p036207\n",
      "Version Goal present in init: ['at obj21 pos77', 'at obj00 pos23'] \n",
      " Problem init: ['at tru4 pos77', 'at tru1 pos12', 'at obj99 pos23', 'at obj21 pos77', 'at obj00 pos23', 'at obj22 pos11', 'at obj66 pos21', 'at obj88 pos12', 'at apn5 apt5', 'at apn7 apt3']\n",
      "Problem p018924\n",
      "Version Goal present in init: ['at obj44 pos44', 'at obj12 pos23'] \n",
      " Problem init: ['at tru4 pos44', 'at tru2 pos12', 'at obj33 pos55', 'at obj12 pos23', 'at obj11 pos44', 'at obj44 pos44', 'at obj55 pos55', 'at obj23 pos55', 'at apn4 apt4']\n",
      "Problem p011409\n",
      "Version Goal present in init: ['at obj44 pos77', 'at obj55 pos12'] \n",
      " Problem init: ['at tru2 pos13', 'at tru5 pos44', 'at obj11 pos22', 'at obj22 pos44', 'at obj66 pos77', 'at obj55 pos12', 'at obj44 pos77', 'at obj21 pos12', 'at apn7 apt3']\n",
      "Original goal state that are already true in init: False (0.0%)\n",
      "Versions goal state that are already true in init: 3 (0.006 %)\n"
     ]
    }
   ],
   "source": [
    "base_goal_in_init_counter = 0\n",
    "versions_goals_in_init_counter = 0\n",
    "\n",
    "for problem in final_gr_problem_list:\n",
    "    base_goal_present_in_init = True\n",
    "    for base_goal_fluent in problem.og_plan.goals:\n",
    "        # print(base_goal_fluent)\n",
    "        # print(problem.og_plan.initial_state)\n",
    "        if base_goal_fluent in problem.og_plan.initial_state:\n",
    "            continue\n",
    "        else:\n",
    "            base_goal_present_in_init = False\n",
    "            break\n",
    "    \n",
    "    if base_goal_present_in_init:\n",
    "        base_goal_in_init_counter += 1\n",
    "        print(f\"Base Goal present in init: {problem.base_goal_state} \\n Problem init: {problem.og_plan.initial_state}\")\n",
    "        \n",
    "    for goal_state in problem.goal_state_list:\n",
    "        version_goal_present_in_init = True\n",
    "        for goal_fluent in goal_state:\n",
    "            if goal_fluent in problem.og_plan.initial_state:\n",
    "                # print(f\"Partial match: {goal_state} \\n Problem init: {problem.og_plan.initial_state}\")\n",
    "                continue\n",
    "            else:\n",
    "                version_goal_present_in_init = False\n",
    "        if version_goal_present_in_init:\n",
    "            print(f\"Problem {problem.name}\")\n",
    "            print(f\"Version Goal present in init: {goal_state} \\n Problem init: {problem.og_plan.initial_state}\")\n",
    "            versions_goals_in_init_counter += 1\n",
    "\n",
    "perc = round((base_goal_present_in_init/len(gr_problems_list)*100),3)\n",
    "print(f\"Original goal state that are already true in init: {base_goal_present_in_init} ({perc}%)\")\n",
    "\n",
    "perc = round((versions_goals_in_init_counter/len(gr_problems_list)*100),3)\n",
    "print(f\"Versions goal state that are already true in init: {versions_goals_in_init_counter} ({perc} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b670b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem dropped: p053197,[0, 0.2]\n",
      "Problem dropped: p014152,[0, 0.2]\n",
      "Problem dropped: p009684,[0, 0.2]\n",
      "Problem dropped: p031341,[0, 0.2]\n",
      "Problem dropped: p052302,[0, 0.2]\n",
      "Problem dropped: p001795,[0, 0.2]\n",
      "Dropped: 10000-9994 = 6(0.06%)\n"
     ]
    }
   ],
   "source": [
    "begin_len = len(final_gr_problem_list)\n",
    "\n",
    "final_gr_problem_list_after_drop = []\n",
    "for problem in final_gr_problem_list:\n",
    "    if check_duplicates(problem.goal_state_list):\n",
    "        print(f\"Problem dropped: {problem.name},{problem.recognizability_class}\")\n",
    "        continue\n",
    "    elif (\n",
    "        problem.recognizability > problem.recognizability_class[1]\n",
    "        or problem.recognizability < problem.recognizability_class[0]\n",
    "    ):\n",
    "        continue\n",
    "    else:\n",
    "        version_goal_present_in_init = True\n",
    "        for goal_state in problem.goal_state_list:\n",
    "            for goal_fluent in goal_state:\n",
    "                if goal_fluent in problem.og_plan.initial_state:\n",
    "                    # print(f\"Partial match: {goal_state} \\n Problem init: {problem.og_plan.initial_state}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    version_goal_present_in_init = False\n",
    "        if not version_goal_present_in_init:\n",
    "            final_gr_problem_list_after_drop.append(problem)                \n",
    "end_len = len(final_gr_problem_list_after_drop)\n",
    "\n",
    "\n",
    "diff = begin_len - end_len\n",
    "perc = diff/begin_len*100\n",
    "print(f\"Dropped: {begin_len}-{end_len} = {diff}({perc}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe04770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniformly sampled problems (initial): 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# First, deduplicate problems by name so that each problem (from the same plan) appears only once\n",
    "\n",
    "problem_groups = defaultdict(list)\n",
    "for problem in final_gr_problem_list_after_drop:\n",
    "    problem_groups[problem.name].append(problem)\n",
    "\n",
    "unique_problems = {name: random.choice(problems) for name, problems in problem_groups.items()}\n",
    "\n",
    "# Group unique problems by recognizability class (using tuple of bounds as key)\n",
    "problems_by_class = defaultdict(list)\n",
    "for problem in unique_problems.values():\n",
    "    rec_class_key = tuple(problem.recognizability_class)\n",
    "    problems_by_class[rec_class_key].append(problem)\n",
    "\n",
    "# Number of recognizability classes, assuming rec_classes defined in cell 1\n",
    "num_classes = len(rec_classes)\n",
    "desired_per_class = 1000 // num_classes\n",
    "\n",
    "uniform_problems = []\n",
    "for rec_class_key, problems in problems_by_class.items():\n",
    "    if len(problems) >= desired_per_class:\n",
    "        uniform_problems.extend(random.sample(problems, desired_per_class))\n",
    "    else:\n",
    "        uniform_problems.extend(problems)\n",
    "        \n",
    "\n",
    "print(\"Uniformly sampled problems (initial):\", len(uniform_problems))\n",
    "\n",
    "# If the total is less than 1000, fill with additional problems randomly from the remaining ones\n",
    "if len(uniform_problems) < 1000:\n",
    "    remaining = 1000 - len(uniform_problems)\n",
    "    remaining_pool = [p for p in final_gr_problem_list_after_drop if p not in uniform_problems]\n",
    "    if remaining_pool:\n",
    "        extra = random.sample(remaining_pool, min(remaining, len(remaining_pool)))\n",
    "        uniform_problems.extend(extra)\n",
    "    print(\"After extra sampling, total problems:\", len(uniform_problems))\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build a distribution dictionary with keys as \"low-high\" strings for each recognizability class\n",
    "distribution = {f\"{rc[0]}-{rc[1]}\": 0 for rc in rec_classes}\n",
    "for problem in uniform_problems:\n",
    "    key = f\"{problem.recognizability_class[0]}-{problem.recognizability_class[1]}\"\n",
    "    distribution[key] += 1\n",
    "\n",
    "# Plot the distribution as a bar graph\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(distribution.keys(), distribution.values(), color='skyblue')\n",
    "plt.xlabel(\"Recognizability Class Interval\")\n",
    "plt.ylabel(\"Number of Problems\")\n",
    "plt.title(\"Distribution of Recognizability Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a02283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to clear the results directory\n",
    "for folder in os.listdir(results_dir):\n",
    "    #remove directory if it exists along with its content\n",
    "    if isdir(join(results_dir, folder)):\n",
    "        shutil.rmtree(join(results_dir, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48bc279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = True\n",
    "count = 0\n",
    "\n",
    "\n",
    "#write to file all the problems\n",
    "for problem in uniform_problems:\n",
    "    # print(problem)\n",
    "    if test3:\n",
    "        if count > 600:\n",
    "            break\n",
    "    write_original_plan(plan=problem.og_plan, goal_state=problem.base_goal_state, obj_set_dict=problem.objects)\n",
    "    write_and_save_versions(\n",
    "        plan=problem.og_plan,\n",
    "        goal_state_list=problem.goal_state_list,\n",
    "        obj_set_dict=problem.objects,\n",
    "        rec_class=problem.recognizability_class,\n",
    "    )\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beebcee",
   "metadata": {},
   "source": [
    "prendere lista di problemi, dove prendere circa 1000 problemi, divisi in modo uniforme tra le classi di recognizability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9a098",
   "metadata": {},
   "source": [
    "ci aspettiamo 1000 piani nuovi + quelli originali quindi 1200, molto probabile alcuni non finiranno ma vedremo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfb5cd",
   "metadata": {},
   "source": [
    "prendere familiarità con i comandi per fare script per runnare i piani\n",
    "\n",
    "create optimal plan è quello per runnare il planner \n",
    "\n",
    "run experiment per creare script a nastro, per poi runnare tot piani in parallelo, quindi non vogliamo un mega script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc5843",
   "metadata": {},
   "source": [
    "leggere articolo e vedere se c'è qualcosa che possiamo usare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goal_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
