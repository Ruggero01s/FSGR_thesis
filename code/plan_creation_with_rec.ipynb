{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "667eec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from os.path import  join, isdir\n",
    "from plan import Plan\n",
    "from action import Action\n",
    "from utils import load_from_folder\n",
    "from multiprocess import Pool\n",
    "import random\n",
    "from logging import exception\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d761e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain dir: ../datasets/logistics/optimal_plans/dictionaries_and_plans/\n"
     ]
    }
   ],
   "source": [
    "save_dir = './new_plans/'\n",
    "data_base_dir = '../datasets/'\n",
    "domain = 'logistics'\n",
    "results_dir = f\"{save_dir}/{domain}/\"   \n",
    "source_dir = f\"{join(data_base_dir, domain)}/optimal_plans/dictionaries_and_plans/\" \n",
    "print('Domain dir:', source_dir)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "plans_to_process = 100 # number of plans to process\n",
    "versions_per_plan = 6 # number of versions per each plan\n",
    "number_of_goals = 4 # number of goals per each new plan\n",
    "test = False # test will process only 3 plans\n",
    "rec_classes = [[0,0.1], [0.1,0.2], [0.2,0.3], [0.3,0.4], [0.4,0.5], [0.5,0.6], [0.6,0.7], [0.7,0.8], [0.8,0.9], [0.9,1]] # classes of recognizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe052be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(results_dir):\n",
    "    #remove directory if it exists along with its content\n",
    "    if isdir(join(results_dir, folder)):\n",
    "        shutil.rmtree(join(results_dir, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ac5476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plans loaded from ../datasets/logistics/optimal_plans/dictionaries_and_plans/\n",
      "Plans: 47769\n"
     ]
    }
   ],
   "source": [
    "plans = load_from_folder(source_dir,[\"plans\"])[0]\n",
    "print(f\"Plans: {len(plans)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a041db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recognizability(current_goal_state, goal_state_list):\n",
    "    \"\"\"\n",
    "    Compute the difficulty of a plan.\n",
    "    :param current_goal_state: The goal state for which we calculate the recognizability.\n",
    "    :param goal_state_list: The list of goal states.\n",
    "    :return: The recognizability of the plan.\n",
    "    \"\"\"\n",
    "    \n",
    "    if current_goal_state not in goal_state_list:\n",
    "        raise ValueError(f\"current_goal_state {current_goal_state} must be included in goal_state_list {goal_state_list}\")\n",
    "    \n",
    "    #min and max to use for normalization\n",
    "    #min recognizability is when all the fluent in current are present in each goal state in the goal state list\n",
    "    #max recognizability is when all the fluent in current are not present in the goal state list\n",
    "    max_recognizability  = 1*len(current_goal_state)\n",
    "    min_recognizability  = 1/(len(goal_state_list)) * len(current_goal_state)\n",
    "    \n",
    "    # print(f\"Max recognizability : {max_recognizability}\")\n",
    "    # print(f\"Min recognizability : {min_recognizability}\")\n",
    "    \n",
    "    sum = 0\n",
    "    #need to count how many times the current goal fluent is in the goal state list\n",
    "    for current_goal_fluent in current_goal_state:\n",
    "        count = 0\n",
    "        for goal_state in goal_state_list:\n",
    "            for goal_fluent in goal_state:       \n",
    "                if current_goal_fluent==goal_fluent:\n",
    "                    count += 1\n",
    "                    break\n",
    "        sum += 1/count\n",
    "    \n",
    "    #print(f\"Unscaled recognizability: {sum}\")\n",
    "    \n",
    "    #normalize the recognizability \n",
    "    recognizability = (sum-min_recognizability) / (max_recognizability-min_recognizability)\n",
    "    \n",
    "    return recognizability\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceab2950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41666666666666663\n"
     ]
    }
   ],
   "source": [
    "#test compute_recognizability\n",
    "goal_state_list = [[\"a\", \"b\", \"c\"], \n",
    "                   [\"a\", \"k\", \"j\"], \n",
    "                   [\"a\", \"b\", \"y\"], ]\n",
    "print(compute_recognizability(goal_state_list[0], goal_state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879de6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute difficulty testing\n",
    "# current_goal_state = [6, 5, 7, 9]\n",
    "# goal_state_list = [[1, 2, 3, 4], \n",
    "#                    [1, 2, 3, 4], \n",
    "#                    [1, 2, 3, 4], \n",
    "#                    [1, 2, 3, 4], \n",
    "#                    [1, 2, 3, 4]]\n",
    "# goal_state_list.append(current_goal_state)\n",
    "# rec = compute_recognizability(current_goal_state, goal_state_list)\n",
    "# print(f\"recognizability : {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d502f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #?tried to have a way to generate the goal state list directly with a given recognizability\n",
    "    #?kinda works, but approximation is too large, and it is unncessarily complex\n",
    "    \n",
    "    #todo check code again, gpt helped with it\n",
    "    \n",
    "# import math\n",
    "\n",
    "# def approx_counts(num_of_fluents: int, num_of_states: int, r: float) -> list:\n",
    "#     \"\"\"\n",
    "#     Return a list of n integer counts in [1..m] whose reciprocals sum\n",
    "#     approximately to S = n/m + r * n*(m-1)/m.\n",
    "\n",
    "#     Strategy:\n",
    "#       1. Compute the “continuous” count c = m / (1 + r*(m-1)).\n",
    "#       2. If c is (nearly) integer, just return [round(c)]*n.\n",
    "#       3. Otherwise let b = floor(c), B = b + 1, and solve for x:\n",
    "#             x*(1/b) + (n-x)*(1/B) = S\n",
    "#          => x = (n/B - S) / (1/B - 1/b)\n",
    "#       4. Round x to the nearest integer; assign x entries = b, (n-x) = B.\n",
    "#       5. Clip to [0..n] and, if desired, do a tiny local tweak\n",
    "#          (e.g. move 1 count up/down) to reduce the residual error.\n",
    "#     \"\"\"\n",
    "#     # 1) target unscaled sum\n",
    "#     S = (num_of_fluents/num_of_states) + r * (num_of_fluents * (num_of_states-1) / num_of_states)\n",
    "\n",
    "#     # 2) continuous ideal count\n",
    "#     c = num_of_states / (1 + r*(num_of_states-1))\n",
    "#     c_round = round(c)\n",
    "#     # if it’s essentially integral, use it\n",
    "#     if abs(c_round - c) < 1e-6 or c_round in (1, num_of_states):\n",
    "#         return [c_round] * num_of_fluents\n",
    "\n",
    "#     # 3) floor / ceil\n",
    "#     b = math.floor(c)\n",
    "#     B = b + 1\n",
    "\n",
    "#     # solve x*(1/b) + (n-x)*(1/B) = S\n",
    "#     #   => x = (n/B - S) / (1/B - 1/b)\n",
    "#     denom = (1/B - 1/b)\n",
    "#     if abs(denom) < 1e-8:\n",
    "#         # degenerate; fallback to uniform\n",
    "#         return [c_round] * num_of_fluents\n",
    "\n",
    "#     x_real = (num_of_fluents/B - S) / denom\n",
    "#     x = int(round(x_real))\n",
    "\n",
    "#     # 4) clip and build\n",
    "#     x = max(0, min(num_of_fluents, x))\n",
    "#     counts = [b]*x + [B]*(num_of_fluents - x)\n",
    "\n",
    "#     # 5) (optional) tiny local corrections\n",
    "#     # compute residual error\n",
    "#     current_sum = sum(1/ci for ci in counts)\n",
    "#     # if we’re off by more than, say, 1/n, try one adjustment\n",
    "#     if abs(current_sum - S) > 1e-3:\n",
    "#         # if sum too small, we need to increase it ⇒ lower some ci by 1\n",
    "#         if current_sum < S:\n",
    "#             # find an index with ci > 1 and decrement it\n",
    "#             for i in range(num_of_fluents):\n",
    "#                 if counts[i] > 1:\n",
    "#                     counts[i] -= 1\n",
    "#                     break\n",
    "#         else:\n",
    "#             # sum too big ⇒ decrement sum ⇒ increase some ci by 1\n",
    "#             for i in range(num_of_fluents):\n",
    "#                 if counts[i] < num_of_states:\n",
    "#                     counts[i] += 1\n",
    "#                     break\n",
    "\n",
    "#     return counts\n",
    "\n",
    "\n",
    "\n",
    "# def build_goal_list(current, goal_set_list_size, counts, fillers=['a','b','c','d','e']):\n",
    "#     num_of_goal_fluents = len(current)\n",
    "#     # initialize empty slots\n",
    "#     slots = [ [] for _ in range(goal_set_list_size) ]\n",
    "#     # for each fluent, choose which rows it goes in\n",
    "#     for fluent, c in zip(current, counts):\n",
    "#         rows = random.sample(range(goal_set_list_size), c)\n",
    "#         for r in rows:\n",
    "#             slots[r].append(fluent)\n",
    "#     # fill the rest with distractors\n",
    "#     all_distractors = ['a','b','c','d','e']  # pool of non-current fluents\n",
    "#     for r in range(goal_set_list_size):\n",
    "#         while len(slots[r]) < num_of_goal_fluents:\n",
    "#             slots[r].append(random.choice(all_distractors))\n",
    "#         random.shuffle(slots[r])\n",
    "#     return slots\n",
    "\n",
    "# # Example usage:\n",
    "# current = [6,5,7,9]\n",
    "# goal_set_list_size = 6\n",
    "# # counts chosen by solving sum(1/ci)=S (approximated)\n",
    "# counts = approx_counts(len(current), goal_set_list_size, 0.47)\n",
    "# print(\"Counts:\", counts)\n",
    "# goal_list = build_goal_list(current, goal_set_list_size, counts)\n",
    "# print(\"Goal list:\")\n",
    "# for i, g in enumerate(goal_list):\n",
    "#     print(f\"Goal {i}: {g}\")\n",
    "# rec = compute_recognizability(current, goal_list)\n",
    "# print(f\"recognizability : {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a315544",
   "metadata": {},
   "outputs": [],
   "source": [
    " #todo do i need plan? or just name\n",
    "def write_and_save_versions(plan, goal_state_list, obj_set_dict={}, rec_class=[0,1]):\n",
    "    \"\"\"Write the plan and its versions to files.\n",
    "    :param plan: The plan to write.\n",
    "    :param goal_state_list: The list of goal states, each state will produce a different version, at index 0 should be the original plan.\n",
    "    :param obj_set_dict: The dictionary of objects.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, goal_state in enumerate(goal_state_list):\n",
    "        \n",
    "        \n",
    "        #extract plan name with regex\n",
    "        name = re.search(r\"(p\\d+)(?=\\.)\", plan.plan_name).group(1)\n",
    "        \n",
    "        #definition\n",
    "        new_problem = \"\"\n",
    "        # if i==0:\n",
    "        #     new_problem += f\";;(;metadata (recognizability:{round(compute_recognizability(goal_state_list[0], goal_state_list),2)})\\n\"\n",
    "        \n",
    "        new_problem += f\"(define (problem {domain}_{name}_{i})\\n(:domain {domain})\\n(:objects\\n\\t\"\n",
    "    \n",
    "        \n",
    "        #objects in a dict format, {type: obj_set}\n",
    "        for type, obj_set in obj_set_dict.items():\n",
    "            if len(obj_set) > 0:\n",
    "                for obj in obj_set:\n",
    "                    new_problem += f\"{obj} \"\n",
    "                new_problem += f\"- {type}\\n\\t\"\n",
    "        new_problem += f\")\\n\"\n",
    "        \n",
    "        #initial state\n",
    "        new_problem += f\"(:init\\n\"\n",
    "        for fluent in plan.initial_state:\n",
    "            new_problem += f\"\\t{fluent}\\n\"\n",
    "        new_problem += f\")\\n\"\n",
    "        \n",
    "        #goal state\n",
    "        new_problem += f\"(:goal (and\\n\"\n",
    "        for goal in goal_state:\n",
    "            new_problem += f\"\\t{goal}\\n\"\n",
    "        new_problem += f\"))\\n)\"\n",
    "        #print(new_problem + \"\\n\\n\")\n",
    "        \n",
    "        #save the new problem in a file\n",
    "        #naming convention is {current plan name_version number.pddl}, _0 is the original plan\n",
    "        new_problem_dir = f\"{results_dir}/{name}/\"\n",
    "        class_dir = f\"{results_dir}/{name}/{rec_class[0]}_{rec_class[1]}/\"\n",
    "        os.makedirs(new_problem_dir, exist_ok=True)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        new_problem_file = f\"{class_dir}/{name}_{i}.pddl\"\n",
    "        with open(new_problem_file, \"w\") as f:\n",
    "            f.write(new_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04fbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_original_plan(plan, goal_state, obj_set_dict):\n",
    "    \n",
    "    #extract plan name with regex\n",
    "    name = re.search(r\"(p\\d+)(?=\\.)\", plan.plan_name).group(1)\n",
    "    \n",
    "    #definition\n",
    "    new_problem = \"\"\n",
    "    \n",
    "    new_problem += f\"(define (problem {domain}_{name}_og)\\n(:domain {domain})\\n(:objects\\n\\t\"\n",
    "\n",
    "    \n",
    "    #objects in a dict format, {type: obj_set}\n",
    "    for type, obj_set in obj_set_dict.items():\n",
    "        if len(obj_set) > 0:\n",
    "            for obj in obj_set:\n",
    "                new_problem += f\"{obj} \"\n",
    "            new_problem += f\"- {type}\\n\\t\"\n",
    "    new_problem += f\")\\n\"\n",
    "    \n",
    "    #initial state\n",
    "    new_problem += f\"(:init\\n\"\n",
    "    for fluent in plan.initial_state:\n",
    "        new_problem += f\"\\t{fluent}\\n\"\n",
    "    new_problem += f\")\\n\"\n",
    "    \n",
    "    #goal state\n",
    "    new_problem += f\"(:goal (and\\n\"\n",
    "    for goal in goal_state:\n",
    "        new_problem += f\"\\t{goal}\\n\"\n",
    "    new_problem += f\"))\\n)\"\n",
    "    #print(new_problem + \"\\n\\n\")\n",
    "    \n",
    "    #save the new problem in a file\n",
    "    #naming convention is {current plan name_version number.pddl}\n",
    "    new_problem_dir = f\"{results_dir}/{name}/\"\n",
    "    os.makedirs(new_problem_dir, exist_ok=True)\n",
    "    new_problem_file = f\"{new_problem_dir}/{name}_og.pddl\"\n",
    "    with open(new_problem_file, \"w\") as f:\n",
    "        f.write(new_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7f04baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_goal_state_list(package_for_goal_set, pos_for_goal_set, number_of_goals, versions_per_plan):\n",
    "            goal_state_list = []\n",
    "            for i in range(0, versions_per_plan + 1):\n",
    "                # generate a random goal state\n",
    "                goal_state = generate_goal_state(package_for_goal_set, pos_for_goal_set, number_of_goals)\n",
    "                    \n",
    "                goal_state_list.append(goal_state)\n",
    "                \n",
    "            for i, goal_state in enumerate(goal_state_list):\n",
    "                #convert the sets to a list\n",
    "                goal_state_list[i] = list(goal_state)\n",
    "                \n",
    "            return goal_state_list\n",
    "        \n",
    "def generate_goal_state(package_for_goal_set, pos_for_goal_set, number_of_goals):\n",
    "    goal_state = set()\n",
    "    package_for_goal_set_copy = package_for_goal_set.copy()\n",
    "    pos_for_goal_set_copy = pos_for_goal_set.copy()\n",
    "    for _ in range(number_of_goals):\n",
    "        random_package = random.choice(list(package_for_goal_set_copy))\n",
    "        package_for_goal_set_copy.remove(random_package)\n",
    "        random_pos = random.choice(list(pos_for_goal_set_copy))\n",
    "        #pos_for_goal_set_copy.remove(random_pos)\n",
    "        goal_state.add(f\"at {random_package} {random_pos}\") \n",
    "    return goal_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f25e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counter = 0\n",
    "\n",
    "running_sum_rec_error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89119559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_consistency(goal_state):\n",
    "    objects = []\n",
    "    for fluent in goal_state:\n",
    "        obj = re.search(r\"obj\\d+\", fluent)\n",
    "        objects.append(obj.group(0))\n",
    "    return len(objects) == len(set(objects))\n",
    "        \n",
    "\n",
    "def check_if_fluent_is_usable(fluent_to_add, goal_state):\n",
    "    #check if goal state is a list of strings\n",
    "    if isinstance(fluent_to_add, list):\n",
    "        raise ValueError(f\"fluent to add is a list: {fluent_to_add}\")\n",
    "    for fluent in goal_state:\n",
    "        if fluent == fluent_to_add:\n",
    "            return False\n",
    "        elif check_same_object_in_fluents(fluent_to_add, fluent, prefix=\"obj\"):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "#? must fix the problem that obj in base goal can already be in other goal states, so we then have duplicates\n",
    "#? for example, \t\n",
    "    # at obj55 pos13\n",
    "\t# at obj11 pos55\n",
    "\t# at obj23 pos44\n",
    "\t# at obj11 pos44\n",
    "#? here we have obj11 in two goal states because at obj11 pos55 is in the base goal state and at obj11 pos44 is in the goal state list\n",
    "#? we use following function, adding the case to check_if_fluent_is_usable() not enough\n",
    "\n",
    "#todo fix to introduce prefix\n",
    "def check_same_object_in_fluents(fluent1, fluent2, prefix=\"obj\"):\n",
    "    \"\"\"\n",
    "    Check if the object in fluent1 is in fluent2.\n",
    "    :return: True if the object in fluent1 is in fluent2, False otherwise.\n",
    "    \"\"\"\n",
    "    #extract the object from the fluent using regex\n",
    "    obj1 = re.search(r\"obj\\d+\", fluent1).group(0)\n",
    "    obj2 = re.search(r\"obj\\d+\", fluent2).group(0)\n",
    "\n",
    "    if obj1 == obj2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def adapt_goal_state_list_to_recognizability(base_goal_state, goal_state_list, \n",
    "                                             package_for_goal_set, pos_for_goal_set, \n",
    "                                             number_of_goals, rec_target=[0.1, 0.2], \n",
    "                                             randomness_patience=5, regeneration_patience=3):\n",
    "    \"\"\"\n",
    "    Adapt the goal state list to the recognizability.\n",
    "    :param base_goal_state: The base goal state.\n",
    "    :param goal_state_list: The list of goal states to use to compute recognizability.\n",
    "    :param recognizability: The target range of recognizability.\n",
    "    :return: The adapted goal state list.\n",
    "    \"\"\"\n",
    "    global global_counter\n",
    "    global running_sum_rec_error\n",
    "    randomness_patience_constant = randomness_patience\n",
    "    \n",
    "    goal_state_list = [list(x) for x in goal_state_list]\n",
    "    \n",
    "    all_goal_fluents = []\n",
    "    for goal_state in goal_state_list:\n",
    "        for fluent in goal_state:\n",
    "            if fluent not in all_goal_fluents:\n",
    "                all_goal_fluents.append(fluent)\n",
    "        \n",
    "    non_base_goal_fluents = []\n",
    "    for fluent in all_goal_fluents:\n",
    "        if fluent not in base_goal_state:\n",
    "            non_base_goal_fluents.append(fluent)\n",
    "    \n",
    "    running_recognizability = compute_recognizability(base_goal_state, [base_goal_state] + goal_state_list)\n",
    "    #print(f\"Starting recognizability: {running_recognizability}, range is {recognizability}\")\n",
    "    \n",
    "    while running_recognizability < rec_target[0] or running_recognizability > rec_target[1]:\n",
    "        #print(f\"Running recognizability start of step: {running_recognizability}, range is {recognizability}\")\n",
    "        #choose a random goal state from the list\n",
    "        goal_state = random.choice(goal_state_list)\n",
    "        \n",
    "        if running_recognizability > rec_target[1]:\n",
    "            #find a goal state in goal_state_list that has a fluent that is not in the base goal state\n",
    "            #swap it with one from usable_base_goal_fluents\n",
    "            #for goal_state in goal_state_list:\n",
    "                \n",
    "                #builds list of fluents that are in the base goal state but not in this goal state\n",
    "                usable_base_goal_fluents = []\n",
    "                for fluent in base_goal_state:  \n",
    "                    if check_if_fluent_is_usable(fluent, goal_state):\n",
    "                        usable_base_goal_fluents.append(fluent)\n",
    "                                \n",
    "                if len(usable_base_goal_fluents) > 0:\n",
    "                    #swap a fluent from the goal state with one from the base goal state\n",
    "                    fluent_to_swap = random.choice(usable_base_goal_fluents)\n",
    "                    \n",
    "                    candidates_list = []\n",
    "                    for fluent in goal_state:\n",
    "                        if fluent not in base_goal_state:\n",
    "                            candidates_list.append(fluent)\n",
    "                    if len(candidates_list) == 0:\n",
    "                        #if there are no candidates to swap, break\n",
    "                        break\n",
    "                    # debug_goal_state = goal_state.copy()\n",
    "                    random_fluent = random.choice(candidates_list)\n",
    "                    # before = check_consistency(goal_state)\n",
    "                    goal_state[goal_state.index(random_fluent)] = fluent_to_swap\n",
    "                    # after = check_consistency(goal_state)\n",
    "                    # if before == True and after == False:\n",
    "                    #     print(f\"|>|Goal state is not consistent: old goal state{debug_goal_state}\\n\\t base_goal_state: {base_goal_state},\\n\\t fluent_to_swap: {fluent_to_swap},\\n\\t random_fluent: {random_fluent}, \\n\\t usable_base_goal_fluents: {usable_base_goal_fluents}\\n\\n\")\n",
    "                                    \n",
    "        elif running_recognizability < rec_target[0]:\n",
    "            #choose a goal state that has a fluent from base goal and swap it with a random one\n",
    "            #for goal_state in goal_state_list:\n",
    "                #builds list of fluents that are in the base goal state and also in this goal state\n",
    "                present_base_goal_fluents = []\n",
    "                for fluent in base_goal_state:\n",
    "                    if fluent in goal_state:\n",
    "                        present_base_goal_fluents.append(fluent)\n",
    "                        break\n",
    "                                    \n",
    "                if len(present_base_goal_fluents) > 0:\n",
    "                    #swap a common fluent with a random one\n",
    "                    candidates_list = []\n",
    "                    for fluent in non_base_goal_fluents:\n",
    "                        if check_if_fluent_is_usable(fluent, goal_state):\n",
    "                            candidates_list.append(fluent)\n",
    "\n",
    "                    if len(candidates_list) == 0:\n",
    "                        #if there are no candidates to swap, break\n",
    "                        break\n",
    "                    # \n",
    "                    random_fluent = random.choice(candidates_list)\n",
    "\n",
    "                    fluent_to_swap = random.choice(present_base_goal_fluents)\n",
    "                    # before = check_consistency(goal_state)\n",
    "                    goal_state[goal_state.index(fluent_to_swap)] = random_fluent\n",
    "                    # after = check_consistency(goal_state)\n",
    "                    # if before == True and after == False:\n",
    "                    #     print(f\"|<| Goal state is not consistent: {goal_state}\\n\\t base_goal_state: {base_goal_state},\\n\\t fluent_to_swap: {fluent_to_swap},\\n\\t random_fluent: {random_fluent}\\n\\n\")\n",
    "                    \n",
    "        new_recognizability = compute_recognizability(base_goal_state, [base_goal_state] + goal_state_list)\n",
    "        if new_recognizability == running_recognizability:\n",
    "            #if the recognizability did not change we have a stuck goal state with no possible easy changes, we regenerate it after it is selected enough times(randomness_patience)\n",
    "            randomness_patience = randomness_patience - 1\n",
    "            if randomness_patience == 0 and not regeneration_patience == 0:\n",
    "                regeneration_patience = regeneration_patience - 1\n",
    "                randomness_patience = randomness_patience_constant\n",
    "                # print(f\"Patience reached, regenerating stuck goal_state\")\n",
    "                goal_state = generate_goal_state(package_for_goal_set, pos_for_goal_set, number_of_goals)\n",
    "            elif randomness_patience == 0 and regeneration_patience == 0:\n",
    "                #if the recognizability did not change and we have no more patience, we break, no guarantee we will reach the target recognizability, but in majority of cases target is reached\n",
    "                print(f\"Patience exhausted, breaking: Reached recognizability: {running_recognizability} | Target: {rec_target}\")\n",
    "                \n",
    "                error = abs(running_recognizability - rec_target[0]) if running_recognizability < rec_target[0] else abs(running_recognizability - rec_target[1])\n",
    "                running_sum_rec_error = running_sum_rec_error + error\n",
    "                \n",
    "                global_counter = global_counter + 1\n",
    "                \n",
    "                break\n",
    "        #print(f\"Running recognizability at end of step: {running_recognizability}\")\n",
    "        running_recognizability = new_recognizability\n",
    "    return base_goal_state, goal_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd9b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#check_same_object_in_fluents testing\n",
    "fluent1 = \"at obj1 pos1\"\n",
    "fluent2 = \"at obj1 pos2\"\n",
    "\n",
    "print(check_same_object_in_fluents(fluent1, fluent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79c334c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patience exhausted, breaking: Reached recognizability: 0.10013888888888887 | Target: [0, 0.1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.11541666666666664 | Target: [0, 0.1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.10886904761904762 | Target: [0, 0.1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.725 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.725 | Target: [0.8, 0.9]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.8625 | Target: [0.9, 1]\n",
      "Patience exhausted, breaking: Reached recognizability: 0.12458333333333332 | Target: [0, 0.1]\n",
      "Global counter: 15\n",
      "Running sum of recognizability error: 0.6365079365079362\n",
      "Average recognizability error: 0.042433862433862414\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for plan in plans:\n",
    "    if test:\n",
    "        if count >= 3:\n",
    "            break\n",
    "    elif count > plans_to_process:\n",
    "        break\n",
    "    #begin plan processing\n",
    "        \n",
    "    all_obj_set = set()\n",
    "    package_for_goal_set = set()\n",
    "    pos_for_goal_set = set()\n",
    "    \n",
    "    #* find all objects in the initial state and actions\n",
    "    for line in plan.initial_state:\n",
    "        for obj in line.split(\" \")[1:]:\n",
    "            all_obj_set.add(obj)\n",
    "    for action in plan.actions:\n",
    "        for fluent in action.positiveEffects:\n",
    "            for obj in fluent.split(\" \")[1:]:\n",
    "                all_obj_set.add(obj)\n",
    "        for fluent in action.negativeEffects:\n",
    "            for obj in fluent.split(\" \")[1:]:\n",
    "                all_obj_set.add(obj)\n",
    "        for fluent in action.precondition:\n",
    "            for obj in fluent.split(\" \")[1:]:\n",
    "                all_obj_set.add(obj)\n",
    "    \n",
    "    #split the objects in their types\n",
    "    pos_set = set()\n",
    "    apn_set = set()\n",
    "    cit_set = set()\n",
    "    apt_set = set()\n",
    "    tru_set = set()\n",
    "    pack_set = set()\n",
    "    obj_set_dict = {}\n",
    "    for obj in all_obj_set:\n",
    "        if obj.startswith(\"pos\"):\n",
    "            pos_set.add(obj)\n",
    "            pos_for_goal_set.add(obj) #these will be used for goal creation\n",
    "        elif obj.startswith(\"obj\"):\n",
    "            pack_set.add(obj)\n",
    "            package_for_goal_set.add(obj) #these will be used for goal creation\n",
    "        elif obj.startswith(\"apn\"):\n",
    "            apn_set.add(obj)\n",
    "        elif obj.startswith(\"cit\"):\n",
    "            cit_set.add(obj)\n",
    "        elif obj.startswith(\"tru\"):\n",
    "            tru_set.add(obj)\n",
    "        elif obj.startswith(\"apt\"):\n",
    "            apt_set.add(obj)\n",
    "    \n",
    "    #useful for printing the plan\n",
    "    if len(pos_set) > 0:\n",
    "        obj_set_dict[\"location\"] = pos_set\n",
    "    if len(apn_set) > 0:\n",
    "        obj_set_dict[\"airplane\"] = apn_set\n",
    "    if len(cit_set) > 0:\n",
    "        obj_set_dict[\"city\"] = cit_set\n",
    "    if len(apt_set) > 0:\n",
    "        obj_set_dict[\"airport\"] = apt_set\n",
    "    if len(tru_set) > 0:\n",
    "        obj_set_dict[\"truck\"] = tru_set\n",
    "    if len(pack_set) > 0:\n",
    "        obj_set_dict[\"package\"] = pack_set\n",
    "    \n",
    "    #raise an exception if number of goals > number of packages or positions\n",
    "    if number_of_goals > len(package_for_goal_set):\n",
    "        raise exception(f\"Number of goals {number_of_goals} is greater than the number of objects {len(package_for_goal_set)}\")\n",
    "\n",
    "    # if number_of_goals > len(pos_for_goal_set):\n",
    "    #     raise exception(f\"Number of goals {number_of_goals} is greater than the number of positions {len(pos_for_goal_set)}\")\n",
    "\n",
    "    write_original_plan(plan=plan, goal_state=plan.goals, obj_set_dict=obj_set_dict)\n",
    "    \n",
    "    for interval in rec_classes:    \n",
    "        goal_state_list = create_goal_state_list(package_for_goal_set=package_for_goal_set, \n",
    "                                                 pos_for_goal_set=pos_for_goal_set, \n",
    "                                                 number_of_goals=number_of_goals, \n",
    "                                                 versions_per_plan=versions_per_plan)\n",
    "        \n",
    "        # for goal_state in goal_state_list:\n",
    "        #     #check if any goal state has conflicting fluents\n",
    "        #     for fluent1 in goal_state:\n",
    "        #         for fluent2 in goal_state:\n",
    "        #             if fluent1 != fluent2 and check_same_object_in_fluents(fluent1, fluent2):\n",
    "        #                 raise exception(f\"Goal state {goal_state} has conflicting fluents: {fluent1} and {fluent2}\")\n",
    "        \n",
    "        #print(f\"Goals state list before: {goal_state_list}\") \n",
    "        base_goal_state, adapted_goal_state_list = adapt_goal_state_list_to_recognizability(base_goal_state=goal_state_list[0], goal_state_list=goal_state_list[1:], \n",
    "                                                                                            package_for_goal_set=package_for_goal_set, pos_for_goal_set=pos_for_goal_set, \n",
    "                                                                                            number_of_goals=number_of_goals, rec_target=interval, \n",
    "                                                                                            randomness_patience=10, regeneration_patience=5)\n",
    "        #print(f\"Goals state list after adapt: {[base_goal_state] + adapted_goal_state_list}\")\n",
    "\n",
    "        write_and_save_versions(plan=plan, goal_state_list=adapted_goal_state_list, obj_set_dict=obj_set_dict, rec_class=interval)\n",
    "\n",
    "    count = count + 1\n",
    "    \n",
    "print(\"Global counter:\", global_counter)\n",
    "print(\"Running sum of recognizability error:\", running_sum_rec_error)\n",
    "print(\"Average recognizability error:\", running_sum_rec_error/global_counter)\n",
    "global_counter = 0\n",
    "\n",
    "running_sum_rec_error = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b2314",
   "metadata": {},
   "source": [
    "94 0.0337\n",
    "90 0.040\n",
    "71 0.0322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6753e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " #todo study of error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goal_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
