ID,TITLE,ABSTRACT,Computer_Science,Physics,Mathematics,Statistics,Quantitative_Biology,Quantitative_Finance
20511,Experimental observations and modelling of intrinsic rotation reversals in tokamaks,"  The progress made in understanding spontaneous toroidal rotation reversals in
tokamaks is reviewed and current ideas to solve this ten-year-old puzzle are
explored. The paper includes a summarial synthesis of the experimental
observations in AUG, C-Mod, KSTAR, MAST and TCV tokamaks, reasons why turbulent
momentum transport is thought to be responsible for the reversals, a review of
the theory of turbulent momentum transport and suggestions for future
investigations.
",0,1,0,0,0,0
20512,"Where, When, and How mmWave is Used in 5G and Beyon","  Wireless engineers and business planners commonly raise the question on
where, when, and how millimeter-wave (mmWave) will be used in 5G and beyond.
Since the next generation network is not just a new radio access standard, but
instead an integration of networks for vertical markets with diverse
applications, answers to the question depend on scenarios and use cases to be
deployed. This paper gives four 5G mmWave deployment examples and describes in
chronological order the scenarios and use cases of their probable deployment,
including expected system architectures and hardware prototypes. The paper
starts with 28 GHz outdoor backhauling for fixed wireless access and moving
hotspots, which will be demonstrated at the PyeongChang winter Olympic games in
2018. The second deployment example is a 60 GHz unlicensed indoor access system
at the Tokyo-Narita airport, which is combined with Mobile Edge Computing (MEC)
to enable ultra-high speed content download with low latency. The third example
is mmWave mesh network to be used as a micro Radio Access Network ({\mu}-RAN),
for cost-effective backhauling of small-cell Base Stations (BSs) in dense urban
scenarios. The last example is mmWave based Vehicular-to-Vehicular (V2V) and
Vehicular-to-Everything (V2X) communications system, which enables automated
driving by exchanging High Definition (HD) dynamic map information between cars
and Roadside Units (RSUs). For 5G and beyond, mmWave and MEC will play
important roles for a diverse set of applications that require both ultra-high
data rate and low latency communications.
",1,0,0,0,0,0
20513,"A simple script language for choreography of multiple, synchronizing non-anthropomorphic robots","  The scripting language described in this document is (in the first place)
intended to be used on robots developed by Anja M{\o}lle Lindelof and Henning
Christiansen as part of a research project about robots performing on stage.
The target robots are expected to appear as familiar domestic objects that
take their own life, so to speak, and perhaps perform together with human
players, creating at illusion of a communication between them. In the current
version, these robots' common behaviour is determined uniquely by a script
written in the language described here -- the only possible autonomy for the
robots is action to correct dynamically for inaccuracies that arise during a
performance.
The present work is preliminary and has not been compared to properly to
other research work in this area, and the testing is still limited. A first
implementation on small Lego Mindstorms based robots is under development by
Mads Saustrup Fox as part of his master thesis work.
",1,0,0,0,0,0
20514,Stability results for abstract evolution equations with intermittent time-delay feedback,"  We consider abstract evolution equations with on-off time delay feedback.
Without the time delay term, the model is described by an exponentially stable
semigroup. We show that, under appropriate conditions involving the delay term,
the system remains asymptotically stable. Under additional assumptions
exponential stability results are also obtained. Concrete examples illustrating
the abstract results are finally given.
",0,0,1,0,0,0
20515,Solar wind turbulent cascade from MHD to sub-ion scales: large-size 3D hybrid particle-in-cell simulations,"  Spectral properties of the turbulent cascade from fluid to kinetic scales in
collisionless plasmas are investigated by means of large-size three-dimensional
(3D) hybrid (fluid electrons, kinetic protons) particle-in-cell simulations.
Initially isotropic Alfvènic fluctuations rapidly develop a strongly
anisotropic turbulent cascade, mainly in the direction perpendicular to the
ambient magnetic field. The omnidirectional magnetic field spectrum shows a
double power-law behavior over almost two decades in wavenumber, with a
Kolmogorov-like index at large scales, a spectral break around ion scales, and
a steepening at sub-ion scales. Power laws are also observed in the spectra of
the ion bulk velocity, density, and electric field, both at magnetohydrodynamic
(MHD) and at kinetic scales. Despite the complex structure, the omnidirectional
spectra of all fields at ion and sub-ion scales are in remarkable quantitative
agreement with those of a two-dimensional (2D) simulation with similar physical
parameters. This provides a partial, a-posteriori validation of the 2D
approximation at kinetic scales. Conversely, at MHD scales, the spectra of the
density and of the velocity (and, consequently, of the electric field) exhibit
differences between the 2D and 3D cases. Although they can be partly ascribed
to the lower spatial resolution, the main reason is likely the larger
importance of compressible effects in a full geometry. Our findings are also in
remarkable quantitative agreement with solar wind observations.
",0,1,0,0,0,0
20516,Blind source separation of tensor-valued time series,"  The blind source separation model for multivariate time series generally
assumes that the observed series is a linear transformation of an unobserved
series with temporally uncorrelated or independent components. Given the
observations, the objective is to find a linear transformation that recovers
the latent series. Several methods for accomplishing this exist and three
particular ones are the classic SOBI and the recently proposed generalized FOBI
(gFOBI) and generalized JADE (gJADE), each based on the use of joint lagged
moments. In this paper we generalize the methodologies behind these algorithms
for tensor-valued time series. We assume that our data consists of a tensor
observed at each time point and that the observations are linear
transformations of latent tensors we wish to estimate. The tensorial
generalizations are shown to have particularly elegant forms and we show that
each of them is Fisher consistent and orthogonal equivariant. Comparing the new
methods with the original ones in various settings shows that the tensorial
extensions are superior to both their vector-valued counterparts and to two
existing tensorial dimension reduction methods for i.i.d. data. Finally,
applications to fMRI-data and video processing show that the methods are
capable of extracting relevant information from noisy high-dimensional data.
",0,0,1,1,0,0
20517,Mixed Cages,"  We introduce the notion of a $[z, r; g]$-mixed cage. A $[z, r; g]$-mixed cage
is a mixed graph $G$, $z$-regular by arcs, $r$-regular by edges, with girth $g$
and minimum order. In this paper we prove the existence of $[z, r ;g]$-mixed
cages and exhibit families of mixed cages for some specific values. We also
give lower and upper bounds for some choices of $z, r$ and $g$. In particular
we present the first results on $[z,r;g]$- mixed cages for $z=1$ and any $r\geq
1$ and $g\geq 3$, and for any $z\geq 1$, $r=1$ and $g=4$.
",0,0,1,0,0,0
20518,Single-beam dielectric-microsphere trapping with optical heterodyne detection,"  A technique to levitate and measure the three-dimensional position of
micrometer-sized dielectric spheres with heterodyne detection is presented. The
two radial degrees of freedom are measured by interfering light transmitted
through the microsphere with a reference wavefront, while the axial degree of
freedom is measured from the phase of the light reflected from the surface of
the microsphere. This method pairs the simplicity and accessibility of single
beam optical traps to a measurement of displacement that is intrinsically
calibrated by the wavelength of the trapping light and has exceptional immunity
to stray light. A theoretical shot noise limit of
$1.3\times10^{-13}\,\text{m}/\sqrt{\text{Hz}}$ for the radial degrees of
freedom, and $3.0\times10^{-15} \, \text{m}/\sqrt{\text{Hz}}$ for the axial
degree of freedom can be obtained in the system described. The measured
acceleration noise in the radial direction is $7.5\times10^{-5} \,
(\text{m/s}^2)/\sqrt{\text{Hz}}$.
",0,1,0,0,0,0
20519,An Empirical Analysis of Traceability in the Monero Blockchain,"  Monero is a privacy-centric cryptocurrency that allows users to obscure their
transactions by including chaff coins, called ""mixins,"" along with the actual
coins they spend. In this paper, we empirically evaluate two weaknesses in
Monero's mixin sampling strategy. First, about 62% of transaction inputs with
one or more mixins are vulnerable to ""chain-reaction"" analysis -- that is, the
real input can be deduced by elimination. Second, Monero mixins are sampled in
such a way that they can be easily distinguished from the real coins by their
age distribution; in short, the real input is usually the ""newest"" input. We
estimate that this heuristic can be used to guess the real input with 80%
accuracy over all transactions with 1 or more mixins. Next, we turn to the
Monero ecosystem and study the importance of mining pools and the former
anonymous marketplace AlphaBay on the transaction volume. We find that after
removing mining pool activity, there remains a large amount of potentially
privacy-sensitive transactions that are affected by these weaknesses. We
propose and evaluate two countermeasures that can improve the privacy of future
transactions.
",1,0,0,0,0,0
20520,Automatic Face Image Quality Prediction,"  Face image quality can be defined as a measure of the utility of a face image
to automatic face recognition. In this work, we propose (and compare) two
methods for automatic face image quality based on target face quality values
from (i) human assessments of face image quality (matcher-independent), and
(ii) quality values computed from similarity scores (matcher-dependent). A
support vector regression model trained on face features extracted using a deep
convolutional neural network (ConvNet) is used to predict the quality of a face
image. The proposed methods are evaluated on two unconstrained face image
databases, LFW and IJB-A, which both contain facial variations with multiple
quality factors. Evaluation of the proposed automatic face image quality
measures shows we are able to reduce the FNMR at 1% FMR by at least 13% for two
face matchers (a COTS matcher and a ConvNet matcher) by using the proposed face
quality to select subsets of face images and video frames for matching
templates (i.e., multiple faces per subject) in the IJB-A protocol. To our
knowledge, this is the first work to utilize human assessments of face image
quality in designing a predictor of unconstrained face quality that is shown to
be effective in cross-database evaluation.
",1,0,0,0,0,0
20521,Stochastic Block Models are a Discrete Surface Tension,"  Networks, which represent agents and interactions between them, arise in
myriad applications throughout the sciences, engineering, and even the
humanities. To understand large-scale structure in a network, a common task is
to cluster a network's nodes into sets called ""communities"" such that there are
dense connections within communities but sparse connections between them. A
popular and statistically principled method to perform such clustering is to
use a family of generative models known as stochastic block models (SBMs). In
this paper, we show that maximum likelihood estimation in an SBM is a network
analog of a well-known continuum surface-tension problem that arises from an
application in metallurgy. To illustrate the utility of this bridge, we
implement network analogs of three surface-tension algorithms, with which we
successfully recover planted community structure in synthetic networks and
which yield fascinating insights on empirical networks from the field of
hyperspectral video segmentation.
",1,0,0,1,0,0
20522,Robust d-wave pairing symmetry in multi-orbital cobalt high temperature superconductors,"  The pairing symmetry of the newly proposed cobalt high temperature
(high-$T_c$) superconductors formed by vertex shared cation-anion tetrahedral
complexes is studied by the methods of mean field, random phase approximation
(RPA) and functional renormalization group (FRG) analysis. The results of all
these methods show that the $d_{x^2-y^2}$ pairing symmetry is robustly favored
near half filling. The RPA and FRG methods, which are valid in weak interaction
regions, predict that the superconducting state is also strongly orbital
selective, namely the $d_{x^2-y^2}$ orbital that has the largest density near
half filling among the three $t_{2g}$ orbitals dominates superconducting
pairing. These results suggest that the new materials, if synthesized, can
provide indisputable test to high-$T_c$ pairing mechanism and the validity of
different theoretical methods.
",0,1,0,0,0,0
20523,Thermodynamic properties of Ba$_2$CoSi$_2$O$_6$Cl$_2$ in strong magnetic field: Realization of flat-band physics in a highly frustrated quantum magnet,"  The search for flat-band solid-state realizations is a crucial issue to
verify or to challenge theoretical predictions for quantum many-body flat-band
systems. For frustrated quantum magnets flat bands lead to various
unconventional properties related to the existence of localized many-magnon
states. The recently synthesized magnetic compound Ba$_2$CoSi$_2$O$_6$Cl$_2$
seems to be an almost perfect candidate to observe these features in
experiments. We develop a theory for Ba$_2$CoSi$_2$O$_6$Cl$_2$ by adapting the
localized-magnon concept to this compound. We first show that our theory
describes the known experimental facts and then we propose new experimental
studies to detect a field-driven phase transition related to a
Wigner-crystal-like ordering of localized magnons at low temperatures.
",0,1,0,0,0,0
20524,Fisher Information and Natural Gradient Learning of Random Deep Networks,"  A deep neural network is a hierarchical nonlinear model transforming input
signals to output signals. Its input-output relation is considered to be
stochastic, being described for a given input by a parameterized conditional
probability distribution of outputs. The space of parameters consisting of
weights and biases is a Riemannian manifold, where the metric is defined by the
Fisher information matrix. The natural gradient method uses the steepest
descent direction in a Riemannian manifold, so it is effective in learning,
avoiding plateaus. It requires inversion of the Fisher information matrix,
however, which is practically impossible when the matrix has a huge number of
dimensions. Many methods for approximating the natural gradient have therefore
been introduced. The present paper uses statistical neurodynamical method to
reveal the properties of the Fisher information matrix in a net of random
connections under the mean field approximation. We prove that the Fisher
information matrix is unit-wise block diagonal supplemented by small order
terms of off-block-diagonal elements, which provides a justification for the
quasi-diagonal natural gradient method by Y. Ollivier. A unitwise
block-diagonal Fisher metrix reduces to the tensor product of the Fisher
information matrices of single units. We further prove that the Fisher
information matrix of a single unit has a simple reduced form, a sum of a
diagonal matrix and a rank 2 matrix of weight-bias correlations. We obtain the
inverse of Fisher information explicitly. We then have an explicit form of the
natural gradient, without relying on the numerical matrix inversion, which
drastically speeds up stochastic gradient learning.
",0,0,0,1,0,0
20525,Dynamic of plumes and scaling during the melting of a Phase Change Material heated from below,"  We identify and describe the main dynamic regimes occurring during the
melting of the PCM n-octadecane in horizontal layers of several sizes heated
from below. This configuration allows to cover a wide range of effective
Rayleigh numbers on the liquid PCM phase, up to $\sim 10^9$, without changing
any external parameter control. We identify four different regimes as time
evolves: (i) the conductive regime, (ii) linear regime, (iii) coarsening regime
and (iv) turbulent regime. The first two regimes appear at all domain sizes.
However the third and fourth regime require a minimum advance of the
solid/liquid interface to develop, and we observe them only for large enough
domains.
The transition to turbulence takes places after a secondary instability that
forces the coarsening of the thermal plumes. Each one of the melting regimes
creates a distinct solid/liquid front that characterizes the internal state of
the melting process. We observe that most of the magnitudes of the melting
process are ruled by power laws, although not all of them. Thus the number of
plumes, some regimes of the Rayleigh number as a function of time, the number
of plumes after the primary and secondary instability, the thermal and kinetic
boundary layers follow simple power laws. In particular, we find that the
Nusselt number scales with the Rayleigh number as $Nu \sim Ra^{0.29}$ in the
turbulent regime, consistent with theories and experiments on Rayleigh-Bénard
convection that show an exponent $2/7$.
",0,1,0,0,0,0
20526,Parallel mean curvature surfaces in four-dimensional homogeneous spaces,"  We survey different classification results for surfaces with parallel mean
curvature immersed into some Riemannian homogeneous four-manifolds, including
real and complex space forms, and product spaces. We provide a common framework
for this problem, with special attention to the existence of holomorphic
quadratic differentials on such surfaces. The case of spheres with parallel
mean curvature is also explained in detail, as well as the state-of-the-art
advances in the general problem.
",0,0,1,0,0,0
20527,"Recent implementations, applications, and extensions of the Locally Optimal Block Preconditioned Conjugate Gradient method (LOBPCG)","  Since introduction [A. Knyazev, Toward the optimal preconditioned
eigensolver: Locally optimal block preconditioned conjugate gradient method,
SISC (2001) DOI:10.1137/S1064827500366124] and efficient parallel
implementation [A. Knyazev et al., Block locally optimal preconditioned
eigenvalue xolvers (BLOPEX) in HYPRE and PETSc, SISC (2007)
DOI:10.1137/060661624], LOBPCG has been used is a wide range of applications in
mechanics, material sciences, and data sciences. We review its recent
implementations and applications, as well as extensions of the local optimality
idea beyond standard eigenvalue problems.
",1,0,0,1,0,0
20528,An evaluation of cosmological models from expansion and growth of structure measurements,"  We compare a large suite of theoretical cosmological models to observational
data from the cosmic microwave background, baryon acoustic oscillation
measurements of expansion, Type Ia SNe measurements of expansion, redshift
space distortion measurements of the growth of structure, and the local Hubble
constant. Our theoretical models include parametrizations of dark energy as
well as physical models of dark energy and modified gravity. We determine the
constraints on the model parameters, incorporating the redshift space
distortion data directly in the analysis. To determine whether models can be
ruled out, we evaluate the $p$ value (the probability under the model of
obtaining data as bad or worse than the observed data). In our comparison, we
find the well known tension of H$_0$ with the other data; no model resolves
this tension successfully. Among the models we consider, the large scale growth
of structure data does not affect the modified gravity models as a category
particularly differently than dark energy models; it matters for some modified
gravity models but not others, and the same is true for dark energy models. We
compute predicted observables for each model under current observational
constraints, and identify models for which future observational constraints
will be particularly informative.
",0,1,0,0,0,0
20529,The variety of $2$-dimensional algebras over an algebraically closed field,"  The work is devoted to the variety of $2$-dimensional algebras over an
algebraically closed field. Firstly, we classify such algebras modulo
isomorphism. Then we describe the degenerations and the closures of principal
algebra series in the variety under consideration. Finally, we apply our
results to obtain analogous descriptions for the subvarieties of flexible, and
bicommutative algebras. In particular, we describe rigid algebras and
irreducible components for these subvarieties.
",0,0,1,0,0,0
20530,A Variational Observation Model of 3D Object for Probabilistic Semantic SLAM,"  We present a Bayesian object observation model for complete probabilistic
semantic SLAM. Recent studies on object detection and feature extraction have
become important for scene understanding and 3D mapping. However, 3D shape of
the object is too complex to formulate the probabilistic observation model;
therefore, performing the Bayesian inference of the object-oriented features as
well as their pose is less considered. Besides, when the robot equipped with an
RGB mono camera only observes the projected single view of an object, a
significant amount of the 3D shape information is abandoned. Due to these
limitations, semantic SLAM and viewpoint-independent loop closure using
volumetric 3D object shape is challenging. In order to enable the complete
formulation of probabilistic semantic SLAM, we approximate the observation
model of a 3D object with a tractable distribution. We also estimate the
variational likelihood from the 2D image of the object to exploit its observed
single view. In order to evaluate the proposed method, we perform pose and
feature estimation, and demonstrate that the automatic loop closure works
seamlessly without additional loop detector in various environments.
",1,0,0,0,0,0
20531,Generation of optical frequency combs via four-wave mixing processes for low- and medium-resolution astronomy,"  We investigate the generation of optical frequency combs through a cascade of
four-wave mixing processes in nonlinear fibres with optimised parameters. The
initial optical field consists of two continuous-wave lasers with frequency
separation larger than 40 GHz (312.7 pm at 1531 nm). It propagates through
three nonlinear fibres. The first fibre serves to pulse shape the initial
sinusoidal-square pulse, while a strong pulse compression down to sub-100 fs
takes place in the second fibre which is an amplifying erbium-doped fibre. The
last stage is a low-dispersion highly nonlinear fibre where the frequency comb
bandwidth is increased and the line intensity is equalised. We model this
system using the generalised nonlinear Schrödinger equation and investigate
it in terms of fibre lengths, fibre dispersion, laser frequency separation and
input powers with the aim to minimise the frequency comb noise. With the
support of the numerical results, a frequency comb is experimentally generated,
first in the near infra-red and then it is frequency-doubled into the visible
spectral range. Using a MUSE-type spectrograph, we evaluate the comb
performance for astronomical wavelength calibration in terms of equidistancy of
the comb lines and their stability.
",0,1,0,0,0,0
20532,Cross-referencing Social Media and Public Surveillance Camera Data for Disaster Response,"  Physical media (like surveillance cameras) and social media (like Instagram
and Twitter) may both be useful in attaining on-the-ground information during
an emergency or disaster situation. However, the intersection and reliability
of both surveillance cameras and social media during a natural disaster are not
fully understood. To address this gap, we tested whether social media is of
utility when physical surveillance cameras went off-line during Hurricane Irma
in 2017. Specifically, we collected and compared geo-tagged Instagram and
Twitter posts in the state of Florida during times and in areas where public
surveillance cameras went off-line. We report social media content and
frequency and content to determine the utility for emergency managers or first
responders during a natural disaster.
",1,0,0,0,0,0
20533,Nonlinear Dynamics of a Viscous Bubbly Fluid,"  A physical model of a three-dimensional flow of a viscous bubbly fluid in an
intermediate regime between bubble formation and breakage is presented. The
model is based on mechanics and thermodynamics of a single bubble coupled to
the dynamics of a viscous fluid as a whole, and takes into account multiple
physical effects, including gravity, viscosity, and surface tension.
Dimensionless versions of the resulting nonlinear model are obtained, and
values of dimensionless parameters are estimated for typical magma flows in
horizontal subaerial lava fields and vertical volcanic conduits.
Exact solutions of the resulting system of nonlinear equations corresponding
to equilibrium flows and traveling waves are analyzed in the one-dimensional
setting. Generalized Su-Gardner-type perturbation analysis is employed to study
approximate solutions of the model in the long-wave ansatz. Simplified
nonlinear partial differential equations (PDE) satisfied by the leading terms
of the perturbation solutions are systematically derived. It is shown that for
specific classes of perturbations, approximate solutions of the bubbly fluid
model arise from solutions of the classical diffusion, Burgers,
variable-coefficient Burgers, and Korteweg-de Vries equations.
",0,1,0,0,0,0
20534,ConvNet-Based Localization of Anatomical Structures in 3D Medical Images,"  Localization of anatomical structures is a prerequisite for many tasks in
medical image analysis. We propose a method for automatic localization of one
or more anatomical structures in 3D medical images through detection of their
presence in 2D image slices using a convolutional neural network (ConvNet).
A single ConvNet is trained to detect presence of the anatomical structure of
interest in axial, coronal, and sagittal slices extracted from a 3D image. To
allow the ConvNet to analyze slices of different sizes, spatial pyramid pooling
is applied. After detection, 3D bounding boxes are created by combining the
output of the ConvNet in all slices.
In the experiments 200 chest CT, 100 cardiac CT angiography (CTA), and 100
abdomen CT scans were used. The heart, ascending aorta, aortic arch, and
descending aorta were localized in chest CT scans, the left cardiac ventricle
in cardiac CTA scans, and the liver in abdomen CT scans. Localization was
evaluated using the distances between automatically and manually defined
reference bounding box centroids and walls.
The best results were achieved in localization of structures with clearly
defined boundaries (e.g. aortic arch) and the worst when the structure boundary
was not clearly visible (e.g. liver). The method was more robust and accurate
in localization multiple structures.
",1,0,0,0,0,0
20535,Gradient estimates for heat kernels and harmonic functions,"  Let $(X,d,\mu)$ be a doubling metric measure space endowed with a Dirichlet
form $\E$ deriving from a ""carré du champ"". Assume that $(X,d,\mu,\E)$
supports a scale-invariant $L^2$-Poincaré inequality. In this article, we
study the following properties of harmonic functions, heat kernels and Riesz
transforms for $p\in (2,\infty]$:
(i) $(G_p)$: $L^p$-estimate for the gradient of the associated heat
semigroup;
(ii) $(RH_p)$: $L^p$-reverse Hölder inequality for the gradients of
harmonic functions;
(iii) $(R_p)$: $L^p$-boundedness of the Riesz transform ($p<\infty$);
(iv) $(GBE)$: a generalised Bakry-Émery condition.
We show that, for $p\in (2,\infty)$, (i), (ii) (iii) are equivalent, while
for $p=\infty$, (i), (ii), (iv) are equivalent.
Moreover, some of these equivalences still hold under weaker conditions than
the $L^2$-Poincaré inequality.
Our result gives a characterisation of Li-Yau's gradient estimate of heat
kernels for $p=\infty$, while for $p\in (2,\infty)$ it is a substantial
improvement as well as a generalisation of earlier results by
Auscher-Coulhon-Duong-Hofmann [7] and Auscher-Coulhon [6]. Applications to
isoperimetric inequalities and Sobolev inequalities are given. Our results
apply to Riemannian and sub-Riemannian manifolds as well as to non-smooth
spaces, and to degenerate elliptic/parabolic equations in these settings.
",0,0,1,0,0,0
20536,The Deep Underground Neutrino Experiment -- DUNE: the precision era of neutrino physics,"  The last decade was remarkable for neutrino physics. In particular, the
phenomenon of neutrino flavor oscillations has been firmly established by a
series of independent measurements. All parameters of the neutrino mixing are
now known and we have elements to plan a judicious exploration of new scenarios
that are opened by these recent advances. With precise measurements, we can
test the 3-neutrino paradigm, neutrino mass hierarchy and CP asymmetry in the
lepton sector. The future long-baseline experiments are considered to be a
fundamental tool to deepen our knowledge of electroweak interactions. The Deep
Underground Neutrino Experiment -- DUNE will detect a broad-band neutrino beam
from Fermilab in an underground massive Liquid Argon Time-Projection Chamber at
an L/E of about $10^3$ km / GeV to reach good sensitivity for CP-phase
measurements and the determination of the mass hierarchy. The dimensions and
the depth of the Far Detector also create an excellent opportunity to look for
rare signals like proton decay to study violation of baryonic number, as well
as supernova neutrino bursts, broadening the scope of the experiment to
astrophysics and associated impacts in cosmology. In this presentation, we will
discuss the physics motivations and the main experimental features of the DUNE
project required to reach its scientific goals.
",0,1,0,0,0,0
20537,Variations of $q$-Garnier system,"  We study several variants of q-Garnier system corresponding to various
directions of discrete time evolutions. We also investigate a relation between
the $q$-Garnier system and Suzuki's higher order $q$-Painlev/'e system by using
a duality of the $q$-KP system.
",0,1,1,0,0,0
20538,Quantum Quench dynamics in Non-local Luttinger Model: Rigorous Results,"  We investigate, in the Luttinger model with fixed box potential, the time
evolution of an inhomogeneous state prepared as a localized fermion added to
the noninteracting ground state. We proved that, if the state is evolved with
the interacting Hamiltonian, the averaged density has two peaks moving in
opposite directions, with a constant but renormalized velocity. We also proved
that a dynamical `Landau quasi-particle weight' appears in the oscillating part
of the averaged density, asymptotically vanishing with large time. The results
are proved with the Mattis-Lieb diagonalization method. A simpler proof with
the exact Bosonization formulas is also provided.
",0,0,1,0,0,0
20539,Dynamics of Relaxed Inflation,"  The cosmological relaxation of the electroweak scale has been proposed as a
mechanism to address the hierarchy problem of the Standard Model. A field, the
relaxion, rolls down its potential and, in doing so, scans the squared mass
parameter of the Higgs, relaxing it to a parametrically small value. In this
work, we promote the relaxion to an inflaton. We couple it to Abelian gauge
bosons, thereby introducing the necessary dissipation mechanism which slows
down the field in the last stages. We describe a novel reheating mechanism,
which relies on the gauge-boson production leading to strong electromagnetic
fields, and proceeds via the vacuum production of electron-positron pairs
through the Schwinger effect. We refer to this mechanism as Schwinger
reheating. We discuss the cosmological dynamics of the model and the
phenomenological constraints from CMB and other experiments. We find that a
cutoff close to the Planck scale may be achieved. In its minimal form, the
model does not generate sufficient curvature perturbations and additional
ingredients, such as a curvaton field, are needed.
",0,1,0,0,0,0
20540,Clustering is semidefinitely not that hard: Nonnegative SDP for manifold disentangling,"  In solving hard computational problems, semidefinite program (SDP)
relaxations often play an important role because they come with a guarantee of
optimality. Here, we focus on a popular semidefinite relaxation of K-means
clustering which yields the same solution as the non-convex original
formulation for well segregated datasets. We report an unexpected finding: when
data contains (greater than zero-dimensional) manifolds, the SDP solution
captures such geometrical structures. Unlike traditional manifold embedding
techniques, our approach does not rely on manually defining a kernel but rather
enforces locality via a nonnegativity constraint. We thus call our approach
NOnnegative MAnifold Disentangling, or NOMAD. To build an intuitive
understanding of its manifold learning capabilities, we develop a theoretical
analysis of NOMAD on idealized datasets. While NOMAD is convex and the globally
optimal solution can be found by generic SDP solvers with polynomial time
complexity, they are too slow for modern datasets. To address this problem, we
analyze a non-convex heuristic and present a new, convex and yet efficient,
algorithm, based on the conditional gradient method. Our results render NOMAD a
versatile, understandable, and powerful tool for manifold learning.
",1,0,0,0,0,0
20541,Dispersive optical detection of magnetic Feshbach resonances in ultracold gases,"  Magnetically tunable Feshbach resonances in ultracold atomic systems are
chiefly identified and characterized through time consuming atom loss
spectroscopy. We describe an off-resonant dispersive optical probing technique
to rapidly locate Feshbach resonances and demonstrate the method by locating
four resonances of $^{87}$Rb, between the $|\rm{F} = 1, \rm{m_F}=1 \rangle$ and
$|\rm{F} = 2, \rm{m_F}=0 \rangle$ states. Despite the loss features being
$\lesssim0.1$ G wide, we require only 21 experimental runs to explore a
magnetic field range >18 G, where $1~\rm{G}=10^{-4}$ T. The resonances consist
of two known s-wave features in the vicinity of 9 G and 18 G and two previously
unobserved p-wave features near 5 G and 10 G. We further utilize the dispersive
approach to directly characterize the two-body loss dynamics for each Feshbach
resonance.
",0,1,0,0,0,0
20542,Unveiling Bias Compensation in Turbo-Based Algorithms for (Discrete) Compressed Sensing,"  In Compressed Sensing, a real-valued sparse vector has to be recovered from
an underdetermined system of linear equations. In many applications, however,
the elements of the sparse vector are drawn from a finite set. Adapted
algorithms incorporating this additional knowledge are required for the
discrete-valued setup. In this paper, turbo-based algorithms for both cases are
elucidated and analyzed from a communications engineering perspective, leading
to a deeper understanding of the algorithm. In particular, we gain the
intriguing insight that the calculation of extrinsic values is equal to the
unbiasing of a biased estimate and present an improved algorithm.
",1,0,0,0,0,0
20543,Accelerated Linear Convergence of Stochastic Momentum Methods in Wasserstein Distances,"  Momentum methods such as Polyak's heavy ball (HB) method, Nesterov's
accelerated gradient (AG) as well as accelerated projected gradient (APG)
method have been commonly used in machine learning practice, but their
performance is quite sensitive to noise in the gradients. We study these
methods under a first-order stochastic oracle model where noisy estimates of
the gradients are available. For strongly convex problems, we show that the
distribution of the iterates of AG converges with the accelerated
$O(\sqrt{\kappa}\log(1/\varepsilon))$ linear rate to a ball of radius
$\varepsilon$ centered at a unique invariant distribution in the 1-Wasserstein
metric where $\kappa$ is the condition number as long as the noise variance is
smaller than an explicit upper bound we can provide. Our analysis also
certifies linear convergence rates as a function of the stepsize, momentum
parameter and the noise variance; recovering the accelerated rates in the
noiseless case and quantifying the level of noise that can be tolerated to
achieve a given performance. In the special case of strongly convex quadratic
objectives, we can show accelerated linear rates in the $p$-Wasserstein metric
for any $p\geq 1$ with improved sensitivity to noise for both AG and HB through
a non-asymptotic analysis under some additional assumptions on the noise
structure. Our analysis for HB and AG also leads to improved non-asymptotic
convergence bounds in suboptimality for both deterministic and stochastic
settings which is of independent interest. To the best of our knowledge, these
are the first linear convergence results for stochastic momentum methods under
the stochastic oracle model. We also extend our results to the APG method and
weakly convex functions showing accelerated rates when the noise magnitude is
sufficiently small.
",1,0,0,1,0,0
20544,Compressed sensing with sparse corruptions: Fault-tolerant sparse collocation approximations,"  The recovery of approximately sparse or compressible coefficients in a
Polynomial Chaos Expansion is a common goal in modern parametric uncertainty
quantification (UQ). However, relatively little effort in UQ has been directed
toward theoretical and computational strategies for addressing the sparse
corruptions problem, where a small number of measurements are highly corrupted.
Such a situation has become pertinent today since modern computational
frameworks are sufficiently complex with many interdependent components that
may introduce hardware and software failures, some of which can be difficult to
detect and result in a highly polluted simulation result.
In this paper we present a novel compressive sampling-based theoretical
analysis for a regularized $\ell^1$ minimization algorithm that aims to recover
sparse expansion coefficients in the presence of measurement corruptions. Our
recovery results are uniform, and prescribe algorithmic regularization
parameters in terms of a user-defined a priori estimate on the ratio of
measurements that are believed to be corrupted. We also propose an iteratively
reweighted optimization algorithm that automatically refines the value of the
regularization parameter, and empirically produces superior results. Our
numerical results test our framework on several medium-to-high dimensional
examples of solutions to parameterized differential equations, and demonstrate
the effectiveness of our approach.
",0,0,1,0,0,0
20545,Learning to Remember Rare Events,"  Despite recent advances, memory-augmented deep neural networks are still
limited when it comes to life-long and one-shot learning, especially in
remembering rare events. We present a large-scale life-long memory module for
use in deep learning. The module exploits fast nearest-neighbor algorithms for
efficiency and thus scales to large memory sizes. Except for the
nearest-neighbor query, the module is fully differentiable and trained
end-to-end with no extra supervision. It operates in a life-long manner, i.e.,
without the need to reset it during training.
Our memory module can be easily added to any part of a supervised neural
network. To show its versatility we add it to a number of networks, from simple
convolutional ones tested on image classification to deep sequence-to-sequence
and recurrent-convolutional models. In all cases, the enhanced network gains
the ability to remember and do life-long one-shot learning. Our module
remembers training examples shown many thousands of steps in the past and it
can successfully generalize from them. We set new state-of-the-art for one-shot
learning on the Omniglot dataset and demonstrate, for the first time, life-long
one-shot learning in recurrent neural networks on a large-scale machine
translation task.
",1,0,0,0,0,0
20546,Stacking-dependent electronic structure of trilayer graphene resolved by nanospot angle-resolved photoemission spectroscopy,"  The crystallographic stacking order in multilayer graphene plays an important
role in determining its electronic structure. In trilayer graphene,
rhombohedral stacking (ABC) is particularly intriguing, exhibiting a flat band
with an electric-field tunable band gap. Such electronic structure is distinct
from simple hexagonal stacking (AAA) or typical Bernal stacking (ABA), and is
promising for nanoscale electronics, optoelectronics applications. So far clean
experimental electronic spectra on the first two stackings are missing because
the samples are usually too small in size (um or nm scale) to be resolved by
conventional angle-resolved photoemission spectroscopy (ARPES). Here by using
ARPES with nanospot beam size (NanoARPES), we provide direct experimental
evidence for the coexistence of three different stackings of trilayer graphene
and reveal their distinctive electronic structures directly. By fitting the
experimental data, we provide important experimental band parameters for
describing the electronic structure of trilayer graphene with different
stackings.
",0,1,0,0,0,0
20547,Interaction energy between vortices of vector fields on Riemannian surfaces,"  We study a variational Ginzburg-Landau type model depending on a small
parameter $\epsilon>0$ for (tangent) vector fields on a $2$-dimensional
Riemannian surface. As $\epsilon\to 0$, the vector fields tend to be of unit
length and will have singular points of a (non-zero) index, called vortices.
Our main result determines the interaction energy between these vortices as a
$\Gamma$-limit (at the second order) as $\epsilon\to 0$.
",0,0,1,0,0,0
20548,Multimodal Nonlinear Microscope based on a Compact Fiber-format Laser Source,"  We present a multimodal non-linear optical (NLO) laser-scanning microscope,
based on a compact fiber-format excitation laser and integrating coherent
anti-Stokes Raman scattering (CARS), stimulated Raman scattering (SRS) and
two-photon-excitation fluorescence (TPEF) on a single platform. We demonstrate
its capabilities in simultaneously acquiring CARS and SRS images of a blend of
6-{\mu}m poly(methyl methacrylate) beads and 3-{\mu}m polystyrene beads. We
then apply it to visualize cell walls and chloroplast of an unprocessed fresh
leaf of Elodea aquatic plant via SRS and TPEF modalities, respectively. The
presented NLO microscope, developed in house using off-the-shelf components,
offers full accessibility to the optical path and ensures its easy
re-configurability and flexibility.
",0,1,0,0,0,0
20549,The Diffuse Light of the Universe - On the microwave background before and after its discovery: open questions,"  In 1965, the discovery of a new type of uniform radiation, located between
radiowaves and infrared light, was accidental. Known today as Cosmic Microwave
background (CMB), this diffuse radiation is commonly interpreted as a fossil
light released in an early hot and dense universe and constitutes today the
main 'pilar' of the big bang cosmology. Considerable efforts have been devoted
to derive fundamental cosmological parameters from the characteristics of this
radiation that led to a surprising universe that is shaped by at least three
major unknown components: inflation, dark matter and dark energy. This is an
important weakness of the present consensus cosmological model that justifies
raising several questions on the CMB interpretation. Can we consider its
cosmological nature as undisputable? Do other possible interpretations exist in
the context of other cosmological theories or simply as a result of other
physical mechanisms that could account for it? In an effort to questioning the
validity of scientific hypotheses and the under-determination of theories
compared to observations, we examine here the difficulties that still exist on
the interpretation of this diffuse radiation and explore other proposed tracks
to explain its origin. We discuss previous historical concepts of diffuse
radiation before and after the CMB discovery and underline the limit of our
present understanding.
",0,1,0,0,0,0
20550,Classification of $5$-Dimensional Complex Nilpotent Leibniz Algebras,"  Leibniz algebras are certain generalization of Lie algebras. In this paper we
give the classification of $5-$dimensional complex non-Lie nilpotent Leibniz
algebras. We use the canonical forms for the congruence classes of matrices of
bilinear forms to classify the case $\dim(A^2)=3$ and $\dim(Leib(A))=1$ which
can be applied to higher dimensions. The remaining cases are classified via
direct method.
",0,0,1,0,0,0
20551,Haptics of Screwing and Unscrewing for its Application in Smart Factories for Disassembly,"  Reconstruction of skilled humans sensation and control system often leads to
a development of robust control for the robots. We are developing an unscrewing
robot for the automated disassembly which requires a comprehensive control
system, but unscrewing experiments with robots are often limited to several
conditions. On the contrary, humans typically have a broad range of screwing
experiences and sensations throughout their lives, and we conducted an
experiment to find these haptic patterns. Results show that people apply axial
force to the screws to avoid screwdriver slippage (cam-outs), which is one of
the key problems during screwing and unscrewing, and this axial force is
proportional to the torque which is required for screwing. We have found that
type of the screw head influences the amount of axial force applied. Using this
knowledge an unscrewing robot for the smart disassembly factory RecyBot is
developed, and experiments confirm the optimality of the strategy, used by
humans. Finally, a methodology for robust unscrewing algorithm design is
presented as a generalization of the findings. It can seriously speed up the
development of the screwing and unscrewing robots and tools.
",1,0,0,0,0,0
20552,$G$-invariant Szegö kernel asymptotics and CR reduction,"  Let $(X, T^{1,0}X)$ be a compact connected orientable CR manifold of
dimension $2n+1$ with non-degenerate Levi curvature. Assume that $X$ admits a
connected compact Lie group action $G$. Under certain natural assumptions about
the group action $G$, we show that the $G$-invariant Szegö kernel for $(0,q)$
forms is a complex Fourier integral operator, smoothing away $\mu^{-1}(0)$ and
there is a precise description of the singularity near $\mu^{-1}(0)$, where
$\mu$ denotes the CR moment map. We apply our result to the case when $X$
admits a transversal CR $S^1$ action and deduce an asymptotic expansion for the
$m$-th Fourier component of the $G$-invariant Szegö kernel for $(0,q)$ forms
as $m \to+\infty$. As an application, we show that if $m$ large enough,
quantization commutes with reduction.
",0,0,1,0,0,0
20553,Self-similar resistive circuits as fractal-like structures,"  In the present work we explore resistive circuits where the individual
resistors are arranged in fractal-like patterns. These circuits have some of
the characteristics typically found in geometric fractals, namely
self-similarity and scale invariance. Considering resistive circuits as graphs,
we propose a definition of self-similar circuits which mimics a self-similar
fractal. General properties of the resistive circuits generated by this
approach are investigated, and interesting examples are commented in detail.
Specifically, we consider self-similar resistive series, tree-like resistive
networks and Sierpinski's configurations with resistors.
",0,1,0,0,0,0
20554,DynaPhoPy: A code for extracting phonon quasiparticles from molecular dynamics simulations,"  We have developed a computational code, DynaPhoPy, that allow us to extract
the microscopic anharmonic phonon properties from molecular dynamics (MD)
simulations using the normal-mode-decomposition technique as presented by Sun
et al. [T. Sun, D. Zhang, R. Wentzcovitch, 2014]. Using this code we calculated
the quasiparticle phonon frequencies and linewidths of crystalline silicon at
different temperatures using both of first-principles and the Tersoff empirical
potential approaches. In this work we show the dependence of these properties
on the temperature using both approaches and compare them with reported
experimental data obtained by Raman spectroscopy [M. Balkanski, R. Wallis, E.
Haro, 1983 and R. Tsu, J. G. Hernandez, 1982].
",0,1,0,0,0,0
20555,Lower Bounds for Two-Sample Structural Change Detection in Ising and Gaussian Models,"  The change detection problem is to determine if the Markov network structures
of two Markov random fields differ from one another given two sets of samples
drawn from the respective underlying distributions. We study the trade-off
between the sample sizes and the reliability of change detection, measured as a
minimax risk, for the important cases of the Ising models and the Gaussian
Markov random fields restricted to the models which have network structures
with $p$ nodes and degree at most $d$, and obtain information-theoretic lower
bounds for reliable change detection over these models. We show that for the
Ising model, $\Omega\left(\frac{d^2}{(\log d)^2}\log p\right)$ samples are
required from each dataset to detect even the sparsest possible changes, and
that for the Gaussian, $\Omega\left( \gamma^{-2} \log(p)\right)$ samples are
required from each dataset to detect change, where $\gamma$ is the smallest
ratio of off-diagonal to diagonal terms in the precision matrices of the
distributions. These bounds are compared to the corresponding results in
structure learning, and closely match them under mild conditions on the model
parameters. Thus, our change detection bounds inherit partial tightness from
the structure learning schemes in previous literature, demonstrating that in
certain parameter regimes, the naive structure learning based approach to
change detection is minimax optimal up to constant factors.
",1,0,1,0,0,0
20556,How Usable are Rust Cryptography APIs?,"  Context: Poor usability of cryptographic APIs is a severe source of
vulnerabilities. Aim: We wanted to find out what kind of cryptographic
libraries are present in Rust and how usable they are. Method: We explored
Rust's cryptographic libraries through a systematic search, conducted an
exploratory study on the major libraries and a controlled experiment on two of
these libraries with 28 student participants. Results: Only half of the major
libraries explicitly focus on usability and misuse resistance, which is
reflected in their current APIs. We found that participants were more
successful using rust-crypto which we considered less usable than ring before
the experiment. Conclusion: We discuss API design insights and make
recommendations for the design of crypto libraries in Rust regarding the detail
and structure of the documentation, higher-level APIs as wrappers for the
existing low-level libraries, and selected, good-quality example code to
improve the emerging cryptographic libraries of Rust.
",1,0,0,0,0,0
20557,Augmenting End-to-End Dialog Systems with Commonsense Knowledge,"  Building dialog agents that can converse naturally with humans is a
challenging yet intriguing problem of artificial intelligence. In open-domain
human-computer conversation, where the conversational agent is expected to
respond to human responses in an interesting and engaging way, commonsense
knowledge has to be integrated into the model effectively. In this paper, we
investigate the impact of providing commonsense knowledge about the concepts
covered in the dialog. Our model represents the first attempt to integrating a
large commonsense knowledge base into end-to-end conversational models. In the
retrieval-based scenario, we propose the Tri-LSTM model to jointly take into
account message and commonsense for selecting an appropriate response. Our
experiments suggest that the knowledge-augmented models are superior to their
knowledge-free counterparts in automatic evaluation.
",1,0,0,0,0,0
20558,A framework for Multi-A(rmed)/B(andit) testing with online FDR control,"  We propose an alternative framework to existing setups for controlling false
alarms when multiple A/B tests are run over time. This setup arises in many
practical applications, e.g. when pharmaceutical companies test new treatment
options against control pills for different diseases, or when internet
companies test their default webpages versus various alternatives over time.
Our framework proposes to replace a sequence of A/B tests by a sequence of
best-arm MAB instances, which can be continuously monitored by the data
scientist. When interleaving the MAB tests with an an online false discovery
rate (FDR) algorithm, we can obtain the best of both worlds: low sample
complexity and any time online FDR control. Our main contributions are: (i) to
propose reasonable definitions of a null hypothesis for MAB instances; (ii) to
demonstrate how one can derive an always-valid sequential p-value that allows
continuous monitoring of each MAB test; and (iii) to show that using rejection
thresholds of online-FDR algorithms as the confidence levels for the MAB
algorithms results in both sample-optimality, high power and low FDR at any
point in time. We run extensive simulations to verify our claims, and also
report results on real data collected from the New Yorker Cartoon Caption
contest.
",1,0,0,1,0,0
20559,Statistical Speech Enhancement Based on Probabilistic Integration of Variational Autoencoder and Non-Negative Matrix Factorization,"  This paper presents a statistical method of single-channel speech enhancement
that uses a variational autoencoder (VAE) as a prior distribution on clean
speech. A standard approach to speech enhancement is to train a deep neural
network (DNN) to take noisy speech as input and output clean speech. Although
this supervised approach requires a very large amount of pair data for
training, it is not robust against unknown environments. Another approach is to
use non-negative matrix factorization (NMF) based on basis spectra trained on
clean speech in advance and those adapted to noise on the fly. This
semi-supervised approach, however, causes considerable signal distortion in
enhanced speech due to the unrealistic assumption that speech spectrograms are
linear combinations of the basis spectra. Replacing the poor linear generative
model of clean speech in NMF with a VAE---a powerful nonlinear deep generative
model---trained on clean speech, we formulate a unified probabilistic
generative model of noisy speech. Given noisy speech as observed data, we can
sample clean speech from its posterior distribution. The proposed method
outperformed the conventional DNN-based method in unseen noisy environments.
",1,0,0,1,0,0
20560,BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning,"  Understanding the global optimality in deep learning (DL) has been attracting
more and more attention recently. Conventional DL solvers, however, have not
been developed intentionally to seek for such global optimality. In this paper
we propose a novel approximation algorithm, BPGrad, towards optimizing deep
models globally via branch and pruning. Our BPGrad algorithm is based on the
assumption of Lipschitz continuity in DL, and as a result it can adaptively
determine the step size for current gradient given the history of previous
updates, wherein theoretically no smaller steps can achieve the global
optimality. We prove that, by repeating such branch-and-pruning procedure, we
can locate the global optimality within finite iterations. Empirically an
efficient solver based on BPGrad for DL is proposed as well, and it outperforms
conventional DL solvers such as Adagrad, Adadelta, RMSProp, and Adam in the
tasks of object recognition, detection, and segmentation.
",1,0,0,1,0,0
20561,Lagrangian Flow Network approach to an open flow model,"  Concepts and tools from network theory, the so-called Lagrangian Flow Network
framework, have been successfully used to obtain a coarse-grained description
of transport by closed fluid flows. Here we explore the application of this
methodology to open chaotic flows, and check it with numerical results for a
model open flow, namely a jet with a localized wave perturbation. We find that
network nodes with high values of out-degree and of finite-time entropy in the
forward-in-time direction identify the location of the chaotic saddle and its
stable manifold, whereas nodes with high in-degree and backwards finite-time
entropy highlight the location of the saddle and its unstable manifold. The
cyclic clustering coefficient, associated to the presence of periodic orbits,
takes non-vanishing values at the location of the saddle itself.
",0,1,0,0,0,0
20562,Some new gradient estimates for two nonlinear parabolic equations under Ricci flow,"  In this paper, by maximum principle and cutoff function, we investigate
gradient estimates for positive solutions to two nonlinear parabolic equations
under Ricci flow. The related Harnack inequalities are deduced. An result about
positive solutions on closed manifolds under Ricci flow is abtained. As
applications, gradient estimates and Harnack inequalities for positive
solutions to the heat equation under Ricci flow are derived. These results in
the paper can be regard as generalizing the gradient estimates of Li-Yau, J. Y.
Li, Hamilton and Li-Xu to the Ricci flow. Our results also improve the
estimates of S. P. Liu and J. Sun to the nonlinear parabolic equation under
Ricci flow.
",0,0,1,0,0,0
20563,On the pointwise iteration-complexity of a dynamic regularized ADMM with over-relaxation stepsize,"  In this paper, we extend the improved pointwise iteration-complexity result
of a dynamic regularized alternating direction method of multipliers (ADMM) for
a new stepsize domain. In this complexity analysis, the stepsize parameter can
even be chosen in the interval $(0,2)$ instead of interval
$(0,(1+\sqrt{5})/2)$. As usual, our analysis is established by interpreting
this ADMM variant as an instance of a hybrid proximal extragradient framework
applied to a specific monotone inclusion problem.
",0,0,1,0,0,0
20564,DeepBrain: Functional Representation of Neural In-Situ Hybridization Images for Gene Ontology Classification Using Deep Convolutional Autoencoders,"  This paper presents a novel deep learning-based method for learning a
functional representation of mammalian neural images. The method uses a deep
convolutional denoising autoencoder (CDAE) for generating an invariant, compact
representation of in situ hybridization (ISH) images. While most existing
methods for bio-imaging analysis were not developed to handle images with
highly complex anatomical structures, the results presented in this paper show
that functional representation extracted by CDAE can help learn features of
functional gene ontology categories for their classification in a highly
accurate manner. Using this CDAE representation, our method outperforms the
previous state-of-the-art classification rate, by improving the average AUC
from 0.92 to 0.98, i.e., achieving 75% reduction in error. The method operates
on input images that were downsampled significantly with respect to the
original ones to make it computationally feasible.
",1,0,0,1,0,0
20565,Nonlocal heat equations in the Heisenberg group,"  We study the following nonlocal diffusion equation in the Heisenberg group
$\mathbb{H}_n$, \[ u_t(z,s,t)=J\ast u(z,s,t)-u(z,s,t), \] where $\ast$ denote
convolution product and $J$ satisfies appropriated hypothesis. For the Cauchy
problem we obtain that the asymptotic behavior of the solutions is the same
form that the one for the heat equation in the Heisenberg group. To obtain this
result we use the spherical transform related to the pair
$(U(n),\mathbb{H}_n)$. Finally we prove that solutions of properly rescaled
nonlocal Dirichlet problem converge uniformly to the solution of the
corresponding Dirichlet problem for the classical heat equation in the
Heisenberg group.
",0,0,1,0,0,0
20566,Motion Planning Networks,"  Fast and efficient motion planning algorithms are crucial for many
state-of-the-art robotics applications such as self-driving cars. Existing
motion planning methods such as RRT*, A*, and D*, become ineffective as their
computational complexity increases exponentially with the dimensionality of the
motion planning problem. To address this issue, we present a neural
network-based novel planning algorithm which generates end-to-end
collision-free paths irrespective of the obstacles' geometry. The proposed
method, called MPNet (Motion Planning Network), comprises of a Contractive
Autoencoder which encodes the given workspaces directly from a point cloud
measurement, and a deep feedforward neural network which takes the workspace
encoding, start and goal configuration, and generates end-to-end feasible
motion trajectories for the robot to follow. We evaluate MPNet on multiple
planning problems such as planning of a point-mass robot, rigid-body, and 7 DOF
Baxter robot manipulators in various 2D and 3D environments. The results show
that MPNet is not only consistently computationally efficient in all 2D and 3D
environments but also show remarkable generalization to completely unseen
environments. The results also show that computation time of MPNet consistently
remains less than 1 second which is significantly lower than existing
state-of-the-art motion planning algorithms. Furthermore, through transfer
learning, the MPNet trained in one scenario (e.g., indoor living places) can
also quickly adapt to new scenarios (e.g., factory floors) with a little amount
of data.
",1,0,0,1,0,0
20567,Query Expansion Techniques for Information Retrieval: a Survey,"  With the ever increasing size of web, relevant information extraction on the
Internet with a query formed by a few keywords has become a big challenge. To
overcome this, query expansion (QE) plays a crucial role in improving the
Internet searches, where the user's initial query is reformulated to a new
query by adding new meaningful terms with similar significance. QE -- as part
of information retrieval (IR) -- has long attracted researchers' attention. It
has also become very influential in the field of personalized social document,
Question Answering over Linked Data (QALD), and, Text Retrieval Conference
(TREC) and REAL sets. This paper surveys QE techniques in IR from 1960 to 2017
with respect to core techniques, data sources used, weighting and ranking
methodologies, user participation and applications (of QE techniques) --
bringing out similarities and differences.
",1,0,0,0,0,0
20568,Method for Aspect-Based Sentiment Annotation Using Rhetorical Analysis,"  This paper fills a gap in aspect-based sentiment analysis and aims to present
a new method for preparing and analysing texts concerning opinion and
generating user-friendly descriptive reports in natural language. We present a
comprehensive set of techniques derived from Rhetorical Structure Theory and
sentiment analysis to extract aspects from textual opinions and then build an
abstractive summary of a set of opinions. Moreover, we propose aspect-aspect
graphs to evaluate the importance of aspects and to filter out unimportant ones
from the summary. Additionally, the paper presents a prototype solution of data
flow with interesting and valuable results. The proposed method's results
proved the high accuracy of aspect detection when applied to the gold standard
dataset.
",1,0,0,0,0,0
20569,Commutativity of integral quasi-arithmetic means on measure spaces,"  Let $(X, \mathscr{L}, \lambda)$ and $(Y, \mathscr{M}, \mu)$ be finite measure
spaces for which there exist $A \in \mathscr{L}$ and $B \in \mathscr{M}$ with
$0 < \lambda(A) < \lambda(X)$ and $0 < \mu(B) < \mu(Y)$, and let $I\subseteq
\mathbf{R}$ be a non-empty interval. We prove that, if $f$ and $g$ are
continuous bijections $I \to \mathbf{R}^+$, then the equation $$
f^{-1}\!\left(\int_X f\!\left(g^{-1}\!\left(\int_Y g \circ
h\;d\mu\right)\right)d \lambda\right)\! = g^{-1}\!\left(\int_Y
g\!\left(f^{-1}\!\left(\int_X f \circ h\;d\lambda\right)\right)d \mu\right)$$
is satisfied by every $\mathscr{L} \otimes \mathscr{M}$-measurable simple
function $h: X \times Y \to I$ if and only if $f=c g$ for some $c \in
\mathbf{R}^+$ (it is easy to see that the equation is well posed). An
analogous, but essentially different, result, with $f$ and $g$ replaced by
continuous injections $I \to \mathbf R$ and $\lambda(X)=\mu(Y)=1$, was recently
obtained in [Indag. Math. 27 (2016), 945-953].
",0,0,1,0,0,0
20570,Moderate Deviation for Random Elliptic PDEs with Small Noise,"  Partial differential equations with random inputs have become popular models
to characterize physical systems with uncertainty coming from, e.g., imprecise
measurement and intrinsic randomness. In this paper, we perform asymptotic rare
event analysis for such elliptic PDEs with random inputs. In particular, we
consider the asymptotic regime that the noise level converges to zero
suggesting that the system uncertainty is low, but does exists. We develop
sharp approximations of the probability of a large class of rare events.
",0,0,1,0,0,0
20571,Music Transformer,"  Music relies heavily on repetition to build structure and meaning.
Self-reference occurs on multiple timescales, from motifs to phrases to reusing
of entire sections of music, such as in pieces with ABA structure. The
Transformer (Vaswani et al., 2017), a sequence model based on self-attention,
has achieved compelling results in many generation tasks that require
maintaining long-range coherence. This suggests that self-attention might also
be well-suited to modeling music. In musical composition and performance,
however, relative timing is critically important. Existing approaches for
representing relative positional information in the Transformer modulate
attention based on pairwise distance (Shaw et al., 2018). This is impractical
for long sequences such as musical compositions since their memory complexity
for intermediate relative information is quadratic in the sequence length. We
propose an algorithm that reduces their intermediate memory requirement to
linear in the sequence length. This enables us to demonstrate that a
Transformer with our modified relative attention mechanism can generate
minute-long compositions (thousands of steps, four times the length modeled in
Oore et al., 2018) with compelling structure, generate continuations that
coherently elaborate on a given motif, and in a seq2seq setup generate
accompaniments conditioned on melodies. We evaluate the Transformer with our
relative attention mechanism on two datasets, JSB Chorales and
Piano-e-Competition, and obtain state-of-the-art results on the latter.
",1,0,0,1,0,0
20572,Residual-Based Detections and Unified Architecture for Massive MIMO Uplink,"  Massive multiple-input multiple-output (M-MIMO) technique brings better
energy efficiency and coverage but higher computational complexity than
small-scale MIMO. For linear detections such as minimum mean square error
(MMSE), prohibitive complexity lies in solving large-scale linear equations.
For a better trade-off between bit-error-rate (BER) performance and
computational complexity, iterative linear algorithms like conjugate gradient
(CG) have been applied and have shown their feasibility in recent years. In
this paper, residual-based detection (RBD) algorithms are proposed for M-MIMO
detection, including minimal residual (MINRES) algorithm, generalized minimal
residual (GMRES) algorithm, and conjugate residual (CR) algorithm. RBD
algorithms focus on the minimization of residual norm per iteration, whereas
most existing algorithms focus on the approximation of exact signal. Numerical
results have shown that, for $64$-QAM $128\times 8$ MIMO, RBD algorithms are
only $0.13$ dB away from the exact matrix inversion method when BER$=10^{-4}$.
Stability of RBD algorithms has also been verified in various correlation
conditions. Complexity comparison has shown that, CR algorithm require $87\%$
less complexity than the traditional method for $128\times 60$ MIMO. The
unified hardware architecture is proposed with flexibility, which guarantees a
low-complexity implementation for a family of RBD M-MIMO detectors.
",1,0,0,0,0,0
20573,Sparsity constrained split feasibility for dose-volume constraints in inverse planning of intensity-modulated photon or proton therapy,"  A split feasibility formulation for the inverse problem of
intensity-modulated radiation therapy (IMRT) treatment planning with
dose-volume constraints (DVCs) included in the planning algorithm is presented.
It involves a new type of sparsity constraint that enables the inclusion of a
percentage-violation constraint in the model problem and its handling by
continuous (as opposed to integer) methods. We propose an iterative algorithmic
framework for solving such a problem by applying the feasibility-seeking
CQ-algorithm of Byrne combined with the automatic relaxation method (ARM) that
uses cyclic projections. Detailed implementation instructions are furnished.
Functionality of the algorithm was demonstrated through the creation of an
intensity-modulated proton therapy plan for a simple 2D C-shaped geometry and
also for a realistic base-of-skull chordoma treatment site. Monte Carlo
simulations of proton pencil beams of varying energy were conducted to obtain
dose distributions for the 2D test case. A research release of the Pinnacle3
proton treatment planning system was used to extract pencil beam doses for a
clinical base-of-skull chordoma case. In both cases the beamlet doses were
calculated to satisfy dose-volume constraints according to our new algorithm.
Examination of the dose-volume histograms following inverse planning with our
algorithm demonstrated that it performed as intended. The application of our
proposed algorithm to dose-volume constraint inverse planning was successfully
demonstrated. Comparison with optimized dose distributions from the research
release of the Pinnacle3 treatment planning system showed the algorithm could
achieve equivalent or superior results.
",0,1,1,0,0,0
20574,On 2-Verma modules for quantum $\mathfrak{sl}_2$,"  In this paper we study the superalgebra $A_n$, introduced by the authors in
previous work on categorification of Verma modules for quantum
$\mathfrak{sl}_2$. The superalgebra $A_n$ is akin to the nilHecke algebra, and
shares similar properties. In particular, we prove a uniqueness result about
2-Verma modules on $\Bbbk$-linear 2-categories.
",0,0,1,0,0,0
20575,On the Number of Single-Peaked Narcissistic or Single-Crossing Narcissistic Preference Profiles,"  We investigate preference profiles for a set $\mathcal{V}$ of voters, where
each voter $i$ has a preference order $\succ_i$ on a finite set $A$ of
alternatives (that is, a linear order on $A$) such that for each two
alternatives $a,b\in A$, voter $i$ prefers $a$ to $b$ if $a\succ_i b$. Such a
profile is narcissistic if each alternative $a$ is preferred the most by at
least one voter. It is single-peaked if there is a linear order
$\triangleright^{\text{sp}}$ on the alternatives such that each voter's
preferences on the alternatives along the order $\triangleright^{\text{sp}}$
are either strictly increasing, or strictly decreasing, or first strictly
increasing and then strictly decreasing. It is single-crossing if there is a
linear order $\triangleright^{\text{sc}}$ on the voters such that each pair of
alternatives divides the order $\triangleright^{\text{sc}}$ into at most two
suborders, where in each suborder, all voters have the same linear order on
this pair.
We show that for $n$ voters and $n$ alternatives,the number of single-peaked
narcissistic profiles is $\prod_{i=2}^{n-1} \binom{n-1}{i-1}$ while the number
of single-crossing narcissistic profiles is $2^{\binom{n-1}{2}}$.
",0,0,1,0,0,0
20576,Planet formation and disk-planet interactions,"  This review is based on lectures given at the 45th Saas-Fee Advanced Course
'From Protoplanetary Disks to Planet Formation' held in March 2015 in Les
Diablerets, Switzerland. Starting with an overview of the main characterictics
of the Solar System and extrasolar planets, we describe the planet formation
process in terms of the sequential accretion scenario. First the growth
processes of dust particles to planetesimals and subsequently to terrestrial
planets or planetary cores are presented. This is followed by the formation
process of the giant planets either by core accretion or gravitational
instability. Finally, the dynamical evolution of the orbital elements as driven
by disk-planet interaction and the overall evolution of multi-object systems is
presented.
",0,1,0,0,0,0
20577,Cherednik algebras and Calogero-Moser cells,"  Using the representation theory of Cherednik algebras at $t=0$ and a Galois
covering of the Calogero-Moser space, we define the notions of left, right and
two-sided Calogero-Moser cells for any finite complex reflection group. To each
Caloger-Moser two-sided cell is associated a Calogero-Moser family, while to
each Calogero-Moser left cell is associated a Calogero-Moser cellular
representation. We study properties of these objects and we conjecture that,
whenever the reflection group is real (i.e. is a Coxeter group), these notions
coincide with the one of Kazhdan-Lusztig left, right and two-sided cells,
Kazhdan-Lusztig families and Kazhdan-Lusztig cellular representations.
",0,0,1,0,0,0
20578,Khovanov complexes of rational tangles,"  We show that the Khovanov complex of a rational tangle has a very simple
representative whose backbone of non-zero morphisms forms a zig-zag.
Furthermore, this minimal complex can be computed quickly by an inductive
algorithm. (For example, we calculate $Kh(8_2)$ by hand.) We find that the
bigradings of the subobjects in these minimal complexes can be described by
matrix actions, which after a change of basis is the reduced Burau
representation of $B_3$.
",0,0,1,0,0,0
20579,Asymmetric Connectedness of Fears in the U.S. Financial Sector,"  We study how shocks to the forward-looking expectations of investors buying
call and put options transmit across the financial system. We introduce a new
contagion measure, called asymmetric fear connectedness (AFC), which captures
the information related to ""fear"" on the two sides of the options market and
can be used as a forward-looking systemic risk monitoring tool. The decomposed
connectedness measures provide timely predictive information for near-future
macroeconomic conditions and uncertainty indicators, and they contain
additional valuable information that is not included in the aggregate
connectedness measure. The role of a positive/negative ""fear""
transmitter/receiver emerges clearly when we focus more closely on
idiosyncratic events for financial institutions. We identify banks that are
predominantly positive/negative receivers of ""fear"", as well as banks that
positively/negatively transmit ""fear"" in the financial system.
",0,0,0,0,0,1
20580,Neural Network Based Speaker Classification and Verification Systems with Enhanced Features,"  This work presents a novel framework based on feed-forward neural network for
text-independent speaker classification and verification, two related systems
of speaker recognition. With optimized features and model training, it achieves
100% classification rate in classification and less than 6% Equal Error Rate
(ERR), using merely about 1 second and 5 seconds of data respectively. Features
with stricter Voice Active Detection (VAD) than the regular one for speech
recognition ensure extracting stronger voiced portion for speaker recognition,
speaker-level mean and variance normalization helps to eliminate the
discrepancy between samples from the same speaker. Both are proven to improve
the system performance. In building the neural network speaker classifier, the
network structure parameters are optimized with grid search and dynamically
reduced regularization parameters are used to avoid training terminated in
local minimum. It enables the training goes further with lower cost. In speaker
verification, performance is improved with prediction score normalization,
which rewards the speaker identity indices with distinct peaks and penalizes
the weak ones with high scores but more competitors, and speaker-specific
thresholding, which significantly reduces ERR in the ROC curve. TIMIT corpus
with 8K sampling rate is used here. First 200 male speakers are used to train
and test the classification performance. The testing files of them are used as
in-domain registered speakers, while data from the remaining 126 male speakers
are used as out-of-domain speakers, i.e. imposters in speaker verification.
",1,0,0,0,0,0
20581,Slimness of graphs,"  Slimness of a graph measures the local deviation of its metric from a tree
metric. In a graph $G=(V,E)$, a geodesic triangle $\bigtriangleup(x,y,z)$ with
$x, y, z\in V$ is the union $P(x,y) \cup P(x,z) \cup P(y,z)$ of three shortest
paths connecting these vertices. A geodesic triangle $\bigtriangleup(x,y,z)$ is
called $\delta$-slim if for any vertex $u\in V$ on any side $P(x,y)$ the
distance from $u$ to $P(x,z) \cup P(y,z)$ is at most $\delta$, i.e. each path
is contained in the union of the $\delta$-neighborhoods of two others. A graph
$G$ is called $\delta$-slim, if all geodesic triangles in $G$ are
$\delta$-slim. The smallest value $\delta$ for which $G$ is $\delta$-slim is
called the slimness of $G$. In this paper, using the layering partition
technique, we obtain sharp bounds on slimness of such families of graphs as (1)
graphs with cluster-diameter $\Delta(G)$ of a layering partition of $G$, (2)
graphs with tree-length $\lambda$, (3) graphs with tree-breadth $\rho$, (4)
$k$-chordal graphs, AT-free graphs and HHD-free graphs. Additionally, we show
that the slimness of every 4-chordal graph is at most 2 and characterize those
4-chordal graphs for which the slimness of every of its induced subgraph is at
most 1.
",1,0,0,0,0,0
20582,SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems,"  Despite their immense popularity, deep learning-based acoustic systems are
inherently vulnerable to adversarial attacks, wherein maliciously crafted
audios trigger target systems to misbehave. In this paper, we present
SirenAttack, a new class of attacks to generate adversarial audios. Compared
with existing attacks, SirenAttack highlights with a set of significant
features: (i) versatile -- it is able to deceive a range of end-to-end acoustic
systems under both white-box and black-box settings; (ii) effective -- it is
able to generate adversarial audios that can be recognized as specific phrases
by target acoustic systems; and (iii) stealthy -- it is able to generate
adversarial audios indistinguishable from their benign counterparts to human
perception. We empirically evaluate SirenAttack on a set of state-of-the-art
deep learning-based acoustic systems (including speech command recognition,
speaker recognition and sound event classification), with results showing the
versatility, effectiveness, and stealthiness of SirenAttack. For instance, it
achieves 99.45% attack success rate on the IEMOCAP dataset against the ResNet18
model, while the generated adversarial audios are also misinterpreted by
multiple popular ASR platforms, including Google Cloud Speech, Microsoft Bing
Voice, and IBM Speech-to-Text. We further evaluate three potential defense
methods to mitigate such attacks, including adversarial training, audio
downsampling, and moving average filtering, which leads to promising directions
for further research.
",1,0,0,0,0,0
20583,k-server via multiscale entropic regularization,"  We present an $O((\log k)^2)$-competitive randomized algorithm for the
$k$-server problem on hierarchically separated trees (HSTs). This is the first
$o(k)$-competitive randomized algorithm for which the competitive ratio is
independent of the size of the underlying HST. Our algorithm is designed in the
framework of online mirror descent where the mirror map is a multiscale
entropy. When combined with Bartal's static HST embedding reduction, this leads
to an $O((\log k)^2 \log n)$-competitive algorithm on any $n$-point metric
space. We give a new dynamic HST embedding that yields an $O((\log k)^3 \log
\Delta)$-competitive algorithm on any metric space where the ratio of the
largest to smallest non-zero distance is at most $\Delta$.
",1,0,1,0,0,0
20584,Some Large Sample Results for the Method of Regularized Estimators,"  We present a general framework for studying regularized estimators; i.e.,
estimation problems wherein ""plug-in"" type estimators are either ill-defined or
ill-behaved. We derive primitive conditions that imply consistency and
asymptotic linear representation for regularized estimators, allowing for
slower than $\sqrt{n}$ estimators as well as infinite dimensional parameters.
We also provide data-driven methods for choosing tuning parameters that, under
some conditions, achieve the aforementioned results. We illustrate the scope of
our approach by studying a wide range of applications, revisiting known results
and deriving new ones.
",0,0,1,0,0,0
20585,Coregionalised Locomotion Envelopes - A Qualitative Approach,"  'Sharing of statistical strength' is a phrase often employed in machine
learning and signal processing. In sensor networks, for example, missing
signals from certain sensors may be predicted by exploiting their correlation
with observed signals acquired from other sensors. For humans, our hands move
synchronously with our legs, and we can exploit these implicit correlations for
predicting new poses and for generating new natural-looking walking sequences.
We can also go much further and exploit this form of transfer learning, to
develop new control schemas for robust control of rehabilitation robots. In
this short paper we introduce coregionalised locomotion envelopes - a method
for multi-dimensional manifold regression, on human locomotion variates. Herein
we render a qualitative description of this method.
",1,0,0,1,0,0
20586,Optimal Invariant Tests in an Instrumental Variables Regression With Heteroskedastic and Autocorrelated Errors,"  This paper uses model symmetries in the instrumental variable (IV) regression
to derive an invariant test for the causal structural parameter. Contrary to
popular belief, we show there exist model symmetries when equation errors are
heteroskedastic and autocorrelated (HAC). Our theory is consistent with
existing results for the homoskedastic model (Andrews, Moreira and Stock(2006}
and Chamberlain (2007}), but in general uses information on the structural
parameter beyond the Anderson-Rubin, score, and rank statistics. This suggests
that tests based only the Anderson-Rubin and score statistics discard
information on the causal parameter of interest. We apply our theory to
construct designs in which these tests indeed have power arbitrarily close to
size. Other tests, including other adaptations to the CLR test, do not suffer
the same deficiencies. Finally, we use the model symmetries to propose novel
weighted-average power tests for the HAC-IV model.
",0,0,1,1,0,0
20587,Longitudinal electric field: from Maxwell equation to non-locality in time and space,"  In this paper we use the classical electrodynamics to show that the Lorenz
gauge can be incompatible with some particular solutions of the d Alembert
equations for electromagnetic potentials. In its turn, the d Alembert equations
for the elec- tromagnetic potentials is the result of application of the Lorenz
gauge to general equations for the potentials. The last ones is the
straightforward consequence of Maxwell equations. Since the d Alembert
equations and the electromagnetic poten- tials are necessary for quantum
electrodynamics formulation, one should oblige to satisfy these equations also
in classical case. The solution of d Alembert equations, which modifies
longitudinal electric field is found. The requirement of this modifi- cation
follows from the necessity to satisfy the physical condition of impossibility
of instantaneous transferring of interaction in space.
",0,1,0,0,0,0
20588,Estimating linear functionals of a sparse family of Poisson means,"  Assume that we observe a sample of size n composed of p-dimensional signals,
each signal having independent entries drawn from a scaled Poisson distribution
with an unknown intensity. We are interested in estimating the sum of the n
unknown intensity vectors, under the assumption that most of them coincide with
a given 'background' signal. The number s of p-dimensional signals different
from the background signal plays the role of sparsity and the goal is to
leverage this sparsity assumption in order to improve the quality of estimation
as compared to the naive estimator that computes the sum of the observed
signals. We first introduce the group hard thresholding estimator and analyze
its mean squared error measured by the squared Euclidean norm. We establish a
nonasymptotic upper bound showing that the risk is at most of the order of
{\sigma}^2(sp + s^2sqrt(p)) log^3/2(np). We then establish lower bounds on the
minimax risk over a properly defined class of collections of s-sparse signals.
These lower bounds match with the upper bound, up to logarithmic terms, when
the dimension p is fixed or of larger order than s^2. In the case where the
dimension p increases but remains of smaller order than s^2, our results show a
gap between the lower and the upper bounds, which can be up to order sqrt(p).
",0,0,1,1,0,0
20589,Fabrication of porous microrings via laser printing and ion-beam post-etching,"  Pulsed-laser dry printing of noble-metal microrings with a tunable internal
porous structure, which can be revealed via an ion-beam etching post-procedure,
was demonstrated. Abundance and average size of the pores inside the microrings
were shown to be tuned in a wide range by varying incident pulse energy and a
nitrogen doping level controlled in the process of magnetron deposition of the
gold film in the appropriate gaseous environment. The fabricated porous
microrings were shown to provide many-fold near-field enhancement of incident
electromagnetic fields, which was confirmed by mapping of the characteristic
Raman band of a nanometer-thick covering layer of Rhodamine 6G dye molecules
and supporting finite-difference time-domain calculations. The proposed laser
printing/ion-beam etching approach is demonstrated to be a unique tool aimed at
designing and fabricating multifunctional plasmonic structures and metasurfaces
for spectroscopic bioidentification based on surface-enhanced infrared
absorption, Raman scattering and photoluminescence detection schemes.
",0,1,0,0,0,0
20590,Performance Measurements of Supercomputing and Cloud Storage Solutions,"  Increasing amounts of data from varied sources, particularly in the fields of
machine learning and graph analytics, are causing storage requirements to grow
rapidly. A variety of technologies exist for storing and sharing these data,
ranging from parallel file systems used by supercomputers to distributed block
storage systems found in clouds. Relatively few comparative measurements exist
to inform decisions about which storage systems are best suited for particular
tasks. This work provides these measurements for two of the most popular
storage technologies: Lustre and Amazon S3. Lustre is an open-source, high
performance, parallel file system used by many of the largest supercomputers in
the world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web
Services offering, and offers a scalable, distributed option to store and
retrieve data from anywhere on the Internet. Parallel processing is essential
for achieving high performance on modern storage systems. The performance tests
used span the gamut of parallel I/O scenarios, ranging from single-client,
single-node Amazon S3 and Lustre performance to a large-scale, multi-client
test designed to demonstrate the capabilities of a modern storage appliance
under heavy load. These results show that, when parallel I/O is used correctly
(i.e., many simultaneous read or write processes), full network bandwidth
performance is achievable and ranged from 10 gigabits/s over a 10 GigE S3
connection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These
results demonstrate that S3 is well-suited to sharing vast quantities of data
over the Internet, while Lustre is well-suited to processing large quantities
of data locally.
",1,1,0,0,0,0
20591,Multi-Objective Event-triggered Consensus of Linear Multi-agent Systems,"  This paper proposes a distributed consensus algorithm for linear event-based
heterogeneous multi-agent systems (MAS). The proposed scheme is event-triggered
in the sense that an agent selectively transmits its information within its
local neighbourhood based on a directed network topology under the fulfillment
of certain conditions. Using the Lyapunov stability theorem, the system
constraints and event-triggering condition are expressed in terms of several
linear matrix inequalities (LMIs) to derive the consensus parameters. The
objective is to design the transmission threshold and minimum-norm
heterogeneous control gains which collectively ensure an exponential consensus
convergence rate for the closed-loop systems. The LMI computed control gains
are robust to uncertainty with some deviation from their nominal values
allowed. The practicability of the proposed event-based framework is further
studied by proving the Zeno behaviour exclusion. Numerical simulations quantify
the advantages of our event-triggered consensus approach in second-order,
linear and heterogeneous multi-agent systems.
",1,0,0,0,0,0
20592,Private and Secure Coordination of Match-Making for Heavy-Duty Vehicle Platooning,"  A secure and private framework for inter-agent communication and coordination
is developed. This allows an agent, in our case a fleet owner, to ask questions
or submit queries in an encrypted fashion using semi-homomorphic encryption.
The submitted query can be about the interest of the other fleet owners for
using a road at a specific time of the day, for instance, for the purpose of
collaborative vehicle platooning. The other agents can then provide appropriate
responses without knowing the content of the questions or the queries. Strong
privacy and security guarantees are provided for the agent who is submitting
the queries. It is also shown that the amount of the information that this
agent can extract from the other agent is bounded. In fact, with submitting one
query, a sophisticated agent can at most extract the answer to two queries.
This secure communication platform is used subsequently to develop a
distributed coordination mechanisms among fleet owners.
",1,0,1,0,0,0
20593,Kernel Robust Bias-Aware Prediction under Covariate Shift,"  Under covariate shift, training (source) data and testing (target) data
differ in input space distribution, but share the same conditional label
distribution. This poses a challenging machine learning task. Robust Bias-Aware
(RBA) prediction provides the conditional label distribution that is robust to
the worstcase logarithmic loss for the target distribution while matching
feature expectation constraints from the source distribution. However,
employing RBA with insufficient feature constraints may result in high
certainty predictions for much of the source data, while leaving too much
uncertainty for target data predictions. To overcome this issue, we extend the
representer theorem to the RBA setting, enabling minimization of regularized
expected target risk by a reweighted kernel expectation under the source
distribution. By applying kernel methods, we establish consistency guarantees
and demonstrate better performance of the RBA classifier than competing methods
on synthetically biased UCI datasets as well as datasets that have natural
covariate shift.
",1,0,0,1,0,0
20594,Degeneration in VAE: in the Light of Fisher Information Loss,"  While enormous progress has been made to Variational Autoencoder (VAE) in
recent years, similar to other deep networks, VAE with deep networks suffers
from the problem of degeneration, which seriously weakens the correlation
between the input and the corresponding latent codes, deviating from the goal
of the representation learning. To investigate how degeneration affects VAE
from a theoretical perspective, we illustrate the information transmission in
VAE and analyze the intermediate layers of the encoders/decoders. Specifically,
we propose a Fisher Information measure for the layer-wise analysis. With such
measure, we demonstrate that information loss is ineluctable in feed-forward
networks and causes the degeneration in VAE. We show that skip connections in
VAE enable the preservation of information without changing the model
architecture. We call this class of VAE equipped with skip connections as SCVAE
and perform a range of experiments to show its advantages in information
preservation and degeneration mitigation.
",0,0,0,1,0,0
20595,Room-temperature spin transport in n-Ge probed by four-terminal nonlocal measurements,"  We demonsrtate electrical spin injection and detection in $n$-type Ge
($n$-Ge) at room temperature using four-terminal nonlocal spin-valve and
Hanle-effect measurements in lateral spin-valve (LSV) devices with
Heusler-alloy Schottky tunnel contacts. The spin diffusion length
($\lambda$$_{\rm Ge}$) of the Ge layer used ($n \sim$ 1 $\times$ 10$^{19}$
cm$^{-3}$) at 296 K is estimated to be $\sim$ 0.44 $\pm$ 0.02 $\mu$m.
Room-temperature spin signals can be observed reproducibly at the low bias
voltage range ($\le$ 0.7 V) for LSVs with relatively low resistance-area
product ($RA$) values ($\le$ 1 k$\Omega$$\mu$m$^{2}$). This means that the
Schottky tunnel contacts used here are more suitable than ferromagnet/MgO
tunnel contacts ($RA \ge$ 100 k$\Omega$$\mu$m$^{2}$) for developing Ge
spintronic applications.
",0,1,0,0,0,0
20596,Synthesizing Neural Network Controllers with Probabilistic Model based Reinforcement Learning,"  We present an algorithm for rapidly learning controllers for robotics
systems. The algorithm follows the model-based reinforcement learning paradigm,
and improves upon existing algorithms; namely Probabilistic learning in Control
(PILCO) and a sample-based version of PILCO with neural network dynamics
(Deep-PILCO). We propose training a neural network dynamics model using
variational dropout with truncated Log-Normal noise. This allows us to obtain a
dynamics model with calibrated uncertainty, which can be used to simulate
controller executions via rollouts. We also describe set of techniques,
inspired by viewing PILCO as a recurrent neural network model, that are crucial
to improve the convergence of the method. We test our method on a variety of
benchmark tasks, demonstrating data-efficiency that is competitive with PILCO,
while being able to optimize complex neural network controllers. Finally, we
assess the performance of the algorithm for learning motor controllers for a
six legged autonomous underwater vehicle. This demonstrates the potential of
the algorithm for scaling up the dimensionality and dataset sizes, in more
complex control tasks.
",1,0,0,0,0,0
20597,Stealthy Deception Attacks Against SCADA Systems,"  SCADA protocols for Industrial Control Systems (ICS) are vulnerable to
network attacks such as session hijacking. Hence, research focuses on network
anomaly detection based on meta--data (message sizes, timing, command
sequence), or on the state values of the physical process. In this work we
present a class of semantic network-based attacks against SCADA systems that
are undetectable by the above mentioned anomaly detection. After hijacking the
communication channels between the Human Machine Interface (HMI) and
Programmable Logic Controllers (PLCs), our attacks cause the HMI to present a
fake view of the industrial process, deceiving the human operator into taking
manual actions. Our most advanced attack also manipulates the messages
generated by the operator's actions, reversing their semantic meaning while
causing the HMI to present a view that is consistent with the attempted human
actions. The attacks are totaly stealthy because the message sizes and timing,
the command sequences, and the data values of the ICS's state all remain
legitimate.
We implemented and tested several attack scenarios in the test lab of our
local electric company, against a real HMI and real PLCs, separated by a
commercial-grade firewall. We developed a real-time security assessment tool,
that can simultaneously manipulate the communication to multiple PLCs and cause
the HMI to display a coherent system--wide fake view. Our tool is configured
with message-manipulating rules written in an ICS Attack Markup Language (IAML)
we designed, which may be of independent interest. Our semantic attacks all
successfully fooled the operator and brought the system to states of blackout
and possible equipment damage.
",1,0,0,0,0,0
20598,Beta-rhythm oscillations and synchronization transition in network models of Izhikevich neurons: effect of topology and synaptic type,"  Despite their significant functional roles, beta-band oscillations are least
understood. Synchronization in neuronal networks have attracted much attention
in recent years with the main focus on transition type. Whether one obtains
explosive transition or a continuous transition is an important feature of the
neuronal network which can depend on network structure as well as synaptic
types. In this study we consider the effect of synaptic interaction (electrical
and chemical) as well as structural connectivity on synchronization transition
in network models of Izhikevich neurons which spike regularly with beta
rhythms. We find a wide range of behavior including continuous transition,
explosive transition, as well as lack of global order. The stronger electrical
synapses are more conducive to synchronization and can even lead to explosive
synchronization. The key network element which determines the order of
transition is found to be the clustering coefficient and not the small world
effect, or the existence of hubs in a network. These results are in contrast to
previous results which use phase oscillator models such as the Kuramoto model.
Furthermore, we show that the patterns of synchronization changes when one goes
to the gamma band. We attribute such a change to the change in the refractory
period of Izhikevich neurons which changes significantly with frequency.
",0,0,0,0,1,0
20599,Renyi Differential Privacy,"  We propose a natural relaxation of differential privacy based on the Renyi
divergence. Closely related notions have appeared in several recent papers that
analyzed composition of differentially private mechanisms. We argue that the
useful analytical tool can be used as a privacy definition, compactly and
accurately representing guarantees on the tails of the privacy loss.
We demonstrate that the new definition shares many important properties with
the standard definition of differential privacy, while additionally allowing
tighter analysis of composite heterogeneous mechanisms.
",1,0,0,0,0,0
20600,Enhancing Quality for VVC Compressed Videos by Jointly Exploiting Spatial Details and Temporal Structure,"  In this paper, we propose a quality enhancement network for Versatile Video
Coding (VVC) compressed videos by jointly exploiting spatial details and
temporal structure (SDTS). The network consists of a temporal structure
prediction subnet and a spatial detail enhancement subnet. The former subnet is
used to estimate and compensate the temporal motion across frames, and the
spatial detail subnet is used to reduce the compression artifacts and enhance
the reconstruction quality of the VVC compressed video. Experimental results
demonstrate the effectiveness of our SDTS-based approach. It offers over
7.82$\%$ BD-rate saving on the common test video sequences and achieves the
state-of-the-art performance.
",1,0,0,0,0,0
20601,Discrete CMC surfaces in R^3 and discrete minimal surfaces in S^3. A discrete Lawson correspondence,"  The main result of this paper is a discrete Lawson correspondence between
discrete CMC surfaces in R^3 and discrete minimal surfaces in S^3. This is a
correspondence between two discrete isothermic surfaces. We show that this
correspondence is an isometry in the following sense: it preserves the metric
coefficients introduced previously by Bobenko and Suris for isothermic nets.
Exactly as in the smooth case, this is a correspondence between nets with the
same Lax matrices, and the immersion formulas also coincide with the smooth
case.
",0,1,1,0,0,0
20602,Network Model Selection Using Task-Focused Minimum Description Length,"  Networks are fundamental models for data used in practically every
application domain. In most instances, several implicit or explicit choices
about the network definition impact the translation of underlying data to a
network representation, and the subsequent question(s) about the underlying
system being represented. Users of downstream network data may not even be
aware of these choices or their impacts. We propose a task-focused network
model selection methodology which addresses several key challenges. Our
approach constructs network models from underlying data and uses minimum
description length (MDL) criteria for selection. Our methodology measures
efficiency, a general and comparable measure of the network's performance of a
local (i.e. node-level) predictive task of interest. Selection on efficiency
favors parsimonious (e.g. sparse) models to avoid overfitting and can be
applied across arbitrary tasks and representations. We show stability,
sensitivity, and significance testing in our methodology.
",1,0,0,0,0,0
20603,Concentration of curvature and Lipschitz invariants of holomorphic functions of two variables,"  By combining analytic and geometric viewpoints on the concentration of the
curvature of the Milnor fibre, we prove that Lipschitz homeomorphisms preserve
the zones of multi-scale curvature concentration as well as the gradient canyon
structure of holomorphic functions of two variables. This yields the first new
Lipschitz invariants after those discovered by Henry and Parusinski in 2003.
",0,0,1,0,0,0
20604,Beam tuning and bunch length measurement in the bunch compression operation at the cERL,"  Realization of a short bunch beam by manipulating the longitudinal phase
space distribution with a finite longitudinal dispersion following an off-crest
accelera- tion is a widely used technique. The technique was applied in a
compact test accelerator of an energy-recovery linac scheme for compressing the
bunch length at the return loop. A diagnostic system utilizing coherent
transition radiation was developed for the beam tuning and for estimating the
bunch length. By scanning the beam parameters, we experimentally found the best
condition for the bunch compression. The RMS bunch length of 250+-50 fs was
obtained at a bunch charge of 2 pC. This result confirmed the design and the
tuning pro- cedure of the bunch compression operation for the future
energy-recovery linac (ERL).
",0,1,0,0,0,0
20605,Long-Lived Ultracold Molecules with Electric and Magnetic Dipole Moments,"  We create fermionic dipolar $^{23}$Na$^6$Li molecules in their triplet ground
state from an ultracold mixture of $^{23}$Na and $^6$Li. Using
magneto-association across a narrow Feshbach resonance followed by a two-photon
STIRAP transfer to the triplet ground state, we produce $3\,{\times}\,10^4$
ground state molecules in a spin-polarized state. We observe a lifetime of
$4.6\,\text{s}$ in an isolated molecular sample, approaching the $p$-wave
universal rate limit. Electron spin resonance spectroscopy of the triplet state
was used to determine the hyperfine structure of this previously unobserved
molecular state.
",0,1,0,0,0,0
20606,Bilinear generalized Radon transforms in the plane,"  Let $\sigma$ be arc-length measure on $S^1\subset \mathbb R^2$ and $\Theta$
denote rotation by an angle $\theta \in (0, \pi]$. Define a model bilinear
generalized Radon transform, $$B_{\theta}(f,g)(x)=\int_{S^1} f(x-y)g(x-\Theta
y)\, d\sigma(y),$$ an analogue of the linear generalized Radon transforms of
Guillemin and Sternberg \cite{GS} and Phong and Stein (e.g.,
\cite{PhSt91,St93}). Operators such as $B_\theta$ are motivated by problems in
geometric measure theory and combinatorics. For $\theta<\pi$, we show that
$B_{\theta}: L^p({\Bbb R}^2) \times L^q({\Bbb R}^2) \to L^r({\Bbb R}^2)$ if
$\left(\frac{1}{p},\frac{1}{q},\frac{1}{r}\right)\in Q$, the polyhedron with
the vertices $(0,0,0)$, $(\frac{2}{3}, \frac{2}{3}, 1)$, $(0, \frac{2}{3},
\frac{1}{3})$, $(\frac{2}{3},0,\frac{1}{3})$, $(1,0,1)$, $(0,1,1)$ and
$(\frac{1}{2},\frac{1}{2},\frac{1}{2})$, except for $\left(
\frac{1}{2},\frac{1}{2},\frac{1}{2} \right)$, where we obtain a restricted
strong type estimate. For the degenerate case $\theta=\pi$, a more restrictive
set of exponents holds. In the scale of normed spaces, $p,q,r \ge 1$, the type
set $Q$ is sharp. Estimates for the same exponents are also proved for a class
of bilinear generalized Radon transforms in $\mathbb R^2$ of the form $$
B(f,g)(x)=\int \int \delta(\phi_1(x,y)-t_1)\delta(\phi_2(x,z)-t_2)
\delta(\phi_3(y,z)-t_3) f(y)g(z) \psi(y,z) \, dy\, dz, $$ where $\delta$
denotes the Dirac distribution, $t_1,t_2,t_3\in\mathbb R$, $\psi$ is a smooth
cut-off and the defining functions $\phi_j$ satisfy some natural geometric
assumptions.
",0,0,1,0,0,0
20607,Diffusion of new products with recovering consumers,"  We consider the diffusion of new products in the discrete Bass-SIR model, in
which consumers who adopt the product can later ""recover"" and stop influencing
their peers to adopt the product. To gain insight into the effect of the social
network structure on the diffusion, we focus on two extreme cases. In the
""most-connected"" configuration where all consumers are inter-connected
(complete network), averaging over all consumers leads to an aggregate model,
which combines the Bass model for diffusion of new products with the SIR model
for epidemics. In the ""least-connected"" configuration where consumers are
arranged on a circle and each consumer can only be influenced by his left
neighbor (one-sided 1D network), averaging over all consumers leads to a
different aggregate model which is linear, and can be solved explicitly. We
conjecture that for any other network, the diffusion is bounded from below and
from above by that on a one-sided 1D network and on a complete network,
respectively. When consumers are arranged on a circle and each consumer can be
influenced by his left and right neighbors (two-sided 1D network), the
diffusion is strictly faster than on a one-sided 1D network. This is different
from the case of non-recovering adopters, where the diffusion on one-sided and
on two-sided 1D networks is identical. We also propose a nonlinear model for
recoveries, and show that consumers' heterogeneity has a negligible effect on
the aggregate diffusion.
",1,1,0,0,0,0
20608,Answering Complex Questions Using Open Information Extraction,"  While there has been substantial progress in factoid question-answering (QA),
answering complex questions remains challenging, typically requiring both a
large body of knowledge and inference techniques. Open Information Extraction
(Open IE) provides a way to generate semi-structured knowledge for QA, but to
date such knowledge has only been used to answer simple questions with
retrieval-based methods. We overcome this limitation by presenting a method for
reasoning with Open IE knowledge, allowing more complex questions to be
handled. Using a recently proposed support graph optimization framework for QA,
we develop a new inference model for Open IE, in particular one that can work
effectively with multiple short facts, noise, and the relational structure of
tuples. Our model significantly outperforms a state-of-the-art structured
solver on complex questions of varying difficulty, while also removing the
reliance on manually curated knowledge.
",1,0,0,0,0,0
20609,On Testing Quantum Programs,"  A quantum computer (QC) can solve many computational problems more
efficiently than a classic one. The field of QCs is growing: companies (such as
DWave, IBM, Google, and Microsoft) are building QC offerings. We position that
software engineers should look into defining a set of software engineering
practices that apply to QC's software. To start this process, we give examples
of challenges associated with testing such software and sketch potential
solutions to some of these challenges.
",1,0,0,0,0,0
20610,Degree weighted recurrence networks for the analysis of time series data,"  Recurrence networks are powerful tools used effectively in the nonlinear
analysis of time series data. The analysis in this context is done mostly with
unweighted and undirected complex networks constructed with specific criteria
from the time series. In this work, we propose a novel method to construct
""weighted recurrence network""(WRN) from a time series and show how it can
reveal useful information regarding the structure of a chaotic attractor, which
the usual unweighted recurrence network cannot provide. Especially, we find the
node strength distribution of the WRN, from every chaotic attractor follows a
power law (with exponential tail) with the index characteristic to the fractal
structure of the attractor. This leads to a new class among complex networks,
to which networks from all standard chaotic attractors are found to belong. In
addition, we present generalized definitions for clustering coefficient and
characteristic path length and show that these measures can effectively
discriminate chaotic dynamics from white noise and $1/f$ colored noise. Our
results indicate that the WRN and the associated measures can become
potentially important tools for the analysis of short and noisy time series
from the real world systems as they are clearly demarked from that of noisy or
stochastic systems.
",0,1,0,0,0,0
20611,Parcels v0.9: prototyping a Lagrangian Ocean Analysis framework for the petascale age,"  As Ocean General Circulation Models (OGCMs) move into the petascale age,
where the output from global high-resolution model runs can be of the order of
hundreds of terabytes in size, tools to analyse the output of these models will
need to scale up too. Lagrangian Ocean Analysis, where virtual particles are
tracked through hydrodynamic fields, is an increasingly popular way to analyse
OGCM output, by mapping pathways and connectivity of biotic and abiotic
particulates. However, the current software stack of Lagrangian Ocean Analysis
codes is not dynamic enough to cope with the increasing complexity, scale and
need for customisation of use-cases. Furthermore, most community codes are
developed for stand-alone use, making it a nontrivial task to integrate virtual
particles at runtime of the OGCM. Here, we introduce the new Parcels code,
which was designed from the ground up to be sufficiently scalable to cope with
petascale computing. We highlight its API design that combines flexibility and
customisation with the ability to optimise for HPC workflows, following the
paradigm of domain-specific languages. Parcels is primarily written in Python,
utilising the wide range of tools available in the scientific Python ecosystem,
while generating low-level C-code and using Just-In-Time compilation for
performance-critical computation. We show a worked-out example of its API, and
validate the accuracy of the code against seven idealised test cases. This
version~0.9 of Parcels is focussed on laying out the API, with future work
concentrating on optimisation, efficiency and at-runtime coupling with OGCMs.
",1,1,0,0,0,0
20612,TFLMS: Large Model Support in TensorFlow by Graph Rewriting,"  While accelerators such as GPUs have limited memory, deep neural networks are
becoming larger and will not fit with the memory limitation of accelerators for
training. We propose an approach to tackle this problem by rewriting the
computational graph of a neural network, in which swap-out and swap-in
operations are inserted to temporarily store intermediate results on CPU
memory. In particular, we first revise the concept of a computational graph by
defining a concrete semantics for variables in a graph. We then formally show
how to derive swap-out and swap-in operations from an existing graph and
present rules to optimize the graph. To realize our approach, we developed a
module in TensorFlow, named TFLMS. TFLMS is published as a pull request in the
TensorFlow repository for contributing to the TensorFlow community. With TFLMS,
we were able to train ResNet-50 and 3DUnet with 4.7x and 2x larger batch size,
respectively. In particular, we were able to train 3DUNet using images of size
of $192^3$ for image segmentation, which, without TFLMS, had been done only by
dividing the images to smaller images, which affects the accuracy.
",0,0,0,1,0,0
20613,Machine Learning for Quantum Dynamics: Deep Learning of Excitation Energy Transfer Properties,"  Understanding the relationship between the structure of light-harvesting
systems and their excitation energy transfer properties is of fundamental
importance in many applications including the development of next generation
photovoltaics. Natural light harvesting in photosynthesis shows remarkable
excitation energy transfer properties, which suggests that pigment-protein
complexes could serve as blueprints for the design of nature inspired devices.
Mechanistic insights into energy transport dynamics can be gained by leveraging
numerically involved propagation schemes such as the hierarchical equations of
motion (HEOM). Solving these equations, however, is computationally costly due
to the adverse scaling with the number of pigments. Therefore virtual
high-throughput screening, which has become a powerful tool in material
discovery, is less readily applicable for the search of novel excitonic
devices. We propose the use of artificial neural networks to bypass the
computational limitations of established techniques for exploring the
structure-dynamics relation in excitonic systems. Once trained, our neural
networks reduce computational costs by several orders of magnitudes. Our
predicted transfer times and transfer efficiencies exhibit similar or even
higher accuracies than frequently used approximate methods such as secular
Redfield theory
",0,1,0,1,0,0
20614,Multi-Player Bandits: A Trekking Approach,"  We study stochastic multi-armed bandits with many players. The players do not
know the number of players, cannot communicate with each other and if multiple
players select a common arm they collide and none of them receive any reward.
We consider the static scenario, where the number of players remains fixed, and
the dynamic scenario, where the players enter and leave at any time. We provide
algorithms based on a novel `trekking approach' that guarantees constant regret
for the static case and sub-linear regret for the dynamic case with high
probability. The trekking approach eliminates the need to estimate the number
of players resulting in fewer collisions and improved regret performance
compared to the state-of-the-art algorithms. We also develop an epoch-less
algorithm that eliminates any requirement of time synchronization across the
players provided each player can detect the presence of other players on an
arm. We validate our theoretical guarantees using simulation based and real
test-bed based experiments.
",0,0,0,1,0,0
20615,High-resolution investigation of spinal cord and spine,"  High-resolution non-invasive 3D study of intact spine and spinal cord
morphology on the level of complex vascular and neuronal organization is a
crucial issue for the development of treatments for the injuries and
pathologies of central nervous system (CNS). X-ray phase contrast tomography
enables high quality 3D visualization in ex-vivo mouse model of both vascular
and neuronal network of the soft spinal cord tissue at the scale from
millimeters to hundreds of nanometers without any contrast agents and
sectioning. Until now, 3D high resolution visualization of spinal cord mostly
has been limited by imaging of organ extracted from vertebral column because
high absorbing boney tissue drastically reduces the morphological details of
soft tissue in image. However, the extremely destructive procedure of bones
removal leads to sample deterioration and, therefore, to the lack of
considerable part of information about the object. In this work we present the
data analysis procedure to get high resolution and high contrast 3D images of
intact mice spinal cord surrounded by vertebras, preserving all richness of
micro-details of the spinal cord inhabiting inside. Our results are the first
step forward to the difficult way toward the high- resolution investigation of
in-vivo model central nervous system.
",0,1,0,0,0,0
20616,Bohr--Rogosinski radius for analytic functions,"  There are a number of articles which deal with Bohr's phenomenon whereas only
a few papers appeared in the literature on Rogosinski's radii for analytic
functions defined on the unit disk $|z|<1$. In this article, we introduce and
investigate Bohr-Rogosinski's radii for analytic functions defined for $|z|<1$.
Also, we prove several different improved versions of the classical Bohr's
inequality. Finally, we also discuss the Bohr-Rogosinski's radius for a class
of subordinations. All the results are proved to be sharp.
",0,0,1,0,0,0
20617,Methods to locate Saddle Points in Complex Landscapes,"  We present a class of simple algorithms that allows to find the reaction path
in systems with a complex potential energy landscape. The approach does not
need any knowledge on the product state and does not require the calculation of
any second derivatives. The underlying idea is to use two nearby points in
configuration space to locate the path of slowest ascent. By introducing a weak
noise term, the algorithm is able to find even low-lying saddle points that are
not reachable by means of a slowest ascent path. Since the algorithm makes only
use of the value of the potential and its gradient, the computational effort to
find saddles is linear in the number of degrees of freedom, if the potential is
short-ranged. We test the performance of the algorithm for two potential energy
landscapes. For the Müller-Brown surface we find that the algorithm always
finds the correct saddle point. For the modified Müller-Brown surface, which
has a saddle point that is not reachable by means of a slowest ascent path, the
algorithm is still able to find this saddle point with high probability.
",0,1,0,0,0,0
20618,On the Complexity of Opinions and Online Discussions,"  In an increasingly polarized world, demagogues who reduce complexity down to
simple arguments based on emotion are gaining in popularity. Are opinions and
online discussions falling into demagoguery? In this work, we aim to provide
computational tools to investigate this question and, by doing so, explore the
nature and complexity of online discussions and their space of opinions,
uncovering where each participant lies.
More specifically, we present a modeling framework to construct latent
representations of opinions in online discussions which are consistent with
human judgements, as measured by online voting. If two opinions are close in
the resulting latent space of opinions, it is because humans think they are
similar. Our modeling framework is theoretically grounded and establishes a
surprising connection between opinions and voting models and the sign-rank of a
matrix. Moreover, it also provides a set of practical algorithms to both
estimate the dimension of the latent space of opinions and infer where opinions
expressed by the participants of an online discussion lie in this space.
Experiments on a large dataset from Yahoo! News, Yahoo! Finance, Yahoo! Sports,
and the Newsroom app suggest that unidimensional opinion models may often be
unable to accurately represent online discussions, provide insights into human
judgements and opinions, and show that our framework is able to circumvent
language nuances such as sarcasm or humor by relying on human judgements
instead of textual analysis.
",1,0,0,1,0,0
20619,Free energy distribution of the stationary O'Connell-Yor directed random polymer model,"  We study the semi-discrete directed polymer model introduced by O'Connell-Yor
in its stationary regime, based on our previous work on the stationary
$q$-totally asymmetric simple exclusion process ($q$-TASEP) using a two-sided
$q$-Whittaker process. We give a formula for the free energy distribution of
the polymer model in terms of Fredholm determinant and show that the universal
KPZ stationary distribution appears in the long time limit. We also consider
the limit to the stationary KPZ equation and discuss the connections with
previously found formulas.
",0,1,1,0,0,0
20620,Personalized Gaussian Processes for Forecasting of Alzheimer's Disease Assessment Scale-Cognition Sub-Scale (ADAS-Cog13),"  In this paper, we introduce the use of a personalized Gaussian Process model
(pGP) to predict per-patient changes in ADAS-Cog13 -- a significant predictor
of Alzheimer's Disease (AD) in the cognitive domain -- using data from each
patient's previous visits, and testing on future (held-out) data. We start by
learning a population-level model using multi-modal data from previously seen
patients using a base Gaussian Process (GP) regression. The personalized GP
(pGP) is formed by adapting the base GP sequentially over time to a new
(target) patient using domain adaptive GPs. We extend this personalized
approach to predict the values of ADAS-Cog13 over the future 6, 12, 18, and 24
months. We compare this approach to a GP model trained only on past data of the
target patients (tGP), as well as to a new approach that combines pGP with tGP.
We find that the new approach, combining pGP with tGP, leads to large
improvements in accurately forecasting future ADAS-Cog13 scores.
",0,0,0,1,0,0
20621,Analysis and Control of a Non-Standard Hyperbolic PDE Traffic Flow Model,"  The paper provides results for a non-standard, hyperbolic, 1-D, nonlinear
traffic flow model on a bounded domain. The model consists of two first-order
PDEs with a dynamic boundary condition that involves the time derivative of the
velocity. The proposed model has features that are important from a
traffic-theoretic point of view: is completely anisotropic and information
travels forward exactly at the same speed as traffic. It is shown that, for all
physically meaningful initial conditions, the model admits a globally defined,
unique, classical solution that remains positive and bounded for all times.
Moreover, it is shown that global stabilization can be achieved for arbitrary
equilibria by means of an explicit boundary feedback law. The stabilizing
feedback law depends only on the inlet velocity and consequently, the
measurement requirements for the implementation of the proposed boundary
feedback law are minimal. The efficiency of the proposed boundary feedback law
is demonstrated by means of a numerical example.
",1,0,1,0,0,0
20622,Learning Robust Representations for Computer Vision,"  Unsupervised learning techniques in computer vision often require learning
latent representations, such as low-dimensional linear and non-linear
subspaces. Noise and outliers in the data can frustrate these approaches by
obscuring the latent spaces.
Our main goal is deeper understanding and new development of robust
approaches for representation learning. We provide a new interpretation for
existing robust approaches and present two specific contributions: a new robust
PCA approach, which can separate foreground features from dynamic background,
and a novel robust spectral clustering method, that can cluster facial images
with high accuracy. Both contributions show superior performance to standard
methods on real-world test sets.
",1,0,0,1,0,0
20623,Detection Estimation and Grid matching of Multiple Targets with Single Snapshot Measurements,"  In this work, we explore the problems of detecting the number of narrow-band,
far-field targets and estimating their corresponding directions from single
snapshot measurements. The principles of sparse signal recovery (SSR) are used
for the single snapshot detection and estimation of multiple targets. In the
SSR framework, the DoA estimation problem is grid based and can be posed as the
lasso optimization problem. However, the SSR framework for DoA estimation gives
rise to the grid mismatch problem, when the unknown targets (sources) are not
matched with the estimation grid chosen for the construction of the array
steering matrix at the receiver. The block sparse recovery framework is known
to mitigate the grid mismatch problem by jointly estimating the targets and
their corresponding offsets from the estimation grid using the group lasso
estimator. The corresponding detection problem reduces to estimating the
optimal regularization parameter ($\tau$) of the lasso (in case of perfect
grid-matching) or group-lasso estimation problem for achieving the required
probability of correct detection ($P_c$). We propose asymptotic and finite
sample test statistics for detecting the number of sources with the required
$P_c$ at moderate to high signal to noise ratios. Once the number of sources
are detected, or equivalently the optimal $\hat{\tau}$ is estimated, the
corresponding estimation and grid matching of the DoAs can be performed by
solving the lasso or group-lasso problem at $\hat{\tau}$
",0,0,0,1,0,0
20624,Small-Variance Asymptotics for Nonparametric Bayesian Overlapping Stochastic Blockmodels,"  The latent feature relational model (LFRM) is a generative model for
graph-structured data to learn a binary vector representation for each node in
the graph. The binary vector denotes the node's membership in one or more
communities. At its core, the LFRM miller2009nonparametric is an overlapping
stochastic blockmodel, which defines the link probability between any pair of
nodes as a bilinear function of their community membership vectors. Moreover,
using a nonparametric Bayesian prior (Indian Buffet Process) enables learning
the number of communities automatically from the data. However, despite its
appealing properties, inference in LFRM remains a challenge and is typically
done via MCMC methods. This can be slow and may take a long time to converge.
In this work, we develop a small-variance asymptotics based framework for the
non-parametric Bayesian LFRM. This leads to an objective function that retains
the nonparametric Bayesian flavor of LFRM, while enabling us to design
deterministic inference algorithms for this model, that are easy to implement
(using generic or specialized optimization routines) and are fast in practice.
Our results on several benchmark datasets demonstrate that our algorithm is
competitive to methods such as MCMC, while being much faster.
",0,0,0,1,0,0
20625,Towards a Science of Mind,"  The ancient mind/body problem continues to be one of deepest mysteries of
science and of the human spirit. Despite major advances in many fields, there
is still no plausible link between subjective experience (qualia) and its
realization in the body. This paper outlines some of the elements of a rigorous
science of mind (SoM) - key ideas include scientific realism of mind, agnostic
mysterianism, careful attention to language, and a focus on concrete
(touchstone) questions and results.
",1,0,0,0,1,0
20626,Resistance distance criterion for optimal slack bus selection,"  We investigate the dependence of transmission losses on the choice of a slack
bus in high voltage AC transmission networks. We formulate a transmission loss
minimization problem in terms of slack variables representing the additional
power injection that each generator provides to compensate the transmission
losses. We show analytically that for transmission lines having small,
homogeneous resistance over reactance ratios ${r/x\ll1}$, transmission losses
are generically minimal in the case of a unique \textit{slack bus} instead of a
distributed slack bus. For the unique slack bus scenario, to lowest order in
${r/x}$, transmission losses depend linearly on a resistance distance based
indicator measuring the separation of the slack bus candidate from the rest of
the network. We confirm these results numerically for several IEEE and Pegase
testcases, and show that our predictions qualitatively hold also in the case of
lines having inhomogeneous ${r/x}$ ratios, with optimal slack bus choices
reducing transmission losses by ${10}\%$ typically.
",1,1,0,0,0,0
20627,Interpolation in the Presence of Domain Inhomogeneity,"  Standard interpolation techniques are implicitly based on the assumption that
the signal lies on a homogeneous domain. In this letter, the proposed
interpolation method instead exploits prior information about domain
inhomogeneity, characterized by different, potentially overlapping, subdomains.
By introducing a domain-similarity metric for each sample, the interpolation
process is then based on a domain-informed consistency principle. We illustrate
and demonstrate the feasibility of domain-informed linear interpolation in 1D,
and also, on a real fMRI image in 2D. The results show the benefit of
incorporating domain knowledge so that, for example, sharp domain boundaries
can be recovered by the interpolation, if such information is available.
",0,0,1,0,0,0
20628,Lectures on the mean values of functionals -- An elementary introduction to infinite-dimensional probability,"  This is an elementary introduction to infinite-dimensional probability. In
the lectures, we compute the exact mean values of some functionals on C[0,1]
and L[0,1] by considering these functionals as infinite-dimensional random
variables. The results show that there exist the complete concentration of
measure phenomenon for these mean values since the variances are all zeroes.
",0,1,1,1,0,0
20629,Synthesis of Optimal Resilient Control Strategies,"  Repair mechanisms are important within resilient systems to maintain the
system in an operational state after an error occurred. Usually, constraints on
the repair mechanisms are imposed, e.g., concerning the time or resources
required (such as energy consumption or other kinds of costs). For systems
modeled by Markov decision processes (MDPs), we introduce the concept of
resilient schedulers, which represent control strategies guaranteeing that
these constraints are always met within some given probability. Assigning
rewards to the operational states of the system, we then aim towards resilient
schedulers which maximize the long-run average reward, i.e., the expected mean
payoff. We present a pseudo-polynomial algorithm that decides whether a
resilient scheduler exists and if so, yields an optimal resilient scheduler. We
show also that already the decision problem asking whether there exists a
resilient scheduler is PSPACE-hard.
",1,0,0,0,0,0
20630,Limits of the Kucera-Gacs coding method,"  Every real is computable from a Martin-Loef random real. This well known
result in algorithmic randomness was proved by Kucera and Gacs. In this survey
article we discuss various approaches to the problem of coding an arbitrary
real into a Martin-Loef random real,and also describe new results concerning
optimal methods of coding. We start with a simple presentation of the original
methods of Kucera and Gacs and then rigorously demonstrate their limitations in
terms of the size of the redundancy in the codes that they produce. Armed with
a deeper understanding of these methods, we then proceed to motivate and
illustrate aspects of the new coding method that was recently introduced by
Barmpalias and Lewis-Pye and which achieves optimal logarithmic redundancy, an
exponential improvement over the original redundancy bounds.
",0,0,1,0,0,0
20631,Subspace Tracking Algorithms for Millimeter Wave MIMO Channel Estimation with Hybrid Beamforming,"  This paper proposes the use of subspace tracking algorithms for performing
MIMO channel estimation at millimeter wave (mmWave) frequencies. Using a
subspace approach, we develop a protocol enabling the estimation of the right
(resp. left) singular vectors at the transmitter (resp. receiver) side; then,
we adapt the projection approximation subspace tracking with deflation (PASTd)
and the orthogonal Oja (OOJA) algorithms to our framework and obtain two
channel estimation algorithms. The hybrid analog/digital nature of the
beamformer is also explicitly taken into account at the algorithm design stage.
Numerical results show that the proposed estimation algorithms are effective,
and that they perform better than two relevant competing alternatives available
in the open literature.
",1,0,0,0,0,0
20632,Thomas Precession for Dressed Particles,"  We consider a particle dressed with boundary gravitons in three-dimensional
Minkowski space. The existence of BMS transformations implies that the
particle's wavefunction picks up a Berry phase when subjected to changes of
reference frames that trace a closed path in the asymptotic symmetry group. We
evaluate this phase and show that, for BMS superrotations, it provides a
gravitational generalization of Thomas precession. In principle, such phases
are observable signatures of asymptotic symmetries.
",0,1,1,0,0,0
20633,Exponential random graphs behave like mixtures of stochastic block models,"  We study the behavior of exponential random graphs in both the sparse and the
dense regime. We show that exponential random graphs are approximate mixtures
of graphs with independent edges whose probability matrices are critical points
of an associated functional, thereby satisfying a certain matrix equation. In
the dense regime, every solution to this equation is close to a block matrix,
concluding that the exponential random graph behaves roughly like a mixture of
stochastic block models. We also show existence and uniqueness of solutions to
this equation for several families of exponential random graphs, including the
case where the subgraphs are counted with positive weights and the case where
all weights are small in absolute value. In particular, this generalizes some
of the results in a paper by Chatterjee and Diaconis from the dense regime to
the sparse regime and strengthens their bounds from the cut-metric to the
one-metric.
",1,0,1,1,0,0
20634,Certificate Enhanced Data-Flow Analysis,"  Proof-carrying-code was proposed as a solution to ensure a trust relationship
between two parties: a (heavyweight) analyzer and a (lightweight) checker. The
analyzer verifies the conformance of a given application to a specified
property and generates a certificate attesting the validity of the analysis
result. It suffices then for the checker just to test the consistency of the
proof instead of constructing it. We set out to study the applicability of this
technique in the context of data- flow analysis. In particular, we want to know
if there is a significant performance difference between the analyzer and the
checker. Therefore, we developed a tool, called DCert, implementing an
inter-procedural context and flow-sensitive data-flow analyzer and checker for
Android. Applying our tool to real-world large applications, we found out that
checking can be up to 8 times faster than verification. This important gain in
time suggests a potential for equipping applications on app stores with
certificates that can be checked on mobile devices which are limited in
computation and storage resources. We describe our implementation and report on
experimental results.
",1,0,0,0,0,0
20635,Small cells in a Poisson hyperplane tessellation,"  Until now, little was known about properties of small cells in a Poisson
hyperplane tessellation. The few existing results were either heuristic or
applying only to the two dimensional case and for very specific size
functionals and directional distributions. This paper fills this gap by
providing a systematic study of small cells in a Poisson hyperplane
tessellation of arbitrary dimension, arbitrary directional distribution
$\varphi$ and with respect to an arbitrary size functional $\Sigma$. More
precisely, we investigate the distribution of the typical cell $Z$, conditioned
on the event $\{\Sigma(Z)<a\}$, where $a\to0$ and $\Sigma$ is a size
functional, i.e. a functional on the set of convex bodies which is continuous,
not identically zero, homogeneous of degree $k>0$, and increasing with respect
to set inclusion. We focus on the number of facets and the shape of such small
cells. We show in various general settings that small cells tend to minimize
the number of facets and that they have a non degenerated limit shape
distribution which depends on the size $\Sigma$ and the directional
distribution. We also exhibit a class of directional distribution for which
cells with small inradius do not tend to minimize the number of facets.
",0,0,1,0,0,0
20636,Privacy-Aware Guessing Efficiency,"  We investigate the problem of guessing a discrete random variable $Y$ under a
privacy constraint dictated by another correlated discrete random variable $X$,
where both guessing efficiency and privacy are assessed in terms of the
probability of correct guessing. We define $h(P_{XY}, \epsilon)$ as the maximum
probability of correctly guessing $Y$ given an auxiliary random variable $Z$,
where the maximization is taken over all $P_{Z|Y}$ ensuring that the
probability of correctly guessing $X$ given $Z$ does not exceed $\epsilon$. We
show that the map $\epsilon\mapsto h(P_{XY}, \epsilon)$ is strictly increasing,
concave, and piecewise linear, which allows us to derive a closed form
expression for $h(P_{XY}, \epsilon)$ when $X$ and $Y$ are connected via a
binary-input binary-output channel. For $(X^n, Y^n)$ being pairs of independent
and identically distributed binary random vectors, we similarly define
$\underline{h}_n(P_{X^nY^n}, \epsilon)$ under the assumption that $Z^n$ is also
a binary vector. Then we obtain a closed form expression for
$\underline{h}_n(P_{X^nY^n}, \epsilon)$ for sufficiently large, but nontrivial
values of $\epsilon$.
",1,0,1,1,0,0
20637,Positioning services of a travel agency in social networks,"  In this paper the methods of forming a travel company customer base by means
of social networks are observed. These methods are made to involve web-users of
the social networks (VK.com and Facebook) for positioning of the service of the
travel agency ""New Europe"" on the Internet. The methods of applying the
maintenance activities and interests of web-users are also used. So, the main
method of information exchanging in modern network society is on-line social
networks. The rapid development and improvement of such information and
communication technologies is a key factor in the positioning of the travel
agency brand in the global information space. The absence of time and space
restrictions and the speed of spreading of the information among an aim
audience of social networks create all the conditions for effective
popularization of the travel agency ""New Europe"" and its service in the
Internet.
",1,0,0,0,0,0
20638,Inverse Mapping for Rainfall-Runoff Models using History Matching Approach,"  In this paper, we consider two rainfall-runoff computer models. The first
model is Matlab-Simulink model which simulates runoff from windrow compost pad
(located at the Bioconversion Center in Athens, GA) over a period of time based
on rainfall events. The second model is Soil Water Assessment Tool (SWAT) which
estimates surface runoff in the Middle Oconee River in Athens, GA. The input
parameter spaces of both models are sensitive and high dimensional, the model
output for every input combination is a time-series of runoff, and these two
computer models generate a wide spectrum of outputs including some that are far
from reality. In order to improve the prediction accuracy, in this paper we
propose to apply a history matching approach for calibrating these hydrological
models, which also gives better insights for improved management of these
systems.
",0,0,0,1,0,0
20639,Geometric SMOTE: Effective oversampling for imbalanced learning through a geometric extension of SMOTE,"  Classification of imbalanced datasets is a challenging task for standard
algorithms. Although many methods exist to address this problem in different
ways, generating artificial data for the minority class is a more general
approach compared to algorithmic modifications. SMOTE algorithm and its
variations generate synthetic samples along a line segment that joins minority
class instances. In this paper we propose Geometric SMOTE (G-SMOTE) as a
generalization of the SMOTE data generation mechanism. G-SMOTE generates
synthetic samples in a geometric region of the input space, around each
selected minority instance. While in the basic configuration this region is a
hyper-sphere, G-SMOTE allows its deformation to a hyper-spheroid and finally to
a line segment, emulating, in the last case, the SMOTE mechanism. The
performance of G-SMOTE is compared against multiple standard oversampling
algorithms. We present empirical results that show a significant improvement in
the quality of the generated data when G-SMOTE is used as an oversampling
algorithm.
",1,0,0,0,0,0
20640,Liveness Verification and Synthesis: New Algorithms for Recursive Programs,"  We consider the problems of liveness verification and liveness synthesis for
recursive programs. The liveness verification problem (LVP) is to decide
whether a given omega-context-free language is contained in a given
omega-regular language. The liveness synthesis problem (LSP) is to compute a
strategy so that a given omega-context-free game, when played along the
strategy, is guaranteed to derive a word in a given omega-regular language. The
problems are known to be EXPTIME-complete and EXPTIME-complete, respectively.
Our contributions are new algorithms with optimal time complexity. For LVP, we
generalize recent lasso-finding algorithms (also known as Ramsey-based
algorithms) from finite to recursive programs. For LSP, we generalize a recent
summary-based algorithm from finite to infinite words. Lasso finding and
summaries have proven to be efficient in a number of implementations for the
finite state and finite word setting.
",1,0,0,0,0,0
20641,A semiparametric approach for bivariate extreme exceedances,"  Inference over tails is performed by applying only the results of extreme
value theory. Whilst such theory is well defined and flexible enough in the
univariate case, multivariate inferential methods often require the imposition
of arbitrary constraints not fully justifed by the underlying theory. In
contrast, our approach uses only the constraints imposed by theory. We build on
previous, theoretically justified work for marginal exceedances over a high,
unknown threshold, by combining it with flexible, semiparametric copulae
specifications to investigate extreme dependence. Whilst giving probabilistic
judgements about the extreme regime of all marginal variables, our approach
formally uses the full dataset and allows for a variety of patterns of
dependence, be them extremal or not. A new probabilistic criterion quantifying
the possibility that the data exhibits asymptotic independence is introduced
and its robustness empirically studied. Estimation of functions of interest in
extreme value analyses is performed via MCMC algorithms. Attention is also
devoted to the prediction of new extreme observations. Our approach is
evaluated through a series of simulations, applied to real data sets and
assessed against competing approaches. Evidence demonstrates that the bulk of
the data does not bias and improves the inferential process for the extremal
dependence.
",0,0,0,1,0,0
20642,Prolongation of SMAP to Spatio-temporally Seamless Coverage of Continental US Using a Deep Learning Neural Network,"  The Soil Moisture Active Passive (SMAP) mission has delivered valuable
sensing of surface soil moisture since 2015. However, it has a short time span
and irregular revisit schedule. Utilizing a state-of-the-art time-series deep
learning neural network, Long Short-Term Memory (LSTM), we created a system
that predicts SMAP level-3 soil moisture data with atmospheric forcing,
model-simulated moisture, and static physiographic attributes as inputs. The
system removes most of the bias with model simulations and improves predicted
moisture climatology, achieving small test root-mean-squared error (<0.035) and
high correlation coefficient >0.87 for over 75\% of Continental United States,
including the forested Southeast. As the first application of LSTM in
hydrology, we show the proposed network avoids overfitting and is robust for
both temporal and spatial extrapolation tests. LSTM generalizes well across
regions with distinct climates and physiography. With high fidelity to SMAP,
LSTM shows great potential for hindcasting, data assimilation, and weather
forecasting.
",0,0,0,1,0,0
20643,Note on Green Function Formalism and Topological Invariants,"  It has been discovered previously that the topological order parameter could
be identified from the topological data of the Green function, namely the
(generalized) TKNN invariant in general dimensions, for both non-interacting
and interacting systems. In this note, we show that this phenomena has a clear
geometric derivation. This proposal could be regarded as an alternative proof
for the identification of the corresponding topological invariant and
topological order parameter.
",0,0,1,0,0,0
20644,Unsupervised Document Embedding With CNNs,"  We propose a new model for unsupervised document embedding. Leading existing
approaches either require complex inference or use recurrent neural networks
(RNN) that are difficult to parallelize. We take a different route and develop
a convolutional neural network (CNN) embedding model. Our CNN architecture is
fully parallelizable resulting in over 10x speedup in inference time over RNN
models. Parallelizable architecture enables to train deeper models where each
successive layer has increasingly larger receptive field and models longer
range semantic structure within the document. We additionally propose a fully
unsupervised learning algorithm to train this model based on stochastic forward
prediction. Empirical results on two public benchmarks show that our approach
produces comparable to state-of-the-art accuracy at a fraction of computational
cost.
",1,0,0,1,0,0
20645,A metric model for the functional architecture of the visual cortex,"  The purpose of this work is to construct a model for the functional
architecture of the primary visual cortex (V1), based on a structure of metric
measure space induced by the underlying organization of receptive profiles
(RPs) of visual cells. In order to account for the horizontal connectivity of
V1 in such a context, a diffusion process compatible with the geometry of the
space is defined following the classical approach of K.-T. Sturm. The
construction of our distance function does neither require any group
parameterization of the family of RPs, nor involve any differential structure.
As such, it adapts to non-parameterized sets of RPs, possibly obtained through
numerical procedures; it also allows to model the lateral connectivity arising
from non-differential metrics such as the one induced on a pinwheel surface by
a family of filters of vanishing scale. On the other hand, when applied to the
classical framework of Gabor filters, this construction yields a distance
approximating the sub-Riemannian structure proposed as a model for V1 by G.
Citti and A. Sarti [J Math Imaging Vis 24: 307 (2006)], thus showing itself to
be consistent with existing cortex models.
",0,0,0,0,1,0
20646,Bayesian parameter identification in Cahn-Hilliard models for biological growth,"  We consider the inverse problem of parameter estimation in a diffuse
interface model for tumour growth. The model consists of a fourth-order
Cahn--Hilliard system and contains three phenomenological parameters: the
tumour proliferation rate, the nutrient consumption rate, and the chemotactic
sensitivity. We study the inverse problem within the Bayesian framework and
construct the likelihood and noise for two typical observation settings. One
setting involves an infinite-dimensional data space where we observe the full
tumour. In the second setting we observe only the tumour volume, hence the data
space is finite-dimensional. We show the well-posedness of the posterior
measure for both settings, building upon and improving the analytical results
in [C. Kahle and K.F. Lam, Appl. Math. Optim. (2018)]. A numerical example
involving synthetic data is presented in which the posterior measure is
numerically approximated by the Sequential Monte Carlo approach with tempering.
",0,0,0,1,0,0
20647,Transport Phase Diagram and Anderson Localization in Hyperuniform Disordered Photonic Materials,"  Hyperuniform disordered photonic materials (HDPM) are spatially correlated
dielectric structures with unconventional optical properties. They can be
transparent to long-wavelength radiation while at the same time have isotropic
band gaps in another frequency range. This phenomenon raises fundamental
questions concerning photon transport through disordered media. While optical
transparency is robust against recurrent multiple scattering, little is known
about other transport regimes like diffusive multiple scattering or Anderson
localization. Here we investigate band gaps, and we report Anderson
localization in two-dimensional stealthy HDPM using numerical simulations of
the density of states and optical transport statistics. To establish a unified
view, we propose a transport phase diagram. Our results show that, depending
only on the degree of correlation, a dielectric material can transition from
localization behavior to a bandgap crossing an intermediate regime dominated by
tunneling between weakly coupled states.
",0,1,0,0,0,0
20648,Nearly Maximally Predictive Features and Their Dimensions,"  Scientific explanation often requires inferring maximally predictive features
from a given data set. Unfortunately, the collection of minimal maximally
predictive features for most stochastic processes is uncountably infinite. In
such cases, one compromises and instead seeks nearly maximally predictive
features. Here, we derive upper-bounds on the rates at which the number and the
coding cost of nearly maximally predictive features scales with desired
predictive power. The rates are determined by the fractal dimensions of a
process' mixed-state distribution. These results, in turn, show how widely-used
finite-order Markov models can fail as predictors and that mixed-state
predictive features offer a substantial improvement.
",1,1,0,1,0,0
20649,A Survey Of Cross-lingual Word Embedding Models,"  Cross-lingual representations of words enable us to reason about word meaning
in multilingual contexts and are a key facilitator of cross-lingual transfer
when developing natural language processing models for low-resource languages.
In this survey, we provide a comprehensive typology of cross-lingual word
embedding models. We compare their data requirements and objective functions.
The recurring theme of the survey is that many of the models presented in the
literature optimize for the same objectives, and that seemingly different
models are often equivalent modulo optimization strategies, hyper-parameters,
and such. We also discuss the different ways cross-lingual word embeddings are
evaluated, as well as future challenges and research horizons.
",1,0,0,0,0,0
20650,Space-efficient classical and quantum algorithms for the shortest vector problem,"  A lattice is the integer span of some linearly independent vectors. Lattice
problems have many significant applications in coding theory and cryptographic
systems for their conjectured hardness. The Shortest Vector Problem (SVP),
which is to find the shortest non-zero vector in a lattice, is one of the
well-known problems that are believed to be hard to solve, even with a quantum
computer. In this paper we propose space-efficient classical and quantum
algorithms for solving SVP. Currently the best time-efficient algorithm for
solving SVP takes $2^{n+o(n)}$ time and $2^{n+o(n)}$ space. Our classical
algorithm takes $2^{2.05n+o(n)}$ time to solve SVP with only $2^{0.5n+o(n)}$
space. We then modify our classical algorithm to a quantum version, which can
solve SVP in time $2^{1.2553n+o(n)}$ with $2^{0.5n+o(n)}$ classical space and
only poly(n) qubits.
",1,0,0,0,0,0
20651,Low Power SI Class E Power Amplifier and RF Switch For Health Care,"  This research was to design a 2.4 GHz class E Power Amplifier (PA) for health
care, with 0.18um Semiconductor Manufacturing International Corporation CMOS
technology by using Cadence software. And also RF switch was designed at
cadence software with power Jazz 180nm SOI process. The ultimate goal for such
application is to reach high performance and low cost, and between high
performance and low power consumption design. This paper introduces the design
of a 2.4GHz class E power amplifier and RF switch design. PA consists of
cascade stage with negative capacitance. This power amplifier can transmit
16dBm output power to a 50{\Omega} load. The performance of the power amplifier
and switch meet the specification requirements of the desired.
",1,0,0,0,0,0
20652,Improved approximation algorithm for the Dense-3-Subhypergraph Problem,"  The study of Dense-$3$-Subhypergraph problem was initiated in Chlamt{á}c
et al. [Approx'16]. The input is a universe $U$ and collection ${\cal S}$ of
subsets of $U$, each of size $3$, and a number $k$. The goal is to choose a set
$W$ of $k$ elements from the universe, and maximize the number of sets, $S\in
{\cal S}$ so that $S\subseteq W$. The members in $U$ are called {\em vertices}
and the sets of ${\cal S}$ are called the {\em hyperedges}. This is the
simplest extension into hyperedges of the case of sets of size $2$ which is the
well known Dense $k$-subgraph problem.
The best known ratio for the Dense-$3$-Subhypergraph is $O(n^{0.69783..})$ by
Chlamt{á}c et al. We improve this ratio to $n^{0.61802..}$. More
importantly, we give a new algorithm that approximates Dense-$3$-Subhypergraph
within a ratio of $\tilde O(n/k)$, which improves the ratio of $O(n^2/k^2)$ of
Chlamt{á}c et al.
We prove that under the {\em log density conjecture} (see Bhaskara et al.
[STOC'10]) the ratio cannot be better than $\Omega(\sqrt{n})$ and demonstrate
some cases in which this optimum can be attained.
",1,0,0,0,0,0
20653,A Survey of Security Assessment Ontologies,"  A literature survey on ontologies concerning the Security Assessment domain
has been carried out to uncover initiatives that aim at formalizing concepts
from the Security Assessment field of research. A preliminary analysis and a
discussion on the selected works are presented. Our main contribution is an
updated literature review, describing key characteristics, results, research
issues, and application domains of the papers. We have also detected gaps in
the Security Assessment literature that could be the subject of further studies
in the field. This work is meant to be useful for security researchers who wish
to adopt a formal approach in their methods.
",1,0,0,0,0,0
20654,Distributed Online Learning of Event Definitions,"  Logic-based event recognition systems infer occurrences of events in time
using a set of event definitions in the form of first-order rules. The Event
Calculus is a temporal logic that has been used as a basis in event recognition
applications, providing among others, direct connections to machine learning,
via Inductive Logic Programming (ILP). OLED is a recently proposed ILP system
that learns event definitions in the form of Event Calculus theories, in a
single pass over a data stream. In this work we present a version of OLED that
allows for distributed, online learning. We evaluate our approach on a
benchmark activity recognition dataset and show that we can significantly
reduce training times, exchanging minimal information between processing nodes.
",1,0,0,0,0,0
20655,Solving Graph Isomorphism Problem for a Special case,"  Graph isomorphism is an important computer science problem. The problem for
the general case is unknown to be in polynomial time. The base algorithm for
the general case works in quasi-polynomial time. The solutions in polynomial
time for some special type of classes are known. In this work, we have worked
with a special type of graphs. We have proposed a method to represent these
graphs and finding isomorphism between these graphs. The method uses a modified
version of the degree list of a graph and neighbourhood degree list. These
special type of graphs have a property that neighbourhood degree list of any
two immediate neighbours is different for every vertex.The representation
becomes invariant to the order in which the node was selected for giving the
representation making the isomorphism problem trivial for this case. The
algorithm works in $O(n^4)$ time, where n is the number of vertices present in
the graph. The proposed algorithm runs faster than quasi-polynomial time for
the graphs used in the study.
",1,0,0,0,0,0
20656,Selective inference for effect modification via the lasso,"  Effect modification occurs when the effect of the treatment on an outcome
varies according to the level of other covariates and often has important
implications in decision making. When there are tens or hundreds of covariates,
it becomes necessary to use the observed data to select a simpler model for
effect modification and then make valid statistical inference. We propose a two
stage procedure to solve this problem. First, we use Robinson's transformation
to decouple the nuisance parameters from the treatment effect of interest and
use machine learning algorithms to estimate the nuisance parameters. Next,
after plugging in the estimates of the nuisance parameters, we use the Lasso to
choose a low-complexity model for effect modification. Compared to a full model
consisting of all the covariates, the selected model is much more
interpretable. Compared to the univariate subgroup analyses, the selected model
greatly reduces the number of false discoveries. We show that the conditional
selective inference for the selected model is asymptotically valid given the
rate assumptions in classical semiparametric regression. Extensive simulation
studies are conducted to verify the asymptotic results and an epidemiological
application is used to demonstrate the method.
",0,0,1,1,0,0
20657,Is Climate Change Controversial? Modeling Controversy as Contention Within Populations,"  A growing body of research focuses on computationally detecting controversial
topics and understanding the stances people hold on them. Yet gaps remain in
our theoretical and practical understanding of how to define controversy, how
it manifests, and how to measure it. In this paper, we introduce a novel
measure we call ""contention"", defined with respect to a topic and a population.
We model contention from a mathematical standpoint. We validate our model by
examining a diverse set of sources: real-world polling data sets, actual voter
data, and Twitter coverage on several topics. In our publicly-released Twitter
data set of nearly 100M tweets, we examine several topics such as Brexit, the
2016 U.S. Elections, and ""The Dress"", and cross-reference them with other
sources. We demonstrate that the contention measure holds explanatory power for
a wide variety of observed phenomena, such as controversies over climate change
and other topics that are well within scientific consensus. Finally, we
re-examine the notion of controversy, and present a theoretical framework that
defines it in terms of population. We present preliminary evidence suggesting
that contention is one dimension of controversy, along with others, such as
""importance"". Our new contention measure, along with the hypothesized model of
controversy, suggest several avenues for future work in this emerging
interdisciplinary research area.
",1,1,0,0,0,0
20658,Defending Against Adversarial Attacks by Leveraging an Entire GAN,"  Recent work has shown that state-of-the-art models are highly vulnerable to
adversarial perturbations of the input. We propose cowboy, an approach to
detecting and defending against adversarial attacks by using both the
discriminator and generator of a GAN trained on the same dataset. We show that
the discriminator consistently scores the adversarial samples lower than the
real samples across multiple attacks and datasets. We provide empirical
evidence that adversarial samples lie outside of the data manifold learned by
the GAN. Based on this, we propose a cleaning method which uses both the
discriminator and generator of the GAN to project the samples back onto the
data manifold. This cleaning procedure is independent of the classifier and
type of attack and thus can be deployed in existing systems.
",0,0,0,1,0,0
20659,Spectral Graph Convolutions for Population-based Disease Prediction,"  Exploiting the wealth of imaging and non-imaging information for disease
prediction tasks requires models capable of representing, at the same time,
individual features as well as data associations between subjects from
potentially large populations. Graphs provide a natural framework for such
tasks, yet previous graph-based approaches focus on pairwise similarities
without modelling the subjects' individual characteristics and features. On the
other hand, relying solely on subject-specific imaging feature vectors fails to
model the interaction and similarity between subjects, which can reduce
performance. In this paper, we introduce the novel concept of Graph
Convolutional Networks (GCN) for brain analysis in populations, combining
imaging and non-imaging data. We represent populations as a sparse graph where
its vertices are associated with image-based feature vectors and the edges
encode phenotypic information. This structure was used to train a GCN model on
partially labelled graphs, aiming to infer the classes of unlabelled nodes from
the node features and pairwise associations between subjects. We demonstrate
the potential of the method on the challenging ADNI and ABIDE databases, as a
proof of concept of the benefit from integrating contextual information in
classification tasks. This has a clear impact on the quality of the
predictions, leading to 69.5% accuracy for ABIDE (outperforming the current
state of the art of 66.8%) and 77% for ADNI for prediction of MCI conversion,
significantly outperforming standard linear classifiers where only individual
features are considered.
",1,0,0,1,0,0
20660,An independence system as knot invariant,"  An independence system (with respect to the unknotting number) is defined for
a classical knot diagram. It is proved that the independence system is a knot
invariant for alternating knots. The exchange property for minimal unknotting
sets are also discussed. It is shown that there exists an infinite family of
knot diagrams whose corresponding independence systems are matroids. In
contrast, infinite families of knot diagrams exist whose independence systems
are not matroids.
",0,0,1,0,0,0
20661,A cavity-induced artificial gauge field in a Bose-Hubbard ladder,"  We consider theoretically ultracold interacting bosonic atoms confined to
quasi-one-dimensional ladder structures formed by optical lattices and coupled
to the field of an optical cavity. The atoms can collect a spatial phase
imprint during a cavity-assisted tunneling along a rung via Raman transitions
employing a cavity mode and a transverse running wave pump beam. By adiabatic
elimination of the cavity field we obtain an effective Hamiltonian for the
bosonic atoms, with a self-consistency condition. Using the numerical density
matrix renormalization group method, we obtain a rich steady state diagram of
self-organized steady states. Transitions between superfluid to Mott-insulating
states occur, on top of which we can have Meissner, vortex liquid, and vortex
lattice phases. Also a state that explicitly breaks the symmetry between the
two legs of the ladder, namely the biased-ladder phase is dynamically
stabilized.
",0,1,0,0,0,0
20662,A Review of Laser-Plasma Ion Acceleration,"  An overview of research on laser-plasma based acceleration of ions is given.
The experimental state of the art is summarized and recent progress is
discussed. The basic acceleration processes are briefly reviewed with an
outlook on hybrid mechanisms and novel concepts. Finally, we put focus on the
development of engineered targets for enhanced acceleration and of all-optical
methods for beam post-acceleration and control.
",0,1,0,0,0,0
20663,Minimax Optimal Estimators for Additive Scalar Functionals of Discrete Distributions,"  In this paper, we consider estimators for an additive functional of $\phi$,
which is defined as $\theta(P;\phi)=\sum_{i=1}^k\phi(p_i)$, from $n$ i.i.d.
random samples drawn from a discrete distribution $P=(p_1,...,p_k)$ with
alphabet size $k$. We propose a minimax optimal estimator for the estimation
problem of the additive functional. We reveal that the minimax optimal rate is
characterized by the divergence speed of the fourth derivative of $\phi$ if the
divergence speed is high. As a result, we show there is no consistent estimator
if the divergence speed of the fourth derivative of $\phi$ is larger than
$p^{-4}$. Furthermore, if the divergence speed of the fourth derivative of
$\phi$ is $p^{4-\alpha}$ for $\alpha \in (0,1)$, the minimax optimal rate is
obtained within a universal multiplicative constant as $\frac{k^2}{(n\ln
n)^{2\alpha}} + \frac{k^{2-2\alpha}}{n}$.
",1,0,1,1,0,0
20664,Van der Waals Heterostructures Based on Allotropes of Phosphorene and MoSe2,"  The van der Waals heterostructures of allotropes of phosphorene (${\alpha}$-
and $\beta-P$) with MoSe2 (H-, T-, ZT- and SO-MoSe2) are investigated in the
framework of state-of-the-art density functional theory. The semiconducting
heterostructures, $\beta$-P /H-MoSe2 and ${\alpha}$-P / H-MoSe2, forms
anti-type structures with type I and type II band alignments, respectively,
whose bands are tunable with external electric field. ${\alpha}$-P / ZT-MoSe2
and ${\alpha}$-P / SO-MoSe2 form ohmic semiconductor-metal contacts while
Schottky barrier in $\beta$-P / T-MoSe2 can be reduced to zero by external
electric field to form ohmic contact which is useful to realize
high-performance devices. Simulated STM images of given heterostructures reveal
that ${\alpha}$-P can be used as a capping layer to differentiate between
various allotropes of underlying MoSe2. The dielectric response of considered
heterostructures is highly anisotropic in terms of lateral and vertical
polarization. The tunable electronic and dielectric response of van der Waals
phosphorene/MoSe2 heterostructure may find potentials applications in the
fabrication of optoelectronic devices.
",0,1,0,0,0,0
20665,On separated solutions of logistic population equation with harvesting,"  We provide a surprising answer to a question raised in S. Ahmad and A.C.
Lazer [2], and extend the results of that paper.
",0,0,1,0,0,0
20666,Nonreciprocal Electromagnetic Scattering from a Periodically Space-Time Modulated Slab and Application to a Quasisonic Isolator,"  Scattering of obliquely incident electromagnetic waves from periodically
space-time modulated slabs is investigated. It is shown that such structures
operate as nonreciprocal harmonic generators and spatial-frequency filters. For
oblique incidences, low-frequency harmonics are filtered out in the form of
surface waves, while high-frequency harmonics are transmitted as space waves.
In the quasisonic regime, where the velocity of the space-time modulation is
close to the velocity of the electromagnetic waves in the background medium,
the incident wave is strongly coupled to space-time harmonics in the forward
direction, while in the backward direction it exhibits low coupling to other
harmonics. This nonreciprocity is leveraged for the realization of an
electromagnetic isolator in the quasisonic regime and is experimentally
demonstrated at microwave frequencies.
",0,1,0,0,0,0
20667,Story Cloze Ending Selection Baselines and Data Examination,"  This paper describes two supervised baseline systems for the Story Cloze Test
Shared Task (Mostafazadeh et al., 2016a). We first build a classifier using
features based on word embeddings and semantic similarity computation. We
further implement a neural LSTM system with different encoding strategies that
try to model the relation between the story and the provided endings. Our
experiments show that a model using representation features based on average
word embedding vectors over the given story words and the candidate ending
sentences words, joint with similarity features between the story and candidate
ending representations performed better than the neural models. Our best model
achieves an accuracy of 72.42, ranking 3rd in the official evaluation.
",1,0,0,0,0,0
20668,Linear Quadratic Optimal Control Problems with Fixed Terminal States and Integral Quadratic Constraints,"  This paper is concerned with a linear quadratic (LQ, for short) optimal
control problem with fixed terminal states and integral quadratic constraints.
A Riccati equation with infinite terminal value is introduced, which is
uniquely solvable and whose solution can be approximated by the solution for a
suitable unconstrained LQ problem with penalized terminal state. Using results
from duality theory, the optimal control is explicitly derived by solving the
Riccati equation together with an optimal parameter selection problem. It turns
out that the optimal control is not only a feedback of the current state, but
also a feedback of the target (terminal state). Some examples are presented to
illustrate the theory developed.
",0,0,1,0,0,0
20669,A new sampling density condition for shift-invariant spaces,"  Let $X=\{x_i:i\in\mathbb{Z}\}$, $\dots<x_{i-1}<x_i<x_{i+1}<\dots$, be a
sampling set which is separated by a constant $\gamma>0$. Under certain
conditions on $\phi$, it is proved that if there exists a positive integer
$\nu$ such that
$$\delta_\nu:=\sup\limits_{i\in\mathbb{Z}}(x_{i+\nu}-x_i)<\dfrac{\nu}{2\pi}\left(\dfrac{c_{k}^2}{M_{2k}}\right)^{\frac{1}{4k}},$$
then every function belonging to a shift-invariant space $V(\phi)$ can be
reconstructed stably from its nonuniform sample values
$\{f^{(j)}(x_i):j=0,1,\dots, k-1, i\in\mathbb{Z}\}$, where $c_k$ is a
Wirtinger-Sobolev constant and $M_{2k}$ is a constant in Bernstein-type
inequality of $V(\phi)$. Further, when $k=1$, the maximum gap $\delta_\nu<\nu$
is sharp for certain shift-invariant spaces.
",0,0,1,0,0,0
20670,Experimental Design via Generalized Mean Objective Cost of Uncertainty,"  The mean objective cost of uncertainty (MOCU) quantifies the performance cost
of using an operator that is optimal across an uncertainty class of systems as
opposed to using an operator that is optimal for a particular system.
MOCU-based experimental design selects an experiment to maximally reduce MOCU,
thereby gaining the greatest reduction of uncertainty impacting the operational
objective. The original formulation applied to finding optimal system
operators, where optimality is with respect to a cost function, such as
mean-square error; and the prior distribution governing the uncertainty class
relates directly to the underlying physical system. Here we provide a
generalized MOCU and the corresponding experimental design. We then demonstrate
how this new formulation includes as special cases MOCU-based experimental
design methods developed for materials science and genomic networks when there
is experimental error. Most importantly, we show that the classical Knowledge
Gradient and Efficient Global Optimization experimental design procedures are
actually implementations of MOCU-based experimental design under their modeling
assumptions.
",0,0,0,1,0,0
20671,Parallelizing Over Artificial Neural Network Training Runs with Multigrid,"  Artificial neural networks are a popular and effective machine learning
technique. Great progress has been made parallelizing the expensive training
phase of an individual network, leading to highly specialized pieces of
hardware, many based on GPU-type architectures, and more concurrent algorithms
such as synthetic gradients. However, the training phase continues to be a
bottleneck, where the training data must be processed serially over thousands
of individual training runs. This work considers a multigrid reduction in time
(MGRIT) algorithm that is able to parallelize over the thousands of training
runs and converge to the exact same solution as traditional training would
provide. MGRIT was originally developed to provide parallelism for time
evolution problems that serially step through a finite number of time-steps.
This work recasts the training of a neural network similarly, treating neural
network training as an evolution equation that evolves the network weights from
one step to the next. Thus, this work concerns distributed computing approaches
for neural networks, but is distinct from other approaches which seek to
parallelize only over individual training runs. The work concludes with
supporting numerical results for two model problems.
",1,0,0,0,0,0
20672,Learning the Structure of Generative Models without Labeled Data,"  Curating labeled training data has become the primary bottleneck in machine
learning. Recent frameworks address this bottleneck with generative models to
synthesize labels at scale from weak supervision sources. The generative
model's dependency structure directly affects the quality of the estimated
labels, but selecting a structure automatically without any labeled data is a
distinct challenge. We propose a structure estimation method that maximizes the
$\ell_1$-regularized marginal pseudolikelihood of the observed data. Our
analysis shows that the amount of unlabeled data required to identify the true
structure scales sublinearly in the number of possible dependencies for a broad
class of models. Simulations show that our method is 100$\times$ faster than a
maximum likelihood approach and selects $1/4$ as many extraneous dependencies.
We also show that our method provides an average of 1.5 F1 points of
improvement over existing, user-developed information extraction applications
on real-world data such as PubMed journal abstracts.
",1,0,0,1,0,0
20673,Robust Loss Functions under Label Noise for Deep Neural Networks,"  In many applications of classifier learning, training data suffers from label
noise. Deep networks are learned using huge training data where the problem of
noisy labels is particularly relevant. The current techniques proposed for
learning deep networks under label noise focus on modifying the network
architecture and on algorithms for estimating true labels from noisy labels. An
alternate approach would be to look for loss functions that are inherently
noise-tolerant. For binary classification there exist theoretical results on
loss functions that are robust to label noise. In this paper, we provide some
sufficient conditions on a loss function so that risk minimization under that
loss function would be inherently tolerant to label noise for multiclass
classification problems. These results generalize the existing results on
noise-tolerant loss functions for binary classification. We study some of the
widely used loss functions in deep networks and show that the loss function
based on mean absolute value of error is inherently robust to label noise. Thus
standard back propagation is enough to learn the true classifier even under
label noise. Through experiments, we illustrate the robustness of risk
minimization with such loss functions for learning neural networks.
",1,0,0,1,0,0
20674,A quality model for evaluating and choosing a stream processing framework architecture,"  Today, we have to deal with many data (Big data) and we need to make
decisions by choosing an architectural framework to analyze these data coming
from different area. Due to this, it become problematic when we want to process
these data, and even more, when it is continuous data. When you want to process
some data, you have to first receive it, store it, and then query it. This is
what we call Batch Processing. It works well when you process big amount of
data, but it finds its limits when you want to get fast (or real-time)
processing results, such as financial trades, sensors, user session activity,
etc. The solution to this problem is stream processing. Stream processing
approach consists of data arriving record by record and rather than storing it,
the processing should be done directly. Therefore, direct results are needed
with a latency that may vary in real-time.
In this paper, we propose an assessment quality model to evaluate and choose
stream processing frameworks. We describe briefly different architectural
frameworks such as Kafka, Spark Streaming and Flink that address the stream
processing. Using our quality model, we present a decision tree to support
engineers to choose a framework following the quality aspects. Finally, we
evaluate our model doing a case study to Twitter and Netflix streaming.
",1,0,0,0,0,0
20675,On the Hardness of Inventory Management with Censored Demand Data,"  We consider a repeated newsvendor problem where the inventory manager has no
prior information about the demand, and can access only censored/sales data. In
analogy to multi-armed bandit problems, the manager needs to simultaneously
""explore"" and ""exploit"" with her inventory decisions, in order to minimize the
cumulative cost. We make no probabilistic assumptions---importantly,
independence or time stationarity---regarding the mechanism that creates the
demand sequence. Our goal is to shed light on the hardness of the problem, and
to develop policies that perform well with respect to the regret criterion,
that is, the difference between the cumulative cost of a policy and that of the
best fixed action/static inventory decision in hindsight, uniformly over all
feasible demand sequences. We show that a simple randomized policy, termed the
Exponentially Weighted Forecaster, combined with a carefully designed cost
estimator, achieves optimal scaling of the expected regret (up to logarithmic
factors) with respect to all three key primitives: the number of time periods,
the number of inventory decisions available, and the demand support. Through
this result, we derive an important insight: the benefit from ""information
stalking"" as well as the cost of censoring are both negligible in this dynamic
learning problem, at least with respect to the regret criterion. Furthermore,
we modify the proposed policy in order to perform well in terms of the tracking
regret, that is, using as benchmark the best sequence of inventory decisions
that switches a limited number of times. Numerical experiments suggest that the
proposed approach outperforms existing ones (that are tailored to, or
facilitated by, time stationarity) on nonstationary demand models. Finally, we
extend the proposed approach and its analysis to a ""combinatorial"" version of
the repeated newsvendor problem.
",1,0,0,1,0,0
20676,Social Media Analysis For Organizations: Us Northeastern Public And State Libraries Case Study,"  Social networking sites such as Twitter have provided a great opportunity for
organizations such as public libraries to disseminate information for public
relations purposes. However, there is a need to analyze vast amounts of social
media data. This study presents a computational approach to explore the content
of tweets posted by nine public libraries in the northeastern United States of
America. In December 2017, this study extracted more than 19,000 tweets from
the Twitter accounts of seven state libraries and two urban public libraries.
Computational methods were applied to collect the tweets and discover
meaningful themes. This paper shows how the libraries have used Twitter to
represent their services and provides a starting point for different
organizations to evaluate the themes of their public tweets.
",1,0,0,1,0,0
20677,Weakly tripotent rings,"  We study the class of rings $R$ with the property that for $x\in R$ at least
one of the elements $x$ and $1+x$ are tripotent.
",0,0,1,0,0,0
20678,ML for Flood Forecasting at Scale,"  Effective riverine flood forecasting at scale is hindered by a multitude of
factors, most notably the need to rely on human calibration in current
methodology, the limited amount of data for a specific location, and the
computational difficulty of building continent/global level models that are
sufficiently accurate. Machine learning (ML) is primed to be useful in this
scenario: learned models often surpass human experts in complex
high-dimensional scenarios, and the framework of transfer or multitask learning
is an appealing solution for leveraging local signals to achieve improved
global performance. We propose to build on these strengths and develop ML
systems for timely and accurate riverine flood prediction.
",1,0,0,1,0,0
20679,Spectral proper orthogonal decomposition and its relationship to dynamic mode decomposition and resolvent analysis,"  We consider the frequency domain form of proper orthogonal decomposition
(POD) called spectral proper orthogonal decomposition (SPOD). Spectral POD is
derived from a space-time POD problem for statistically stationary flows and
leads to modes that each oscillate at a single frequency. This form of POD goes
back to the original work of Lumley (Stochastic tools in turbulence, Academic
Press, 1970), but has been overshadowed by a space-only form of POD since the
1990s. We clarify the relationship between these two forms of POD and show that
SPOD modes represent structures that evolve coherently in space and time while
space-only POD modes in general do not. We also establish a relationship
between SPOD and dynamic mode decomposition (DMD); we show that SPOD modes are
in fact optimally averaged DMD modes obtained from an ensemble DMD problem for
stationary flows. Accordingly, SPOD modes represent structures that are dynamic
in the same sense as DMD modes but also optimally account for the statistical
variability of turbulent flows. Finally, we establish a connection between SPOD
and resolvent analysis. The key observation is that the resolvent-mode
expansion coefficients must be regarded as statistical quantities to ensure
convergent approximations of the flow statistics. When the expansion
coefficients are uncorrelated, we show that SPOD and resolvent modes are
identical. Our theoretical results and the overall utility of SPOD are
demonstrated using two example problems: the complex Ginzburg-Landau equation
and a turbulent jet.
",0,1,0,0,0,0
20680,An optimal transportation approach for assessing almost stochastic order,"  When stochastic dominance $F\leq_{st}G$ does not hold, we can improve
agreement to stochastic order by suitably trimming both distributions. In this
work we consider the $L_2-$Wasserstein distance, $\mathcal W_2$, to stochastic
order of these trimmed versions. Our characterization for that distance
naturally leads to consider a $\mathcal W_2$-based index of disagreement with
stochastic order, $\varepsilon_{\mathcal W_2}(F,G)$. We provide asymptotic
results allowing to test $H_0: \varepsilon_{\mathcal W_2}(F,G)\geq
\varepsilon_0$ vs $H_a: \varepsilon_{\mathcal W_2}(F,G)<\varepsilon_0$, that,
under rejection, would give statistical guarantee of almost stochastic
dominance. We include a simulation study showing a good performance of the
index under the normal model.
",0,0,0,1,0,0
20681,The Effect of Electron Lens as Landau Damping Device on Single Particle Dynamics in HL-LHC,"  An electron lens can serve as an effective mechanism for suppressing coherent
instabilities in high intensity storage rings through nonlinear amplitude
dependent betatron tune shift. However, the addition of a strong localized
nonlinear focusing element to the accelerator lattice may lead to undesired
effects in particle dynamics. We evaluate the effect of a Gaussian electron
lens on single particle motion in HL-LHC using numerical tracking simulations,
and compare the results to the case when an equal tune spread is generated by
conventional octupole magnets.
",0,1,0,0,0,0
20682,Search for sterile neutrinos in holographic dark energy cosmology: Reconciling Planck observation with the local measurement of the Hubble constant,"  We search for sterile neutrinos in the holographic dark energy cosmology by
using the latest observational data. To perform the analysis, we employ the
current cosmological observations, including the cosmic microwave background
temperature power spectrum data from the Planck mission, the baryon acoustic
oscillation measurements, the type Ia supernova data, the redshift space
distortion measurements, the shear data of weak lensing observation, the Planck
lensing measurement, and the latest direct measurement of $H_0$ as well. We
show that, compared to the $\Lambda$CDM cosmology, the holographic dark energy
cosmology with sterile neutrinos can relieve the tension between the Planck
observation and the direct measurement of $H_0$ much better. Once we include
the $H_0$ measurement in the global fit, we find that the hint of the existence
of sterile neutrinos in the holographic dark energy cosmology can be given.
Under the constraint of the all-data combination, we obtain $N_{\rm eff}=
3.76\pm0.26$ and $m_{\nu,\rm sterile}^{\rm eff}< 0.215\,\rm eV$, indicating
that the detection of $\Delta N_{\rm eff}>0$ in the holographic dark energy
cosmology is at the $2.75\sigma$ level and the massless or very light sterile
neutrino is favored by the current observations.
",0,1,0,0,0,0
20683,Simulation of high temperature superconductors and experimental validation,"  In this work, we present a parallel, fully-distributed finite element
numerical framework to simulate the low-frequency electromagnetic response of
superconducting devices, which allows to efficiently exploit HPC platforms. We
select the so-called H-formulation, which uses the magnetic field as a state
variable. Nédélec elements (of arbitrary order) are required for an
accurate approximation of the H-formulation for modelling electromagnetic
fields along interfaces between regions with high contrast medium properties.
An h-adaptive mesh refinement technique customized for Nédélec elements
leads to a structured fine mesh in areas of interest whereas a smart coarsening
is obtained in other regions. The composition of a tailored, robust, parallel
nonlinear solver completes the exposition of the developed tools to tackle the
problem. First, a comparison against experimental data is performed to show the
availability of the finite element approximation to model the physical
phenomena. Then, a selected state-of-the-art 3D benchmark is reproduced,
focusing on the parallel performance of the algorithms.
",1,1,0,0,0,0
20684,Hardware Translation Coherence for Virtualized Systems,"  To improve system performance, modern operating systems (OSes) often
undertake activities that require modification of virtual-to-physical page
translation mappings. For example, the OS may migrate data between physical
frames to defragment memory and enable superpages. The OS may migrate pages of
data between heterogeneous memory devices. We refer to all such activities as
page remappings. Unfortunately, page remappings are expensive. We show that
translation coherence is a major culprit and that systems employing
virtualization are especially badly affected by their overheads. In response,
we propose hardware translation invalidation and coherence or HATRIC, a readily
implementable hardware mechanism to piggyback translation coherence atop
existing cache coherence protocols. We perform detailed studies using KVM-based
virtualization, showing that HATRIC achieves up to 30% performance and 10%
energy benefits, for per-CPU area overheads of 2%. We also quantify HATRIC's
benefits on systems running Xen and find up to 33% performance improvements.
",1,0,0,0,0,0
20685,MotifMark: Finding Regulatory Motifs in DNA Sequences,"  The interaction between proteins and DNA is a key driving force in a
significant number of biological processes such as transcriptional regulation,
repair, recombination, splicing, and DNA modification. The identification of
DNA-binding sites and the specificity of target proteins in binding to these
regions are two important steps in understanding the mechanisms of these
biological activities. A number of high-throughput technologies have recently
emerged that try to quantify the affinity between proteins and DNA motifs.
Despite their success, these technologies have their own limitations and fall
short in precise characterization of motifs, and as a result, require further
downstream analysis to extract useful and interpretable information from a
haystack of noisy and inaccurate data. Here we propose MotifMark, a new
algorithm based on graph theory and machine learning, that can find binding
sites on candidate probes and rank their specificity in regard to the
underlying transcription factor. We developed a pipeline to analyze
experimental data derived from compact universal protein binding microarrays
and benchmarked it against two of the most accurate motif search methods. Our
results indicate that MotifMark can be a viable alternative technique for
prediction of motif from protein binding microarrays and possibly other related
high-throughput techniques.
",1,0,0,0,0,0
20686,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning,"  This paper presents KeypointNet, an end-to-end geometric reasoning framework
to learn an optimal set of category-specific 3D keypoints, along with their
detectors. Given a single image, KeypointNet extracts 3D keypoints that are
optimized for a downstream task. We demonstrate this framework on 3D pose
estimation by proposing a differentiable objective that seeks the optimal set
of keypoints for recovering the relative pose between two views of an object.
Our model discovers geometrically and semantically consistent keypoints across
viewing angles and instances of an object category. Importantly, we find that
our end-to-end framework using no ground-truth keypoint annotations outperforms
a fully supervised baseline using the same neural network architecture on the
task of pose estimation. The discovered 3D keypoints on the car, chair, and
plane categories of ShapeNet are visualized at this http URL.
",0,0,0,1,0,0
20687,Multi-State Trajectory Approach to Non-Adiabatic Dynamics: General Formalism and the Active State Trajectory Approximation,"  A general theoretical framework is derived for the recently developed
multi-state trajectory (MST) approach from the time dependent Schrödinger
equation, resulting in equations of motion for coupled nuclear-electronic
dynamics equivalent to Hamilton dynamics or Heisenberg equation based on a new
multistate Meyer-Miller (MM) model. The derived MST formalism incorporates both
diabatic and adiabatic representations as limiting cases, and reduces to
Ehrenfest or Born-Oppenheimer dynamics in the mean field or the single state
limits, respectively. By quantizing nuclear dynamics to a particular active
state, the MST algorithm does not suffer from the instability caused by the
negative instant electronic population variables unlike the standard MM
dynamics. Furthermore the multistate representation for electron coupled
nuclear dynamics with each state associated with one individual trajectory
presumably captures single state dynamics better than the mean field
description. The coupled electronic-nuclear coherence is incorporated
consistently in the MST framework with no ad-hoc state switch and the
associated momentum adjustment or parameters for artificial decoherence, unlike
the original or modified surface hopping treatments. The implementation of the
MST approach to benchmark problems shows reasonably good agreement with exact
quantum calculations, and the results in both representations are similar in
accuracy. The active state trajectory (AST) approximation of the MST approach
provides a consistent interpretation to trajectory surface hopping, which
predicts the transition probabilities reasonably well for multiple nonadiabatic
transitions and conical intersection problems.
",0,1,0,0,0,0
20688,Combining Homotopy Methods and Numerical Optimal Control to Solve Motion Planning Problems,"  This paper presents a systematic approach for computing local solutions to
motion planning problems in non-convex environments using numerical optimal
control techniques. It extends the range of use of state-of-the-art numerical
optimal control tools to problem classes where these tools have previously not
been applicable. Today these problems are typically solved using motion
planners based on randomized or graph search. The general principle is to
define a homotopy that perturbs, or preferably relaxes, the original problem to
an easily solved problem. By combining a Sequential Quadratic Programming (SQP)
method with a homotopy approach that gradually transforms the problem from a
relaxed one to the original one, practically relevant locally optimal solutions
to the motion planning problem can be computed. The approach is demonstrated in
motion planning problems in challenging 2D and 3D environments, where the
presented method significantly outperforms a state-of-the-art open-source
optimizing sampled-based planner commonly used as benchmark.
",0,0,1,0,0,0
20689,High quality atomically thin PtSe2 films grown by molecular beam epitaxy,"  Atomically thin PtSe2 films have attracted extensive research interests for
potential applications in high-speed electronics, spintronics and
photodetectors. Obtaining high quality, single crystalline thin films with
large size is critical. Here we report the first successful layer-by-layer
growth of high quality PtSe2 films by molecular beam epitaxy. Atomically thin
films from 1 ML to 22 ML have been grown and characterized by low-energy
electron diffraction, Raman spectroscopy and X-ray photoemission spectroscopy.
Moreover, a systematic thickness dependent study of the electronic structure is
revealed by angle-resolved photoemission spectroscopy (ARPES), and helical spin
texture is revealed by spin-ARPES. Our work provides new opportunities for
growing large size single crystalline films for investigating the physical
properties and potential applications of PtSe2.
",0,1,0,0,0,0
20690,NAVREN-RL: Learning to fly in real environment via end-to-end deep reinforcement learning using monocular images,"  We present NAVREN-RL, an approach to NAVigate an unmanned aerial vehicle in
an indoor Real ENvironment via end-to-end reinforcement learning RL. A suitable
reward function is designed keeping in mind the cost and weight constraints for
micro drone with minimum number of sensing modalities. Collection of small
number of expert data and knowledge based data aggregation is integrated into
the RL process to aid convergence. Experimentation is carried out on a Parrot
AR drone in different indoor arenas and the results are compared with other
baseline technologies. We demonstrate how the drone successfully avoids
obstacles and navigates across different arenas.
",1,0,0,1,0,0
20691,"Fast, Accurate and Fully Parallelizable Digital Image Correlation","  Digital image correlation (DIC) is a widely used optical metrology for
surface deformation measurements. DIC relies on nonlinear optimization method.
Thus an initial guess is quite important due to its influence on the converge
characteristics of the algorithm. In order to obtain a reliable, accurate
initial guess, a reliability-guided digital image correlation (RG-DIC) method,
which is able to intelligently obtain a reliable initial guess without using
time-consuming integer-pixel registration, was proposed. However, the RG-DIC
and its improved methods are path-dependent and cannot be fully parallelized.
Besides, it is highly possible that RG-DIC fails in the full-field analysis of
deformation without manual intervention if the deformation fields contain large
areas of discontinuous deformation. Feature-based initial guess is highly
robust while it is relatively time-consuming. Recently, path-independent
algorithm, fast Fourier transform-based cross correlation (FFT-CC) algorithm,
was proposed to estimate the initial guess. Complete parallelizability is the
major advantage of the FFT-CC algorithm, while it is sensitive to small
deformation. Wu et al proposed an efficient integer-pixel search scheme, but
the parameters of this algorithm are set by the users empirically. In this
technical note, a fully parallelizable DIC method is proposed. Different from
RG-DIC method, the proposed method divides DIC algorithm into two parts:
full-field initial guess estimation and sub-pixel registration. The proposed
method has the following benefits: 1) providing a pre-knowledge of deformation
fields; 2) saving computational time; 3) reducing error propagation; 4)
integratability with well-established DIC algorithms; 5) fully
parallelizability.
",0,1,0,0,0,0
20692,Discovering the effect of nonlocal payoff calculation on the stabilty of ESS: Spatial patterns of Hawk-Dove game in metapopulations,"  The classical idea of evolutionarily stable strategy (ESS) modeling animal
behavior does not involve any spatial dependence. We considered a spatial
Hawk-Dove game played by animals in a patchy environment with wrap around
boundaries. We posit that each site contains the same number of individuals. An
evolution equation for analyzing the stability of the ESS is found as the mean
dynamics of the classical frequency dependent Moran process coupled via
migration and nonlocal payoff calculation in 1D and 2D habitats. The linear
stability analysis of the model is performed and conditions to observe spatial
patterns are investigated. For the nearest neighbor interactions (including von
Neumann and Moore neighborhoods in 2D) we concluded that it is possible to
destabilize the ESS of the game and observe pattern formation when the
dispersal rate is small enough. We numerically investigate the spatial patterns
arising from the replicator equations coupled via nearest neighbor payoff
calculation and dispersal.
",0,0,0,0,1,0
20693,Analysis of the measurements of anisotropic a.c. vortex resistivity in tilted magnetic fields,"  Measurements of the high-frequency complex resistivity in superconductors are
a tool often used to obtain the vortex parameters, such as the vortex
viscosity, the pinning constant and the depinning frequency. In anisotropic
superconductors, the extraction of these quantities from the measurements faces
new difficulties due to the tensor nature of the electromagnetic problem. The
problem is specifically intricate when the magnetic field is tilted with
respect to the crystallographic axes. Partial solutions exist in the
free-flux-flow (no pinning) and Campbell (pinning dominated) regimes. In this
paper we develop a full tensor model for the vortex motion complex resistivity,
including flux-flow, pinning, and creep. We give explicit expressions for the
tensors involved. We obtain that, despite the complexity of the physics, some
parameters remain scalar in nature. We show that under specific circumstances
the directly measured quantities do not reflect the true vortex parameters, and
we give procedures to derive the true vortex parameters from measurements taken
with arbitrary field orientations. Finally, we discuss the applicability of the
angular scaling properties to the measured and transformed vortex parameters
and we exploit these properties as a tool to unveil the existence of
directional pinning.
",0,1,0,0,0,0
20694,Deep Convolutional Neural Network to Detect J-UNIWARD,"  This paper presents an empirical study on applying convolutional neural
networks (CNNs) to detecting J-UNIWARD, one of the most secure JPEG
steganographic method. Experiments guiding the architectural design of the CNNs
have been conducted on the JPEG compressed BOSSBase containing 10,000 covers of
size 512x512. Results have verified that both the pooling method and the depth
of the CNNs are critical for performance. Results have also proved that a
20-layer CNN, in general, outperforms the most sophisticated feature-based
methods, but its advantage gradually diminishes on hard-to-detect cases. To
show that the performance generalizes to large-scale databases and to different
cover sizes, one experiment has been conducted on the CLS-LOC dataset of
ImageNet containing more than one million covers cropped to unified size of
256x256. The proposed 20-layer CNN has cut the error achieved by a CNN recently
proposed for large-scale JPEG steganalysis by 35%. Source code is available via
GitHub: this https URL
",1,0,0,0,0,0
20695,Observing Power-Law Dynamics of Position-Velocity Correlation in Anomalous Diffusion,"  In this letter we present a measurement of the phase-space density
distribution (PSDD) of ultra-cold \Rb atoms performing 1D anomalous diffusion.
The PSDD is imaged using a direct tomographic method based on Raman velocity
selection. It reveals that the position-velocity correlation function
$C_{xv}(t)$ builds up on a timescale related to the initial conditions of the
ensemble and then decays asymptotically as a power-law. We show that the decay
follows a simple scaling theory involving the power-law asymptotic dynamics of
position and velocity. The generality of this scaling theory is confirmed using
Monte-Carlo simulations of two distinct models of anomalous diffusion.
",0,1,0,0,0,0
20696,"Modular curves, invariant theory and $E_8$","  The $E_8$ root lattice can be constructed from the modular curve $X(13)$ by
the invariant theory for the simple group $\text{PSL}(2, 13)$. This gives a
different construction of the $E_8$ root lattice. It also gives an explicit
construction of the modular curve $X(13)$.
",0,0,1,0,0,0
20697,Analysis of Approximate Stochastic Gradient Using Quadratic Constraints and Sequential Semidefinite Programs,"  We present convergence rate analysis for the approximate stochastic gradient
method, where individual gradient updates are corrupted by computation errors.
We develop stochastic quadratic constraints to formulate a small linear matrix
inequality (LMI) whose feasible set characterizes convergence properties of the
approximate stochastic gradient. Based on this LMI condition, we develop a
sequential minimization approach to analyze the intricate trade-offs that
couple stepsize selection, convergence rate, optimization accuracy, and
robustness to gradient inaccuracy. We also analytically solve this LMI
condition and obtain theoretical formulas that quantify the convergence
properties of the approximate stochastic gradient under various assumptions on
the loss functions.
",0,0,0,1,0,0
20698,Invariant holomorphic discs in some non-convex domains,"  We give a description of complex geodesics and we study the structure of
stationary discs in some non-convex domains for which complex geodesics are not
unique.
",0,0,1,0,0,0
20699,MIMIX: a Bayesian Mixed-Effects Model for Microbiome Data from Designed Experiments,"  Recent advances in bioinformatics have made high-throughput microbiome data
widely available, and new statistical tools are required to maximize the
information gained from these data. For example, analysis of high-dimensional
microbiome data from designed experiments remains an open area in microbiome
research. Contemporary analyses work on metrics that summarize collective
properties of the microbiome, but such reductions preclude inference on the
fine-scale effects of environmental stimuli on individual microbial taxa. Other
approaches model the proportions or counts of individual taxa as response
variables in mixed models, but these methods fail to account for complex
correlation patterns among microbial communities. In this paper, we propose a
novel Bayesian mixed-effects model that exploits cross-taxa correlations within
the microbiome, a model we call MIMIX (MIcrobiome MIXed model). MIMIX offers
global tests for treatment effects, local tests and estimation of treatment
effects on individual taxa, quantification of the relative contribution from
heterogeneous sources to microbiome variability, and identification of latent
ecological subcommunities in the microbiome. MIMIX is tailored to large
microbiome experiments using a combination of Bayesian factor analysis to
efficiently represent dependence between taxa and Bayesian variable selection
methods to achieve sparsity. We demonstrate the model using a simulation
experiment and on a 2x2 factorial experiment of the effects of nutrient
supplement and herbivore exclusion on the foliar fungal microbiome of
$\textit{Andropogon gerardii}$, a perennial bunchgrass, as part of the global
Nutrient Network research initiative.
",0,0,0,1,0,0
20700,SpatEntropy: Spatial Entropy Measures in R,"  This article illustrates how to measure the heterogeneity of spatial data
presenting a finite number of categories via computation of spatial entropy.
The R package SpatEntropy contains functions for the computation of entropy and
spatial entropy measures. The extension to spatial entropy measures is a unique
feature of SpatEntropy. In addition to the traditional version of Shannon's
entropy, the package includes Batty's spatial entropy, O'Neill's entropy, Li
and Reynolds' contagion index, Karlstrom and Ceccato's entropy, Leibovici's
entropy, Parresol and Edwards' entropy and Altieri's entropy. The package is
able to work with both areal and point data. This paper is a general
description of SpatEntropy, as well as its necessary theoretical background,
and an introduction for new users.
",0,0,0,1,0,0
20701,Evidence for universality in the initial planetesimal mass function,"  Planetesimals may form from the gravitational collapse of dense particle
clumps initiated by the streaming instability. We use simulations of
aerodynamically coupled gas-particle mixtures to investigate whether the
properties of planetesimals formed in this way depend upon the sizes of the
particles that participate in the instability. Based on three high resolution
simulations that span a range of dimensionless stopping time $6 \times 10^{-3}
\leq \tau \leq 2$ no statistically significant differences in the initial
planetesimal mass function are found. The mass functions are fit by a
power-law, ${\rm d}N / {\rm d}M_p \propto M_p^{-p}$, with $p=1.5-1.7$ and
errors of $\Delta p \approx 0.1$. Comparing the particle density fields prior
to collapse, we find that the high wavenumber power spectra are similarly
indistinguishable, though the large-scale geometry of structures induced via
the streaming instability is significantly different between all three cases.
We interpret the results as evidence for a near-universal slope to the mass
function, arising from the small-scale structure of streaming-induced
turbulence.
",0,1,0,0,0,0
20702,On covering systems of integers,"  A covering system of the integers is a finite collection of modular residue
classes $\{a_m \bmod{m}\}_{m \in S}$ whose union is all integers. Given a
finite set $S$ of moduli, it is often difficult to tell whether there is a
choice of residues modulo elements of $S$ covering the integers. Hough has
shown that if the smallest modulus in $S$ is at least $10^{16}$, then there is
none. However, the question of whether there is a covering of the integers with
all odd moduli remains open. We consider multiplicative restrictions on the set
of moduli to generalize Hough's negative solution to the minimum modulus
problem. In particular, we find that every covering system of the integers has
a modulus divisible by a prime number less than or equal to $19$. Hough and
Nielsen have shown that every covering system has a modulus divisible by either
$2$ or $3$.
",0,0,1,0,0,0
20703,Asymptotically safe cosmology - a status report,"  Asymptotic Safety, based on a non-Gaussian fixed point of the gravitational
renormalization group flow, provides an elegant mechanism for completing the
gravitational force at sub-Planckian scales. At high energies the fixed point
controls the scaling of couplings such that unphysical divergences are absent
while the emergence of classical low-energy physics is linked to a crossover
between two renormalization group fixed points. These features make Asymptotic
Safety an attractive framework for cosmological model building. The resulting
scenarios may naturally give rise to a quantum gravity driven inflationary
phase in the very early universe and an almost scale-free fluctuation spectrum.
Moreover, effective descriptions arising from an renormalization group
improvement permit a direct comparison to cosmological observations as, e.g.
Planck data.
",0,1,0,0,0,0
20704,Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction,"  Future predictions on sequence data (e.g., videos or audios) require the
algorithms to capture non-Markovian and compositional properties of high-level
semantics. Context-free grammars are natural choices to capture such
properties, but traditional grammar parsers (e.g., Earley parser) only take
symbolic sentences as inputs. In this paper, we generalize the Earley parser to
parse sequence data which is neither segmented nor labeled. This generalized
Earley parser integrates a grammar parser with a classifier to find the optimal
segmentation and labels, and makes top-down future predictions. Experiments
show that our method significantly outperforms other approaches for future
human activity prediction.
",0,0,0,1,0,0
20705,COCrIP: Compliant OmniCrawler In-pipeline Robot,"  This paper presents a modular in-pipeline climbing robot with a novel
compliant foldable OmniCrawler mechanism. The circular cross-section of the
OmniCrawler module enables a holonomic motion to facilitate the alignment of
the robot in the direction of bends. Additionally, the crawler mechanism
provides a fair amount of traction, even on slippery surfaces. These advantages
of crawler modules have been further supplemented by incorporating active
compliance in the module itself which helps to negotiate sharp bends in small
diameter pipes. The robot has a series of 3 such compliant foldable modules
interconnected by the links via passive joints. For the desirable pipe diameter
and curvature of the bends, the spring stiffness value for each passive joint
is determined by formulating a constrained optimization problem using the
quasi-static model of the robot. Moreover, a minimum friction coefficient value
between the module-pipe surface which can be vertically climbed by the robot
without slipping is estimated. The numerical simulation results have further
been validated by experiments on real robot prototype.
",1,0,0,0,0,0
20706,An Inversion-Based Learning Approach for Improving Impromptu Trajectory Tracking of Robots with Non-Minimum Phase Dynamics,"  This paper presents a learning-based approach for impromptu trajectory
tracking for non-minimum phase systems, i.e., systems with unstable inverse
dynamics. Inversion-based feedforward approaches are commonly used for
improving tracking performance; however, these approaches are not directly
applicable to non-minimum phase systems due to their inherent instability. In
order to resolve the instability issue, existing methods have assumed that the
system model is known and used pre-actuation or inverse approximation
techniques. In this work, we propose an approach for learning a stable,
approximate inverse of a non-minimum phase baseline system directly from its
input-output data. Through theoretical discussions, simulations, and
experiments on two different platforms, we show the stability of our proposed
approach and its effectiveness for high-accuracy, impromptu tracking. Our
approach also shows that including more information in the training, as is
commonly assumed to be useful, does not lead to better performance but may
trigger instability and impact the effectiveness of the overall approach.
",1,0,0,0,0,0
20707,Decay Estimates for 1-D Parabolic PDEs with Boundary Disturbances,"  In this work decay estimates are derived for the solutions of 1-D linear
parabolic PDEs with disturbances at both boundaries and distributed
disturbances. The decay estimates are given in the L2 and H1 norms of the
solution and discontinuous disturbances are allowed. Although an eigenfunction
expansion for the solution is exploited for the proof of the decay estimates,
the estimates do not require knowledge of the eigenvalues and the
eigenfunctions of the corresponding Sturm-Liouville operator. Examples show
that the obtained results can be applied for the stability analysis of
parabolic PDEs with nonlocal terms.
",1,0,1,0,0,0
20708,GEANT4 Simulation of Nuclear Interaction Induced Soft Errors in Digital Nanoscale Electronics: Interrelation Between Proton and Heavy Ion Impacts,"  A simple and self-consistent approach has been proposed for simulation of the
proton-induced soft error rate based on the heavy ion induced single event
upset cross-section data and vice versa. The approach relies on the GEANT4
assisted Monte Carlo simulation of the secondary particle LET spectra produced
by nuclear interactions. The method has been validated with the relevant
in-flight soft error rate data for space protons and heavy ions. An approximate
analytical relation is proposed and validated for a fast recalculation between
the two types of experimental data.
",0,1,0,0,0,0
20709,Analysis and Measurement of the Transfer Matrix of a 9-cell 1.3-GHz Superconducting Cavity,"  Superconducting linacs are capable of producing intense, stable, high-quality
electron beams that have found widespread applications in science and industry.
The 9-cell 1.3-GHz superconducting standing-wave accelerating RF cavity
originally developed for $e^+/e^-$ linear-collider applications [B. Aunes, {\em
et al.} Phys. Rev. ST Accel. Beams {\bf 3}, 092001 (2000)] has been broadly
employed in various superconducting-linac designs. In this paper we discuss the
transfer matrix of such a cavity and present its measurement performed at the
Fermilab Accelerator Science and Technology (FAST) facility. The experimental
results are found to be in agreement with analytical calculations and numerical
simulations.
",0,1,0,0,0,0
20710,Size-aware Sharding For Improving Tail Latencies in In-memory Key-value Stores,"  This paper introduces the concept of size-aware sharding to improve tail
latencies for in-memory key-value stores, and describes its implementation in
the Minos key-value store. Tail latencies are crucial in distributed
applications with high fan-out ratios, because overall response time is
determined by the slowest response. Size-aware sharding distributes requests
for keys to cores according to the size of the item associated with the key. In
particular, requests for small and large items are sent to disjoint subsets of
cores. Size-aware sharding improves tail latencies by avoiding head-of-line
blocking, in which a request for a small item gets queued behind a request for
a large item. Alternative size-unaware approaches to sharding, such as
keyhash-based sharding, request dispatching and stealing do not avoid
head-of-line blocking, and therefore exhibit worse tail latencies. The
challenge in implementing size-aware sharding is to maintain high throughput by
avoiding the cost of software dispatching and by achieving load balancing
between different cores. Minos uses hardware dispatch for all requests for
small items, which form the very large majority of all requests. It achieves
load balancing by adapting the number of cores handling requests for small and
large items to their relative presence in the workload. We compare Minos to
three state-of-the-art designs of in-memory KV stores. Compared to its closest
competitor, Minos achieves a 99th percentile latency that is up to two orders
of magnitude lower. Put differently, for a given value for the 99th percentile
latency equal to 10 times the mean service time, Minos achieves a throughput
that is up to 7.4 times higher.
",1,0,0,0,0,0
20711,Abell 2744 may be a supercluster aligned along the sightline,"  To explain the unusual richness and compactness of the Abell 2744, we propose
a hypothesis that it may be a rich supercluster aligned along the sightline,
and present a supporting evidence obtained numerically from the MultiDark
Planck 2 simulations with a linear box size of $1\,h^{-1}$Gpc. Applying the
friends-of-friends (FoF) algorithm with a linkage length of $0.33$ to a sample
of the cluster-size halos from the simulations, we identify the superclusters
and investigate how many superclusters have filamentary branches that would
appear to be similar to the Abell 2744 if the filamentary axis is aligned with
the sightline. Generating randomly a unit vector as a sightline at the position
of the core member of each supercluster and projecting the positions of the
members onto the plane perpendicular to the direction of the sightline, we
measure two dimensional distances ($R_{2d}$) of the member halos from the core
for each supercluster. Defining a Abell 2744-like spuercluster as the one
having a filamentary branch composed of eight or more members with $R_{2d}\le
1\,$Mpc and masses comparable to those of the observed Abell 2744
substructures, we find one Abell 2744-like supercluster at $z=0.3$ and two at
$z=0$. Repeating the same analysis but with the data from the Big MultiDark
Planck simulations performed on a larger box of linear size of
$2.5\,h^{-1}$Mpc, we find that the number of the Abell 2744-like superclusters
at $z=0$ increases up to eighteen, among which three are found more massive
than $5\times 10^{15}\,M_{\odot}$.
",0,1,0,0,0,0
20712,Classification of Pressure Gradient of Human Common Carotid Artery and Ascending Aorta on the Basis of Age and Gender,"  The current work is done to see which artery has more chance of having
cardiovascular diseases by measuring value of pressure gradient in the common
carotid artery (CCA) and ascending aorta according to age and gender. Pressure
gradient is determined in the CCA and ascending aorta of presumed healthy
volunteers, having age between 10 and 60 years. A real 2D model of both aorta
and common carotid artery is constructed for different age groups using
computational fluid dynamics (CFD). Pressure gradient of both the arteries are
calculated and compared for different age groups and gender. It is found that
with increase in diameter of common carotid artery and ascending aorta with
advancing age pressure gradient decreases. The value of pressure gradient of
aorta is found less than common carotid artery in both cases of age and gender.
",0,1,0,0,0,0
20713,Second-order and local characteristics of network intensity functions,"  The last decade has witnessed an increase of interest in the spatial analysis
of structured point patterns over networks whose analysis is challenging
because of geometrical complexities and unique methodological problems. In this
context, it is essential to incorporate the network specificity into the
analysis as the locations of events are restricted to areas covered by line
segments. Relying on concepts originating from graph theory, we extend the
notions of first-order network intensity functions to second-order and local
network intensity functions. We consider two types of local indicators of
network association functions which can be understood as adaptations of the
primary ideas of local analysis on the plane. We develop the node-wise and
cross-hierarchical type of local functions. A real dataset on urban
disturbances is also presented.
",0,0,0,1,0,0
20714,Modeling of hysteresis loop and its applications in ferroelectric materials,"  In order to understand the physical hysteresis loops clearly, we constructed
a novel model, which is combined with the electric field, the temperature, and
the stress as one synthetically parameter. This model revealed the shape of
hysteresis loop was determined by few variables in ferroelectric materials: the
saturation of polarization, the coercive field, the electric susceptibility and
the equivalent field. Comparison with experimental results revealed the model
can retrace polarization versus electric field and temperature. As a
applications of this model, the calculate formula of energy storage efficiency,
the electrocaloric effect, and the P(E,T) function have also been included in
this article.
",0,1,0,0,0,0
20715,Online Factorization and Partition of Complex Networks From Random Walks,"  Finding the reduced-dimensional structure is critical to understanding
complex networks. Existing approaches such as spectral clustering are
applicable only when the full network is explicitly observed. In this paper, we
focus on the online factorization and partition of implicit large-scale
networks based on observations from an associated random walk. We formulate
this into a nonconvex stochastic factorization problem and propose an efficient
and scalable stochastic generalized Hebbian algorithm. The algorithm is able to
process dependent state-transition data dynamically generated by the underlying
network and learn a low-dimensional representation for each vertex. By applying
a diffusion approximation analysis, we show that the continuous-time limiting
process of the stochastic algorithm converges globally to the ""principal
components"" of the Markov chain and achieves a nearly optimal sample
complexity. Once given the learned low-dimensional representations, we further
apply clustering techniques to recover the network partition. We show that when
the associated Markov process is lumpable, one can recover the partition
exactly with high probability. We apply the proposed approach to model the
traffic flow of Manhattan as city-wide random walks. By using our algorithm to
analyze the taxi trip data, we discover a latent partition of the Manhattan
city that closely matches the traffic dynamics.
",1,0,1,1,0,0
20716,Powerful genome-wide design and robust statistical inference in two-sample summary-data Mendelian randomization,"  Two-sample summary-data Mendelian randomization (MR) has become a popular
research design to estimate the causal effect of risk exposures. With the
sample size of GWAS continuing to increase, it is now possible to utilize
genetic instruments that are only weakly associated with the exposure. To
maximize the statistical power of MR, we propose a genome-wide design where
more than a thousand genetic instruments are used. For the statistical
analysis, we use an empirical partially Bayes approach where instruments are
weighted according to their strength, thus weak instruments bring less
variation to the estimator. The estimator is highly efficient with many weak
genetic instruments and is robust to balanced and/or sparse pleiotropy. We
apply our method to estimate the causal effect of body mass index (BMI) and
major blood lipids on cardiovascular disease outcomes and obtain substantially
shorter confidence intervals. Some new and statistically significant findings
are: the estimated causal odds ratio of BMI on ischemic stroke is 1.19 (95% CI:
1.07--1.32, p-value < 0.001); the estimated causal odds ratio of high-density
lipoprotein cholesterol (HDL-C) on coronary artery disease (CAD) is 0.78 (95%
CI 0.73--0.84, p-value < 0.001). However, the estimated effect of HDL-C becomes
substantially smaller and statistically non-significant when we only use the
strong instruments. By employing a genome-wide design and robust statistical
methods, the statistical power of MR studies can be greatly improved. Our
empirical results suggest that, even though the relationship between HDL-C and
CAD appears to be highly heterogeneous, it may be too soon to completely
dismiss the HDL hypothesis.
",0,0,0,1,0,0
20717,A Benchmark on Reliability of Complex Discrete Systems: Emergency Power Supply of a Nuclear Power Plant,"  This paper contains two parts: the description of a real electrical system,
with many redundancies, reconfigurations and repairs, then the description of a
reliability model of this system, based on the BDMP (Boolean logic Driven
Markov Processes) formalism and partial results of a reliability and
availability calculation made from this model.
",1,0,0,0,0,0
20718,Riemannian Gaussian distributions on the space of positive-definite quaternion matrices,"  Recently, Riemannian Gaussian distributions were defined on spaces of
positive-definite real and complex matrices. The present paper extends this
definition to the space of positive-definite quaternion matrices. In order to
do so, it develops the Riemannian geometry of the space of positive-definite
quaternion matrices, which is shown to be a Riemannian symmetric space of
non-positive curvature. The paper gives original formulae for the Riemannian
metric of this space, its geodesics, and distance function. Then, it develops
the theory of Riemannian Gaussian distributions, including the exact expression
of their probability density, their sampling algorithm and statistical
inference.
",0,0,1,1,0,0
20719,Analisis of the power flow in Low Voltage DC grids,"  Power flow in a low voltage direct current grid (LVDC) is a non-linear
problem just as its counterpart ac. This paper demonstrates that, unlike in ac
grids, convergence and uniqueness of the solution can be guaranteed in this
type of grids. The result is not a linearization nor an approximation, but an
analysis of the set of non-linear algebraic equations, which is valid for any
LVDC grid regardless its size, topology or load condition. Computer simulation
corroborate the theoretical analysis.
",0,0,1,0,0,0
20720,Multi-scale bilinear restriction estimates for general phases,"  We prove (adjoint) bilinear restriction estimates for general phases at
different scales in the full non-endpoint mixed norm range, and give bounds
with a sharp and explicit dependence on the phases. These estimates have
applications to high-low frequency interactions for solutions to partial
differential equations, as well as to the linear restriction problem for
surfaces with degenerate curvature. As a consequence, we obtain new bilinear
restriction estimates for elliptic phases and wave/Klein-Gordon interactions in
the full bilinear range, and give a refined Strichartz inequality for the
Klein-Gordon equation. In addition, we extend these bilinear estimates to hold
in adapted function spaces by using a transference type principle which holds
for vector valued waves.
",0,0,1,0,0,0
20721,Program algebra for Turing-machine programs,"  This note presents an algebraic theory of instruction sequences with
instructions for Turing tapes as basic instructions, the behaviours produced by
the instruction sequences concerned under execution, and the interaction
between such behaviours and the Turing tapes provided by an execution
environment. This theory provides a setting for investigating issues relating
to computability and computational complexity that is more general than the
closely related Turing-machine models of computation. The theory is essentially
an instantiation of a parameterized algebraic theory which is the basis of a
line of research in which issues relating to a wide variety of subjects from
computer science have been rigorously investigated thinking in terms of
instruction sequences.
",1,0,0,0,0,0
20722,"CTD: Fast, Accurate, and Interpretable Method for Static and Dynamic Tensor Decompositions","  How can we find patterns and anomalies in a tensor, or multi-dimensional
array, in an efficient and directly interpretable way? How can we do this in an
online environment, where a new tensor arrives each time step? Finding patterns
and anomalies in a tensor is a crucial problem with many applications,
including building safety monitoring, patient health monitoring, cyber
security, terrorist detection, and fake user detection in social networks.
Standard PARAFAC and Tucker decomposition results are not directly
interpretable. Although a few sampling-based methods have previously been
proposed towards better interpretability, they need to be made faster, more
memory efficient, and more accurate.
In this paper, we propose CTD, a fast, accurate, and directly interpretable
tensor decomposition method based on sampling. CTD-S, the static version of
CTD, provably guarantees a high accuracy that is 17 ~ 83x more accurate than
that of the state-of-the-art method. Also, CTD-S is made 5 ~ 86x faster, and 7
~ 12x more memory-efficient than the state-of-the-art method by removing
redundancy. CTD-D, the dynamic version of CTD, is the first interpretable
dynamic tensor decomposition method ever proposed. Also, it is made 2 ~ 3x
faster than already fast CTD-S by exploiting factors at previous time step and
by reordering operations. With CTD, we demonstrate how the results can be
effectively interpreted in the online distributed denial of service (DDoS)
attack detection.
",1,0,0,1,0,0
20723,Memory Augmented Control Networks,"  Planning problems in partially observable environments cannot be solved
directly with convolutional networks and require some form of memory. But, even
memory networks with sophisticated addressing schemes are unable to learn
intelligent reasoning satisfactorily due to the complexity of simultaneously
learning to access memory and plan. To mitigate these challenges we introduce
the Memory Augmented Control Network (MACN). The proposed network architecture
consists of three main parts. The first part uses convolutions to extract
features and the second part uses a neural network-based planning module to
pre-plan in the environment. The third part uses a network controller that
learns to store those specific instances of past information that are necessary
for planning. The performance of the network is evaluated in discrete grid
world environments for path planning in the presence of simple and complex
obstacles. We show that our network learns to plan and can generalize to new
environments.
",1,0,0,0,0,0
20724,Community Recovery in a Preferential Attachment Graph,"  A message passing algorithm is derived for recovering communities within a
graph generated by a variation of the Barabási-Albert preferential
attachment model. The estimator is assumed to know the arrival times, or order
of attachment, of the vertices. The derivation of the algorithm is based on
belief propagation under an independence assumption. Two precursors to the
message passing algorithm are analyzed: the first is a degree thresholding (DT)
algorithm and the second is an algorithm based on the arrival times of the
children (C) of a given vertex, where the children of a given vertex are the
vertices that attached to it. Comparison of the performance of the algorithms
shows it is beneficial to know the arrival times, not just the number, of the
children. The probability of correct classification of a vertex is
asymptotically determined by the fraction of vertices arriving before it. Two
extensions of Algorithm C are given: the first is based on joint likelihood of
the children of a fixed set of vertices; it can sometimes be used to seed the
message passing algorithm. The second is the message passing algorithm.
Simulation results are given.
",1,0,0,1,0,0
20725,The descriptive look at the size of subsets of groups,"  We explore the Borel complexity of some basic families of subsets of a
countable group (large, small, thin, sparse and other) defined by the size of
their elements. Applying the obtained results to the Stone-Čech
compactification $\beta G$ of $G$, we prove, in particular, that the closure of
the minimal ideal of $\beta G$ is of type $F_{\sigma\delta}$.
",0,0,1,0,0,0
20726,The Impact of Antenna Height Difference on the Performance of Downlink Cellular Networks,"  Capable of significantly reducing cell size and enhancing spatial reuse,
network densification is shown to be one of the most dominant approaches to
expand network capacity. Due to the scarcity of available spectrum resources,
nevertheless, the over-deployment of network infrastructures, e.g., cellular
base stations (BSs), would strengthen the inter-cell interference as well, thus
in turn deteriorating the system performance. On this account, we investigate
the performance of downlink cellular networks in terms of user coverage
probability (CP) and network spatial throughput (ST), aiming to shed light on
the limitation of network densification. Notably, it is shown that both CP and
ST would be degraded and even diminish to be zero when BS density is
sufficiently large, provided that practical antenna height difference (AHD)
between BSs and users is involved to characterize pathloss. Moreover, the
results also reveal that the increase of network ST is at the expense of the
degradation of CP. Therefore, to balance the tradeoff between user and network
performance, we further study the critical density, under which ST could be
maximized under the CP constraint. Through a special case study, it follows
that the critical density is inversely proportional to the square of AHD. The
results in this work could provide helpful guideline towards the application of
network densification in the next-generation wireless networks.
",1,0,0,0,0,0
20727,Spin-wave propagation in cubic anisotropic materials,"  The information carrier of modern technologies is the electron charge whose
transport inevitably generates Joule heating. Spin-waves, the collective
precessional motion of electron spins, do not involve moving charges and thus
avoid Joule heating. In this respect, magnonic devices in which the information
is carried by spin-waves attract interest for low-power computing. However
implementation of magnonic devices for practical use suffers from low spin-wave
signal and on/off ratio. Here we demonstrate that cubic anisotropic materials
can enhance spin-wave signals by improving spin-wave amplitude as well as group
velocity and attenuation length. Furthermore, cubic anisotropic material shows
an enhanced on/off ratio through a laterally localized edge mode, which closely
mimics the gate-controlled conducting channel in traditional field-effect
transistors. These attractive features of cubic anisotropic materials will
invigorate magnonics research towards wave-based functional devices.
",0,1,0,0,0,0
20728,Relaxing Exclusive Control in Boolean Games,"  In the typical framework for boolean games (BG) each player can change the
truth value of some propositional atoms, while attempting to make her goal
true. In standard BG goals are propositional formulas, whereas in iterated BG
goals are formulas of Linear Temporal Logic. Both notions of BG are
characterised by the fact that agents have exclusive control over their set of
atoms, meaning that no two agents can control the same atom. In the present
contribution we drop the exclusivity assumption and explore structures where an
atom can be controlled by multiple agents. We introduce Concurrent Game
Structures with Shared Propositional Control (CGS-SPC) and show that they ac-
count for several classes of repeated games, including iterated boolean games,
influence games, and aggregation games. Our main result shows that, as far as
verification is concerned, CGS-SPC can be reduced to concurrent game structures
with exclusive control. This result provides a polynomial reduction for the
model checking problem of specifications in Alternating-time Temporal Logic on
CGS-SPC.
",1,0,0,0,0,0
20729,Representing de Rham cohomology classes on an open Riemann surface by holomorphic forms,"  Let $X$ be a connected open Riemann surface. Let $Y$ be an Oka domain in the
smooth locus of an analytic subvariety of $\mathbb C^n$, $n\geq 1$, such that
the convex hull of $Y$ is all of $\mathbb C^n$. Let $\mathscr O_*(X, Y)$ be the
space of nondegenerate holomorphic maps $X\to Y$. Take a holomorphic $1$-form
$\theta$ on $X$, not identically zero, and let $\pi:\mathscr O_*(X,Y) \to
H^1(X,\mathbb C^n)$ send a map $g$ to the cohomology class of $g\theta$. Our
main theorem states that $\pi$ is a Serre fibration. This result subsumes the
1971 theorem of Kusunoki and Sainouchi that both the periods and the divisor of
a holomorphic form on $X$ can be prescribed arbitrarily. It also subsumes two
parametric h-principles in minimal surface theory proved by Forstneric and
Larusson in 2016.
",0,0,1,0,0,0
20730,Unidirectional control of optically induced spin waves,"  Unidirectional control of optically induced spin waves in a rare-earth iron
garnet crystal is demonstrated. We observed the interference of two spin-wave
packets with different initial phases generated by circularly polarized light
pulses. This interference results in unidirectional propagation if the
spin-wave sources are spaced apart at 1/4 of the wavelength of the spin waves
and the initial phase difference is set to pi/2. The propagating direction of
the spin wave is switched by the polarization helicity of the light pulses.
Moreover, in a numerical simulation, applying more than two spin-wave sources
with a suitable polarization and spot shape, arbitrary manipulation of the spin
wave by the phased array method was replicated.
",0,1,0,0,0,0
20731,Value Prediction Network,"  This paper proposes a novel deep reinforcement learning (RL) architecture,
called Value Prediction Network (VPN), which integrates model-free and
model-based RL methods into a single neural network. In contrast to typical
model-based RL methods, VPN learns a dynamics model whose abstract states are
trained to make option-conditional predictions of future values (discounted sum
of rewards) rather than of future observations. Our experimental results show
that VPN has several advantages over both model-free and model-based baselines
in a stochastic environment where careful planning is required but building an
accurate observation-prediction model is difficult. Furthermore, VPN
outperforms Deep Q-Network (DQN) on several Atari games even with
short-lookahead planning, demonstrating its potential as a new way of learning
a good state representation.
",1,0,0,0,0,0
20732,Scalable Generalized Linear Bandits: Online Computation and Hashing,"  Generalized Linear Bandits (GLBs), a natural extension of the stochastic
linear bandits, has been popular and successful in recent years. However,
existing GLBs scale poorly with the number of rounds and the number of arms,
limiting their utility in practice. This paper proposes new, scalable solutions
to the GLB problem in two respects. First, unlike existing GLBs, whose
per-time-step space and time complexity grow at least linearly with time $t$,
we propose a new algorithm that performs online computations to enjoy a
constant space and time complexity. At its heart is a novel Generalized Linear
extension of the Online-to-confidence-set Conversion (GLOC method) that takes
\emph{any} online learning algorithm and turns it into a GLB algorithm. As a
special case, we apply GLOC to the online Newton step algorithm, which results
in a low-regret GLB algorithm with much lower time and memory complexity than
prior work. Second, for the case where the number $N$ of arms is very large, we
propose new algorithms in which each next arm is selected via an inner product
search. Such methods can be implemented via hashing algorithms (i.e.,
""hash-amenable"") and result in a time complexity sublinear in $N$. While a
Thompson sampling extension of GLOC is hash-amenable, its regret bound for
$d$-dimensional arm sets scales with $d^{3/2}$, whereas GLOC's regret bound
scales with $d$. Towards closing this gap, we propose a new hash-amenable
algorithm whose regret bound scales with $d^{5/4}$. Finally, we propose a fast
approximate hash-key computation (inner product) with a better accuracy than
the state-of-the-art, which can be of independent interest. We conclude the
paper with preliminary experimental results confirming the merits of our
methods.
",1,0,0,1,0,0
20733,Dome of magnetic order inside the nematic phase of sulfur-substituted FeSe under pressure,"  The pressure dependence of the structural, magnetic and superconducting
transitions and of the superconducting upper critical field were studied in
sulfur-substituted Fe(Se$_{1-x}$S$_{x}$). Resistance measurements were
performed on single crystals with three substitution levels ($x$=0.043, 0.096,
0.12) under hydrostatic pressures up to 1.8 GPa and in magnetic fields up to 9
T, and compared to data on pure FeSe. Our results illustrate the effects of
chemical and physical pressure on Fe(Se$_{1-x}$S$_{x}$). On increasing sulfur
content, magnetic order in the low-pressure range is strongly suppressed to a
small dome-like region in the phase diagrams. However, $T_s$ is much less
suppressed by sulfur substitution and $T_c$ of Fe(Se$_{1-x}$S$_{x}$) exhibits
similar non-monotonic pressure dependence with a local maximum and a local
minimum present in the low pressure range for all $x$. The local maximum in
$T_c$ coincides with the emergence of the magnetic order above $T_c$. At this
pressure the slope of the upper critical field decreases abruptly. The minimum
of $T_c$ correlates with a broad maximum of the upper critical field slope
normalized by $T_c$.
",0,1,0,0,0,0
20734,ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge,"  This paper describes Luminoso's participation in SemEval 2017 Task 2,
""Multilingual and Cross-lingual Semantic Word Similarity"", with a system based
on ConceptNet. ConceptNet is an open, multilingual knowledge graph that focuses
on general knowledge that relates the meanings of words and phrases. Our
submission to SemEval was an update of previous work that builds high-quality,
multilingual word embeddings from a combination of ConceptNet and
distributional semantics. Our system took first place in both subtasks. It
ranked first in 4 out of 5 of the separate languages, and also ranked first in
all 10 of the cross-lingual language pairs.
",1,0,0,0,0,0
20735,The symmetrized topological complexity of the circle,"  We determine the symmetrized topological complexity of the circle, using
primarily just general topology.
",0,0,1,0,0,0
20736,Intertwining operators among twisted modules associated to not-necessarily-commuting automorphisms,"  We introduce intertwining operators among twisted modules or twisted
intertwining operators associated to not-necessarily-commuting automorphisms of
a vertex operator algebra. Let $V$ be a vertex operator algebra and let
$g_{1}$, $g_{2}$ and $g_{3}$ be automorphisms of $V$. We prove that for
$g_{1}$-, $g_{2}$- and $g_{3}$-twisted $V$-modules $W_{1}$, $W_{2}$ and
$W_{3}$, respectively, such that the vertex operator map for $W_{3}$ is
injective, if there exists a twisted intertwining operator of type
${W_{3}\choose W_{1}W_{2}}$ such that the images of its component operators
span $W_{3}$, then $g_{3}=g_{1}g_{2}$. We also construct what we call the
skew-symmetry and contragredient isomorphisms between spaces of twisted
intertwining operators among twisted modules of suitable types. The proofs of
these results involve careful analysis of the analytic extensions corresponding
to the actions of the not-necessarily-commuting automorphisms of the vertex
operator algebra.
",0,0,1,0,0,0
20737,Enabling Visual Design Verification Analytics - From Prototype Visualizations to an Analytics Tool using the Unity Game Engine,"  The ever-increasing architectural complexity in contemporary ASIC projects
turns Design Verification (DV) into a highly advanced endeavor. Pressing needs
for short time-to-market has made automation a key solution in DV. However,
recurring execution of large regression suites inevitably leads to challenging
amounts of test results. Following the design science paradigm, we present an
action research study to introduce visual analytics in a commercial ASIC
project. We develop a cityscape visualization tool using the game engine Unity.
Initial evaluations are promising, suggesting that the tool offers a novel
approach to identify error-prone parts of the design, as well as coverage
holes.
",1,0,0,0,0,0
20738,Self-regulation promotes cooperation in social networks,"  Cooperative behavior in real social dilemmas is often perceived as a
phenomenon emerging from norms and punishment. To overcome this paradigm, we
highlight the interplay between the influence of social networks on
individuals, and the activation of spontaneous self-regulating mechanisms,
which may lead them to behave cooperatively, while interacting with others and
taking conflicting decisions over time. By extending Evolutionary game theory
over networks, we prove that cooperation partially or fully emerges whether
self-regulating mechanisms are sufficiently stronger than social pressure.
Interestingly, even few cooperative individuals act as catalyzing agents for
the cooperation of others, thus activating a recruiting mechanism, eventually
driving the whole population to cooperate.
",1,0,0,0,0,0
20739,Magnetic properties of nanoparticles compacts with controlled broadening of the particle size distribution,"  Binary random compacts with different proportions of small (volume V) and
large (volume 2V) bare maghemite nanoparticles (NPs) are used to investigate
the effect of controllably broadening the particle size distribution on the
magnetic properties of magnetic NP assemblies with strong dipolar interaction.
A series of eight random mixtures of highly uniform 9.0 and 11.5 nm diameter
maghemite particles prepared by thermal decomposition are studied. In spite of
severely broadened size distributions in the mixed samples, well defined
superspin glass transition temperatures are observed across the series, their
values increasing linearly with the weight fraction of large particles.
",0,1,0,0,0,0
20740,A Generative Model for Exploring Structure Regularities in Attributed Networks,"  Many real-world networks known as attributed networks contain two types of
information: topology information and node attributes. It is a challenging task
on how to use these two types of information to explore structural
regularities. In this paper, by characterizing potential relationship between
link communities and node attributes, a principled statistical model named
PSB_PG that generates link topology and node attributes is proposed. This model
for generating links is based on the stochastic blockmodels following a Poisson
distribution. Therefore, it is capable of detecting a wide range of network
structures including community structures, bipartite structures and other
mixture structures. The model for generating node attributes assumes that node
attributes are high dimensional and sparse and also follow a Poisson
distribution. This makes the model be uniform and the model parameters can be
directly estimated by expectation-maximization (EM) algorithm. Experimental
results on artificial networks and real networks containing various structures
have shown that the proposed model PSB_PG is not only competitive with the
state-of-the-art models, but also provides good semantic interpretation for
each community via the learned relationship between the community and its
related attributes.
",1,0,0,0,0,0
20741,On the maximal halfspace depth of permutation-invariant distributions on the simplex,"  We compute the maximal halfspace depth for a class of permutation-invariant
distributions on the probability simplex. The derivations are based on
stochastic ordering results that so far were only showed to be relevant for the
Behrens-Fisher problem.
",0,0,1,1,0,0
20742,Theoretical Evaluation of Li et al.'s Approach for Improving a Binary Watermark-Based Scheme in Remote Sensing Data Communications,"  This letter is about a principal weakness of the published article by Li et
al. in 2014. It seems that the mentioned work has a terrible conceptual mistake
while presenting its theoretical approach. In fact, the work has tried to
design a new attack and its effective solution for a basic watermarking
algorithm by Zhu et al. published in 2013, however in practice, we show the Li
et al.'s approach is not correct to obtain the aim. For disproof of the
incorrect approach, we only apply a numerical example as the counterexample of
the Li et al.'s approach.
",1,0,0,0,0,0
20743,Bioinformatics and Medicine in the Era of Deep Learning,"  Many of the current scientific advances in the life sciences have their
origin in the intensive use of data for knowledge discovery. In no area this is
so clear as in bioinformatics, led by technological breakthroughs in data
acquisition technologies. It has been argued that bioinformatics could quickly
become the field of research generating the largest data repositories, beating
other data-intensive areas such as high-energy physics or astroinformatics.
Over the last decade, deep learning has become a disruptive advance in machine
learning, giving new live to the long-standing connectionist paradigm in
artificial intelligence. Deep learning methods are ideally suited to
large-scale data and, therefore, they should be ideally suited to knowledge
discovery in bioinformatics and biomedicine at large. In this brief paper, we
review key aspects of the application of deep learning in bioinformatics and
medicine, drawing from the themes covered by the contributions to an ESANN 2018
special session devoted to this topic.
",0,0,0,1,1,0
20744,A Weakly Supervised Approach to Train Temporal Relation Classifiers and Acquire Regular Event Pairs Simultaneously,"  Capabilities of detecting temporal relations between two events can benefit
many applications. Most of existing temporal relation classifiers were trained
in a supervised manner. Instead, we explore the observation that regular event
pairs show a consistent temporal relation despite of their various contexts,
and these rich contexts can be used to train a contextual temporal relation
classifier, which can further recognize new temporal relation contexts and
identify new regular event pairs. We focus on detecting after and before
temporal relations and design a weakly supervised learning approach that
extracts thousands of regular event pairs and learns a contextual temporal
relation classifier simultaneously. Evaluation shows that the acquired regular
event pairs are of high quality and contain rich commonsense knowledge and
domain specific knowledge. In addition, the weakly supervised trained temporal
relation classifier achieves comparable performance with the state-of-the-art
supervised systems.
",1,0,0,0,0,0
20745,Privacy with Estimation Guarantees,"  We study the central problem in data privacy: how to share data with an
analyst while providing both privacy and utility guarantees to the user that
owns the data. In this setting, we present an estimation-theoretic analysis of
the privacy-utility trade-off (PUT). Here, an analyst is allowed to reconstruct
(in a mean-squared error sense) certain functions of the data (utility), while
other private functions should not be reconstructed with distortion below a
certain threshold (privacy). We demonstrate how $\chi^2$-information captures
the fundamental PUT in this case and provide bounds for the best PUT. We
propose a convex program to compute privacy-assuring mappings when the
functions to be disclosed and hidden are known a priori and the data
distribution is known. We derive lower bounds on the minimum mean-squared error
of estimating a target function from the disclosed data and evaluate the
robustness of our approach when an empirical distribution is used to compute
the privacy-assuring mappings instead of the true data distribution. We
illustrate the proposed approach through two numerical experiments.
",1,0,0,0,0,0
20746,A line of CFTs: from generalized free fields to SYK,"  We point out that there is a simple variant of the SYK model, which we call
cSYK, that is $SL(2,R)$ invariant for all values of the coupling. The
modification consists of replacing the UV part of the SYK action with a
quadratic bilocal term. The corresponding bulk dual is a non-gravitational
theory in a rigid AdS$_2$ background. At weak coupling cSYK is a generalized
free field theory; at strong coupling, it approaches the infrared of SYK. The
existence of this line of fixed points explains the previously found connection
between the three-point function of bilinears in these two theories at large
$q$.
",0,1,0,0,0,0
20747,Miura transformations for discrete Painlevé equations coming from the affine E$_8$ Weyl group,"  We derive integrable equations starting from autonomous mappings with a
general form inspired by the additive systems associated to the affine Weyl
group E$_8^{(1)}$. By deautonomisation we obtain two hitherto unknown systems,
one of which turns out to be a linearisable one, and we show that both these
systems arise from the deautonomisation of a non-QRT mapping. In order to
unambiguously prove the integrability of these nonautonomous systems, we
introduce a series of Miura transformations which allows us to prove that one
of these systems is indeed a discrete Painlevé equation, related to the
affine Weyl group E$_7^{(1)}$, and to cast it in canonical form. A similar
sequence of Miura transformations allows us to effectively linearise the second
system we obtain. An interesting off-shoot of our calculations is that the
series of Miura transformations, when applied at the autonomous limit, allows
one to transform a non-QRT invariant into a QRT one.
",0,1,1,0,0,0
20748,Virtual Molecular Dynamics,"  Molecular dynamics is based on solving Newton's equations for many-particle
systems that evolve along complex, highly fluctuating trajectories. The orbital
instability and short-time complexity of Newtonian orbits is in sharp contrast
to the more coherent behavior of collective modes such as density profiles. The
notion of virtual molecular dynamics is introduced here based on temporal
coarse-graining via Pade approximants and the Ito formula for stochastic
processes. It is demonstrated that this framework leads to significant
efficiency over traditional molecular dynamics and avoids the need to introduce
coarse-grained variables and phenomenological equations for their evolution. In
this framework, an all-atom trajectory is represented by a Markov chain of
virtual atomic states at a discrete sequence of timesteps, transitions between
which are determined by an integration of conventional molecular dynamics with
Pade approximants and a microstate energy annealing methodology. The latter is
achieved by a conventional and an MD NVE energy minimization schemes. This
multiscale framework is demonstrated for a pertussis toxin subunit undergoing a
structural transition, a T=1 capsid-like structure of HPV16 L1 protein, and two
coalescing argon droplets.
",0,1,0,0,0,0
20749,Regression with genuinely functional errors-in-covariates,"  Contamination of covariates by measurement error is a classical problem in
multivariate regression, where it is well known that failing to account for
this contamination can result in substantial bias in the parameter estimators.
The nature and degree of this effect on statistical inference is also
understood to crucially depend on the specific distributional properties of the
measurement error in question. When dealing with functional covariates,
measurement error has thus far been modelled as additive white noise over the
observation grid. Such a setting implicitly assumes that the error arises
purely at the discrete sampling stage, otherwise the model can only be viewed
in a weak (stochastic differential equation) sense, white noise not being a
second-order process. Departing from this simple distributional setting can
have serious consequences for inference, similar to the multivariate case, and
current methodology will break down. In this paper, we consider the case when
the additive measurement error is allowed to be a valid stochastic process. We
propose a novel estimator of the slope parameter in a functional linear model,
for scalar as well as functional responses, in the presence of this general
measurement error specification. The proposed estimator is inspired by the
multivariate regression calibration approach, but hinges on recent advances on
matrix completion methods for functional data in order to handle the nontrivial
(and unknown) error covariance structure. The asymptotic properties of the
proposed estimators are derived. We probe the performance of the proposed
estimator of slope using simulations and observe that it substantially improves
upon the spectral truncation estimator based on the erroneous observations,
i.e., ignoring measurement error. We also investigate the behaviour of the
estimators on a real dataset on hip and knee angle curves during a gait cycle.
",0,0,0,1,0,0
20750,The distance between a naive cumulative estimator and its least concave majorant,"  We consider the process $\widehat\Lambda_n-\Lambda_n$, where $\Lambda_n$ is a
cadlag step estimator for the primitive $\Lambda$ of a nonincreasing function
$\lambda$ on $[0,1]$, and $\widehat\Lambda_n$ is the least concave majorant of
$\Lambda_n$. We extend the results in Kulikov and Lopuhaä (2006, 2008) to the
general setting considered in Durot (2007). Under this setting we prove that a
suitably scaled version of $\widehat\Lambda_n-\Lambda_n$ converges in
distribution to the corresponding process for two-sided Brownian motion with
parabolic drift and we establish a central limit theorem for the $L_p$-distance
between $\widehat\Lambda_n$ and $\Lambda_n$.
",0,0,1,1,0,0
20751,Controllability of impulse controlled systems of heat equations coupled by constant matrices,"  This paper studies the approximate and null controllability for impulse
controlled systems of heat equations coupled by a pair (A,B) of constant
matrices. We present a necessary and sufficient condition for the approximate
controllability, which is exactly Kalman's controllability rank condition of
(A,B). We prove that when such a system is approximately controllable, the
approximate controllability over an interval [0,T] can be realized by adding
controls at arbitrary n different control instants
0<\tau_1<\tau_2<\cdots<\tau_n<T, provided that \tau_n-\tau_1<d_A, where
d_A=\min\{\pi/|Im \lambda| : \lambda\in \sigma(A)\}. We also show that in
general, such systems are not null controllable.
",0,0,1,0,0,0
20752,Nearly Optimal Constructions of PIR and Batch Codes,"  In this work we study two families of codes with availability, namely private
information retrieval (PIR) codes and batch codes. While the former requires
that every information symbol has $k$ mutually disjoint recovering sets, the
latter asks this property for every multiset request of $k$ information
symbols. The main problem under this paradigm is to minimize the number of
redundancy symbols. We denote this value by $r_P(n,k), r_B(n,k)$, for PIR,
batch codes, respectively, where $n$ is the number of information symbols.
Previous results showed that for any constant $k$, $r_P(n,k) =
\Theta(\sqrt{n})$ and $r_B(n,k)=O(\sqrt{n}\log(n)$. In this work we study the
asymptotic behavior of these codes for non-constant $k$ and specifically for
$k=\Theta(n^\epsilon)$. We also study the largest value of $k$ such that the
rate of the codes approaches 1, and show that for all $\epsilon<1$,
$r_P(n,n^\epsilon) = o(n)$, while for batch codes, this property holds for all
$\epsilon< 0.5$.
",1,0,0,0,0,0
20753,Submillimeter Array CO(2-1) Imaging of the NGC 6946 Giant Molecular Clouds,"  We present a CO(2-1) mosaic map of the spiral galaxy NGC 6946 by combining
data from the Submillimeter Array and the IRAM 30 m telescope. We identify 390
giant molecular clouds (GMCs) from the nucleus to 4.5 kpc in the disk. GMCs in
the inner 1 kpc are generally more luminous and turbulent, some of which have
luminosities >10^6 K km/s pc^2 and velocity dispersions >10 km/s. Large-scale
bar-driven dynamics likely regulate GMC properties in the nuclear region.
Similar to the Milky Way and other disk galaxies, GMC mass function of NGC 6946
has a shallower slope (index>-2) in the inner region, and a steeper slope
(index<-2) in the outer region. This difference in mass spectra may be
indicative of different cloud formation pathways: gravitational instabilities
might play a major role in the nuclear region, while cloud coalescence might be
dominant in the outer disk. Finally, the NGC 6946 clouds are similar to those
in M33 in terms of statistical properties, but they are generally less luminous
and turbulent than the M51 clouds.
",0,1,0,0,0,0
20754,Optical and Near-Infrared Spectra of sigma Orionis Isolated Planetary-mass Objects,"  We have obtained low-resolution optical (0.7-0.98 micron) and near-infrared
(1.11-1.34 micron and 0.8-2.5 micron) spectra of twelve isolated planetary-mass
candidates (J = 18.2-19.9 mag) of the 3-Myr sigma Orionis star cluster with a
view to determining the spectroscopic properties of very young, substellar
dwarfs and assembling a complete cluster mass function. We have classified our
targets by visual comparison with high- and low-gravity standards and by
measuring newly defined spectroscopic indices. We derived L0-L4.5 and M9-L2.5
using high- and low-gravity standards, respectively. Our targets reveal clear
signposts of youth, thus corroborating their cluster membership and planetary
masses (6-13 Mjup). These observations complete the sigma Orionis mass function
by spectroscopically confirming the planetary-mass domain to a confidence level
of $\sim$75 percent. The comparison of our spectra with BT-Settl solar
metallicity model atmospheres yields a temperature scale of 2350-1800 K and a
low surface gravity of log g ~ 4.0 [cm/s2], as would be expected for young
planetary-mass objects. We discuss the properties of the cluster least-massive
population as a function of spectral type. We have also obtained the first
optical spectrum of S Ori 70, a T dwarf in the direction of sigma Orionis. Our
data provide reference optical and near-infrared spectra of very young L dwarfs
and a mass function that may be used as templates for future studies of
low-mass substellar objects and exoplanets. The extrapolation of the sigma
Orionis mass function to the solar neighborhood may indicate that isolated
planetary-mass objects with temperatures of 200-300 K and masses in the
interval 6-13-Mjup may be as numerous as very low-mass stars.
",0,1,0,0,0,0
20755,The Blackbird Dataset: A large-scale dataset for UAV perception in aggressive flight,"  The Blackbird unmanned aerial vehicle (UAV) dataset is a large-scale,
aggressive indoor flight dataset collected using a custom-built quadrotor
platform for use in evaluation of agile perception.Inspired by the potential of
future high-speed fully-autonomous drone racing, the Blackbird dataset contains
over 10 hours of flight data from 168 flights over 17 flight trajectories and 5
environments at velocities up to $7.0ms^-1$. Each flight includes sensor data
from 120Hz stereo and downward-facing photorealistic virtual cameras, 100Hz
IMU, $\sim190Hz$ motor speed sensors, and 360Hz millimeter-accurate motion
capture ground truth. Camera images for each flight were photorealistically
rendered using FlightGoggles across a variety of environments to facilitate
easy experimentation of high performance perception algorithms. The dataset is
available for download at this http URL
",1,0,0,0,0,0
20756,An integration of fast alignment and maximum-likelihood methods for electron subtomogram averaging and classification,"  Motivation: Cellular Electron CryoTomography (CECT) is an emerging 3D imaging
technique that visualizes subcellular organization of single cells at
submolecular resolution and in near-native state. CECT captures large numbers
of macromolecular complexes of highly diverse structures and abundances.
However, the structural complexity and imaging limits complicate the systematic
de novo structural recovery and recognition of these macromolecular complexes.
Efficient and accurate reference-free subtomogram averaging and classification
represent the most critical tasks for such analysis. Existing subtomogram
alignment based methods are prone to the missing wedge effects and low
signal-to-noise ratio (SNR). Moreover, existing maximum-likelihood based
methods rely on integration operations, which are in principle computationally
infeasible for accurate calculation.
Results: Built on existing works, we propose an integrated method, Fast
Alignment Maximum Likelihood method (FAML), which uses fast subtomogram
alignment to sample sub-optimal rigid transformations. The transformations are
then used to approximate integrals for maximum-likelihood update of subtomogram
averages through expectation-maximization algorithm. Our tests on simulated and
experimental subtomograms showed that, compared to our previously developed
fast alignment method (FA), FAML is significantly more robust to noise and
missing wedge effects with moderate increases of computation cost.Besides, FAML
performs well with significantly fewer input subtomograms when the FA method
fails. Therefore, FAML can serve as a key component for improved construction
of initial structural models from macromolecules captured by CECT.
",0,0,0,1,1,0
20757,Local and global existence of solutions to a strongly damped wave equation of the $p$-Laplacian type,"  This article focuses on a quasilinear wave equation of $p$-Laplacian type: $$
u_{tt} - \Delta_p u - \Delta u_t=0$$ in a bounded domain
$\Omega\subset\mathbb{R}^3$ with a sufficiently smooth boundary
$\Gamma=\partial\Omega$ subject to a generalized Robin boundary condition
featuring boundary damping and a nonlinear source term. The operator
$\Delta_p$, $2 < p < 3$, denotes the classical $p$-Laplacian. The nonlinear
boundary term $f (u)$ is a source feedback that is allowed to have a
supercritical exponent, in the sense that the associated Nemytskii operator is
not locally Lipschitz from $W^{1,p}(\Omega)$ into $L^2(\Gamma)$. Under suitable
assumptions on the parameters we provide a rigorous proof of existence of a
local weak solution which can be extended globally in time provided the source
term satisfies an appropriate growth condition.
",0,0,1,0,0,0
20758,Quasi-flat representations of uniform groups and quantum groups,"  Given a discrete group $\Gamma=<g_1,\ldots,g_M>$ and a number $K\in\mathbb
N$, a unitary representation $\rho:\Gamma\to U_K$ is called quasi-flat when the
eigenvalues of each $\rho(g_i)\in U_K$ are uniformly distributed among the
$K$-th roots of unity. The quasi-flat representations of $\Gamma$ form
altogether a parametric matrix model $\pi:\Gamma\to C(X,U_K)$.
We compute here the universal model space $X$ for various classes of discrete
groups, notably with results in the case where $\Gamma$ is metabelian. We are
particularly interested in the case where $X$ is a union of compact homogeneous
spaces, and where the induced representation $\tilde{\pi}:C^*(\Gamma)\to
C(X,U_K)$ is stationary in the sense that it commutes with the Haar
functionals. We present several positive and negative results on this subject.
We also discuss similar questions for the discrete quantum groups, proving a
stationarity result for the discrete dual of the twisted orthogonal group
$O_2^{-1}$.
",0,0,1,0,0,0
20759,Nonparametric Preference Completion,"  We consider the task of collaborative preference completion: given a pool of
items, a pool of users and a partially observed item-user rating matrix, the
goal is to recover the \emph{personalized ranking} of each user over all of the
items. Our approach is nonparametric: we assume that each item $i$ and each
user $u$ have unobserved features $x_i$ and $y_u$, and that the associated
rating is given by $g_u(f(x_i,y_u))$ where $f$ is Lipschitz and $g_u$ is a
monotonic transformation that depends on the user. We propose a $k$-nearest
neighbors-like algorithm and prove that it is consistent. To the best of our
knowledge, this is the first consistency result for the collaborative
preference completion problem in a nonparametric setting. Finally, we
demonstrate the performance of our algorithm with experiments on the Netflix
and Movielens datasets.
",1,0,0,1,0,0
20760,Real-Time Reconstruction of Counting Process through Queues,"  For the emerging Internet of Things (IoT), one of the most critical problems
is the real-time reconstruction of signals from a set of aged measurements.
During the reconstruction, distortion occurs between the observed signal and
the reconstructed signal due to sampling and transmission. In this paper, we
focus on minimizing the average distortion defined as the 1-norm of the
difference of the two signals under the scenario that a Poisson counting
process is reconstructed in real-time on a remote monitor. Especially, we
consider the reconstruction under uniform sampling policy and two non-uniform
sampling policies, i.e., the threshold-based policy and the zero-wait policy.
For each of the policy, we derive the closed-form expression of the average
distortion by dividing the overall distortion area into polygons and analyzing
their structures. It turns out that the polygons are built up by sub-polygons
that account for distortions caused by sampling and transmission. The
closed-form expressions of the average distortion help us find the optimal
sampling parameters that achieve the minimum distortion. Simulation results are
provided to validate our conclusion.
",1,0,0,0,0,0
20761,Discrepancy-Based Algorithms for Non-Stationary Rested Bandits,"  We study the multi-armed bandit problem where the rewards are realizations of
general non-stationary stochastic processes, a setting that generalizes many
existing lines of work and analyses. In particular, we present a theoretical
analysis and derive regret guarantees for rested bandits in which the reward
distribution of each arm changes only when we pull that arm. Remarkably, our
regret bounds are logarithmic in the number of rounds under several natural
conditions. We introduce a new algorithm based on classical UCB ideas combined
with the notion of weighted discrepancy, a useful tool for measuring the
non-stationarity of a stochastic process. We show that the notion of
discrepancy can be used to design very general algorithms and a unified
framework for the analysis of multi-armed rested bandit problems with
non-stationary rewards. In particular, we show that we can recover the regret
guarantees of many specific instances of bandit problems with non-stationary
rewards that have been studied in the literature. We also provide experiments
demonstrating that our algorithms can enjoy a significant improvement in
practice compared to standard benchmarks.
",1,0,0,0,0,0
20762,Kondo lattice heavy fermion behavior in CeRh2Ga2,"  The physical properties of an intermetallic compound CeRh2Ga2 have been
investigated by magnetic susceptibility \chi(T), isothermal magnetization M(H),
heat capacity C_p(T), electrical resistivity \rho(T), thermal conductivity
\kappa(T) and thermopower S(T) measurements. CeRh2Ga2 is found to crystallize
with CaBe2Ge2-type primitive tetragonal structure (space group P4/nmm). No
evidence of long range magnetic order is seen down to 1.8 K. The \chi(T) data
show paramagnetic behavior with an effective moment \mu_eff ~ 2.5 \mu_B/Ce
indicating Ce^3+ valence state of Ce ions. The \rho(T) data exhibit Kondo
lattice behavior with a metallic ground state. The low-T C_p(T) data yield an
enhanced Sommerfeld coefficient \gamma = 130(2) mJ/mol K^2 characterizing
CeRh2Ga2 as a moderate heavy fermion system. The high-T C_p(T) and \rho(T) show
an anomaly near 255 K, reflecting a phase transition. The \kappa(T) suggests
phonon dominated thermal transport with considerably higher values of Lorenz
number L(T) compared to the theoretical Sommerfeld value L_0.
",0,1,0,0,0,0
20763,Khovanov homology and periodic links,"  Based on the results of the second author, we define an equivariant version
of Lee and Bar-Natan homology for periodic links and show that there exists an
equivariant spectral sequence from the equivariant Khovanov homology to
equivariant Lee homology. As a result we obtain new obstructions for a link to
be periodic. These obstructions generalize previous results of Przytycki and of
the second author.
",0,0,1,0,0,0
20764,A Note on Spectral Clustering and SVD of Graph Data,"  Spectral clustering and Singular Value Decomposition (SVD) are both widely
used technique for analyzing graph data. In this note, I will present their
connections using simple linear algebra, aiming to provide some in-depth
understanding for future research.
",1,0,0,0,0,0
20765,An explicit analysis of the entropic penalty in linear programming,"  Solving linear programs by using entropic penalization has recently attracted
new interest in the optimization community, since this strategy forms the basis
for the fastest-known algorithms for the optimal transport problem, with many
applications in modern large-scale machine learning. Crucial to these
applications has been an analysis of how quickly solutions to the penalized
program approach true optima to the original linear program. More than 20 years
ago, Cominetti and San Martín showed that this convergence is exponentially
fast; however, their proof is asymptotic and does not give any indication of
how accurately the entropic program approximates the original program for any
particular choice of the penalization parameter. We close this long-standing
gap in the literature regarding entropic penalization by giving a new proof of
the exponential convergence, valid for any linear program. Our proof is
non-asymptotic, yields explicit constants, and has the virtue of being
extremely simple. We provide matching lower bounds and show that the entropic
approach does not lead to a near-linear time approximation scheme for the
linear assignment problem.
",0,0,0,1,0,0
20766,Deconstructing the Tail at Scale Effect Across Network Protocols,"  Network latencies have become increasingly important for the performance of
web servers and cloud computing platforms. Identifying network-related tail
latencies and reasoning about their potential causes is especially important to
gauge application run-time in online data-intensive applications, where the
99th percentile latency of individual operations can significantly affect the
the overall latency of requests.
This paper deconstructs the ""tail at scale"" effect across TCP-IP, UDP-IP, and
RDMA network protocols. Prior scholarly works have analyzed tail latencies
caused by extrinsic network parameters like network congestion and flow
fairness. Contrary to existing literature, we identify surprising rare tails in
TCP-IP round-trip measurements that are as enormous as 110x higher than the
median latency. Our experimental design eliminates network congestion as a
tail-inducing factor. Moreover, we observe similar extreme tails in UDP-IP
packet exchanges, ruling out additional TCP-IP protocol operations as the root
cause of tail latency. However, we are unable to reproduce similar tail
latencies in RDMA packet exchanges, which leads us to conclude that the TCP/UDP
protocol stack within the operating system kernel is likely the primary source
of extreme latency tails.
",1,0,0,0,0,0
20767,Deep Neural Generative Model of Functional MRI Images for Psychiatric Disorder Diagnosis,"  Accurate diagnosis of psychiatric disorders plays a critical role in
improving quality of life for patients and potentially supports the development
of new treatments. Many studies have been conducted on machine learning
techniques that seek brain imaging data for specific biomarkers of disorders.
These studies have encountered the following dilemma: An end-to-end
classification overfits to a small number of high-dimensional samples but
unsupervised feature-extraction has the risk of extracting a signal of no
interest. In addition, such studies often provided only diagnoses for patients
without presenting the reasons for these diagnoses. This study proposed a deep
neural generative model of resting-state functional magnetic resonance imaging
(fMRI) data. The proposed model is conditioned by the assumption of the
subject's state and estimates the posterior probability of the subject's state
given the imaging data, using Bayes' rule. This study applied the proposed
model to diagnose schizophrenia and bipolar disorders. Diagnosis accuracy was
improved by a large margin over competitive approaches, namely a support vector
machine, logistic regression, and multilayer perceptron with or without
unsupervised feature-extractors in addition to a Gaussian mixture model. The
proposed model visualizes brain regions largely related to the disorders, thus
motivating further biological investigation.
",1,0,0,1,0,0
20768,Deep Learning for Patient-Specific Kidney Graft Survival Analysis,"  An accurate model of patient-specific kidney graft survival distributions can
help to improve shared-decision making in the treatment and care of patients.
In this paper, we propose a deep learning method that directly models the
survival function instead of estimating the hazard function to predict survival
times for graft patients based on the principle of multi-task learning. By
learning to jointly predict the time of the event, and its rank in the cox
partial log likelihood framework, our deep learning approach outperforms, in
terms of survival time prediction quality and concordance index, other common
methods for survival analysis, including the Cox Proportional Hazards model and
a network trained on the cox partial log-likelihood.
",1,0,0,1,0,0
20769,When is a Network a Network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks,"  We introduce a framework for the modeling of sequential data capturing
pathways of varying lengths observed in a network. Such data are important,
e.g., when studying click streams in information networks, travel patterns in
transportation systems, information cascades in social networks, biological
pathways or time-stamped social interactions. While it is common to apply graph
analytics and network analysis to such data, recent works have shown that
temporal correlations can invalidate the results of such methods. This raises a
fundamental question: when is a network abstraction of sequential data
justified? Addressing this open question, we propose a framework which combines
Markov chains of multiple, higher orders into a multi-layer graphical model
that captures temporal correlations in pathways at multiple length scales
simultaneously. We develop a model selection technique to infer the optimal
number of layers of such a model and show that it outperforms previously used
Markov order detection techniques. An application to eight real-world data sets
on pathways and temporal networks shows that it allows to infer graphical
models which capture both topological and temporal characteristics of such
data. Our work highlights fallacies of network abstractions and provides a
principled answer to the open question when they are justified. Generalizing
network representations to multi-order graphical models, it opens perspectives
for new data mining and knowledge discovery algorithms.
",1,1,0,0,0,0
20770,Outlier-robust moment-estimation via sum-of-squares,"  We develop efficient algorithms for estimating low-degree moments of unknown
distributions in the presence of adversarial outliers. The guarantees of our
algorithms improve in many cases significantly over the best previous ones,
obtained in recent works of Diakonikolas et al, Lai et al, and Charikar et al.
We also show that the guarantees of our algorithms match information-theoretic
lower-bounds for the class of distributions we consider. These improved
guarantees allow us to give improved algorithms for independent component
analysis and learning mixtures of Gaussians in the presence of outliers.
Our algorithms are based on a standard sum-of-squares relaxation of the
following conceptually-simple optimization problem: Among all distributions
whose moments are bounded in the same way as for the unknown distribution, find
the one that is closest in statistical distance to the empirical distribution
of the adversarially-corrupted sample.
",1,0,0,1,0,0
20771,Clustering High Dimensional Dynamic Data Streams,"  We present data streaming algorithms for the $k$-median problem in
high-dimensional dynamic geometric data streams, i.e. streams allowing both
insertions and deletions of points from a discrete Euclidean space $\{1, 2,
\ldots \Delta\}^d$. Our algorithms use $k \epsilon^{-2} poly(d \log \Delta)$
space/time and maintain with high probability a small weighted set of points (a
coreset) such that for every set of $k$ centers the cost of the coreset
$(1+\epsilon)$-approximates the cost of the streamed point set. We also provide
algorithms that guarantee only positive weights in the coreset with additional
logarithmic factors in the space and time complexities. We can use this
positively-weighted coreset to compute a $(1+\epsilon)$-approximation for the
$k$-median problem by any efficient offline $k$-median algorithm. All previous
algorithms for computing a $(1+\epsilon)$-approximation for the $k$-median
problem over dynamic data streams required space and time exponential in $d$.
Our algorithms can be generalized to metric spaces of bounded doubling
dimension.
",1,0,0,0,0,0
20772,Edge contact angle and modified Kelvin equation for condensation in open pores,"  We consider capillary condensation transitions occurring in open slits of
width $L$ and finite height $H$ immersed in a reservoir of vapour. In this case
the pressure at which condensation occurs is closer to saturation compared to
that occurring in an infinite slit ($H=\infty$) due to the presence of two
menisci which are pinned near the open ends. Using macroscopic arguments we
derive a modified Kelvin equation for the pressure, $p_{cc}(L;H)$, at which
condensation occurs and show that the two menisci are characterised by an edge
contact angle $\theta_e$ which is always larger than the equilibrium contact
angle $\theta$, only equal to it in the limit of macroscopic $H$. For walls
which are completely wet ($\theta=0$) the edge contact angle depends only on
the aspect ratio of the capillary and is well described by $\theta_e\approx
\sqrt{\pi L/2H}$ for large $H$. Similar results apply for condensation in
cylindrical pores of finite length. We have tested these predictions against
numerical results obtained using a microscopic density functional model where
the presence of an edge contact angle characterising the shape of the menisci
is clearly visible from the density profiles. Below the wetting temperature
$T_w$ we find very good agreement for slit pores of widths of just a few tens
of molecular diameters while above $T_w$ the modified Kelvin equation only
becomes accurate for much larger systems.
",0,1,0,0,0,0
20773,Thresholds for hanger slackening and cable shortening in the Melan equation for suspension bridges,"  The Melan equation for suspension bridges is derived by assuming small
displacements of the deck and inextensible hangers. We determine the thresholds
for the validity of the Melan equation when the hangers slacken, thereby
violating the inextensibility assumption. To this end, we preliminarily study
the possible shortening of the cables: it turns out that there is a striking
difference between even and odd vibrating modes since the former never shorten
the cables. These problems are studied both on beams and plates.
",0,1,1,0,0,0
20774,Bendable Cuboid Robot Path Planning with Collision Avoidance using Generalized $L_p$ Norms,"  Optimal path planning problems for rigid and deformable (bendable) cuboid
robots are considered by providing an analytic safety constraint using
generalized $L_p$ norms. For regular cuboid robots, level sets of weighted
$L_p$ norms generate implicit approximations of their surfaces. For bendable
cuboid robots a weighted $L_p$ norm in polar coordinates implicitly
approximates the surface boundary through a specified level set. Obstacle
volumes, in the environment to navigate within, are presumed to be
approximately described as sub-level sets of weighted $L_p$ norms. Using these
approximate surface models, the optimal safe path planning problem is
reformulated as a two stage optimization problem, where the safety constraint
depends on a point on the robot which is closest to the obstacle in the
obstacle's distance metric. A set of equality and inequality constraints are
derived to replace the closest point problem, which is then defines additional
analytic constraints on the original path planning problem. Combining all the
analytic constraints with logical AND operations leads to a general optimal
safe path planning problem. Numerically solving the problem involve conversion
to a nonlinear programing problem. Simulations for rigid and bendable cuboid
robot verify the proposed method.
",1,0,0,0,0,0
20775,"Quotients of triangulated categories and Equivalences of Buchweitz, Orlov and Amiot--Guo--Keller","  We give a sufficient condition for a Verdier quotient $\ct/\cs$ of a
triangulated category $\ct$ by a thick subcategory $\cs$ to be realized inside
of $\ct$ as an ideal quotient. As applications, we deduce three significant
results by Buchweitz, Orlov and Amiot--Guo--Keller.
",0,0,1,0,0,0
20776,Sorting sums of binary decision summands,"  A sum where each of the $N$ summands can be independently chosen from two
choices yields $2^N$ possible summation outcomes. There is an
$\mathcal{O}(K^2)$-algorithm that finds the $K$ smallest/largest of these sums
by evading the enumeration of all sums.
",1,0,0,0,0,0
20777,A Pursuit of Temporal Accuracy in General Activity Detection,"  Detecting activities in untrimmed videos is an important but challenging
task. The performance of existing methods remains unsatisfactory, e.g., they
often meet difficulties in locating the beginning and end of a long complex
action. In this paper, we propose a generic framework that can accurately
detect a wide variety of activities from untrimmed videos. Our first
contribution is a novel proposal scheme that can efficiently generate
candidates with accurate temporal boundaries. The other contribution is a
cascaded classification pipeline that explicitly distinguishes between
relevance and completeness of a candidate instance. On two challenging temporal
activity detection datasets, THUMOS14 and ActivityNet, the proposed framework
significantly outperforms the existing state-of-the-art methods, demonstrating
superior accuracy and strong adaptivity in handling activities with various
temporal structures.
",1,0,0,0,0,0
20778,Adjusting systematic bias in high dimensional principal component scores,"  Principal component analysis continues to be a powerful tool in dimension
reduction of high dimensional data. We assume a variance-diverging model and
use the high-dimension, low-sample-size asymptotics to show that even though
the principal component directions are not consistent, the sample and
prediction principal component scores can be useful in revealing the population
structure. We further show that these scores are biased, and the bias is
asymptotically decomposed into rotation and scaling parts. We propose methods
of bias-adjustment that are shown to be consistent and work well in the finite
but high dimensional situations with small sample sizes. The potential
advantage of bias-adjustment is demonstrated in a classification setting.
",0,0,1,1,0,0
20779,Dynamical Exploration of Amplitude Bistability in Engineered Quantum Systems,"  Nonlinear systems, whose outputs are not directly proportional to their
inputs, are well known to exhibit many interesting and important phenomena
which have profoundly changed our technological landscape over the last 50
years. Recently the ability to engineer quantum metamaterials through
hybridisation has allowed to explore these nonlinear effects in systems with no
natural analogue. Here we investigate amplitude bistability, which is one of
the most fundamental nonlinear phenomena, in a hybrid system composed of a
superconducting resonator inductively coupled to an ensemble of
nitrogen-vacancy centres. One of the exciting properties of this spin system is
its extremely long spin life-time, more than ten orders of magnitude longer
than other relevant timescales of the hybrid system. This allows us to
dynamically explore this nonlinear regime of cavity quantum electrodynamics
(cQED) and demonstrate a critical slowing down of the cavity population on the
order of several tens of thousands of seconds - a timescale much longer than
observed so far for this effect. Our results provide the foundation for future
quantum technologies based on nonlinear phenomena.
",0,1,0,0,0,0
20780,Map Memorization and Forgetting in the IARA Autonomous Car,"  In this work, we present a novel strategy for correcting imperfections in
occupancy grid maps called map decay. The objective of map decay is to correct
invalid occupancy probabilities of map cells that are unobservable by sensors.
The strategy was inspired by an analogy between the memory architecture
believed to exist in the human brain and the maps maintained by an autonomous
vehicle. It consists in merging sensory information obtained during runtime
(online) with a priori data from a high-precision map constructed offline. In
map decay, cells observed by sensors are updated using traditional occupancy
grid mapping techniques and unobserved cells are adjusted so that their
occupancy probabilities tend to the values found in the offline map. This
strategy is grounded in the idea that the most precise information available
about an unobservable cell is the value found in the high-precision offline
map. Map decay was successfully tested and is still in use in the IARA
autonomous vehicle from Universidade Federal do Espírito Santo.
",1,0,0,0,0,0
20781,Effective Subgroup Separability of Finitely Generated Nilpotent Groups,"  This paper studies effective separability for subgroups of finitely generated
nilpotent groups and more broadly effective subgroup separability of finitely
generated nilpotent groups. We provide upper and lower bounds that are
polynomial with respect to the logarithm of the word length for infinite index
subgroups of nilpotent groups. In the case of normal subgroups, we provide an
exact computation generalizing work of the second author. We introduce a
function that quantifies subgroup separability, and we provide polynomial upper
and lower bounds. We finish by demonstrating that our results extend to
virtually nilpotent groups.
",0,0,1,0,0,0
20782,External Prior Guided Internal Prior Learning for Real-World Noisy Image Denoising,"  Most of existing image denoising methods learn image priors from either
external data or the noisy image itself to remove noise. However, priors
learned from external data may not be adaptive to the image to be denoised,
while priors learned from the given noisy image may not be accurate due to the
interference of corrupted noise. Meanwhile, the noise in real-world noisy
images is very complex, which is hard to be described by simple distributions
such as Gaussian distribution, making real-world noisy image denoising a very
challenging problem. We propose to exploit the information in both external
data and the given noisy image, and develop an external prior guided internal
prior learning method for real-world noisy image denoising. We first learn
external priors from an independent set of clean natural images. With the aid
of learned external priors, we then learn internal priors from the given noisy
image to refine the prior model. The external and internal priors are
formulated as a set of orthogonal dictionaries to efficiently reconstruct the
desired image. Extensive experiments are performed on several real-world noisy
image datasets. The proposed method demonstrates highly competitive denoising
performance, outperforming state-of-the-art denoising methods including those
designed for real-world noisy images.
",1,0,0,0,0,0
20783,A Study of MAC Address Randomization in Mobile Devices and When it Fails,"  MAC address randomization is a privacy technique whereby mobile devices
rotate through random hardware addresses in order to prevent observers from
singling out their traffic or physical location from other nearby devices.
Adoption of this technology, however, has been sporadic and varied across
device manufacturers. In this paper, we present the first wide-scale study of
MAC address randomization in the wild, including a detailed breakdown of
different randomization techniques by operating system, manufacturer, and model
of device.
We then identify multiple flaws in these implementations which can be
exploited to defeat randomization as performed by existing devices. First, we
show that devices commonly make improper use of randomization by sending
wireless frames with the true, global address when they should be using a
randomized address. We move on to extend the passive identification techniques
of Vanhoef et al. to effectively defeat randomization in ~96% of Android
phones. Finally, we show a method that can be used to track 100% of devices
using randomization, regardless of manufacturer, by exploiting a previously
unknown flaw in the way existing wireless chipsets handle low-level control
frames.
",1,0,0,0,0,0
20784,Completion of the integrable coupling systems,"  In this paper, we proposed an procedure to construct the completion of the
integrable system by adding a perturbation to the generalized matrix problem,
which can be used to continuous integrable couplings, discrete integrable
couplings and super integrable couplings. As example, we construct the
completion of the Kaup-Newell (KN) integrable coupling, the
Wadati-Konno-Ichikawa (WKI) integrable couplingsis, vector
Ablowitz-Kaup-Newell-Segur (vAKNS) integrable couplings, the Volterra
integrable couplings, Dirac type integrable couplings and NLS-mKdV type
integrable couplings.
",0,1,0,0,0,0
20785,On the wildness of cambrian lattices,"  In this note, we investigate the representation type of the cambrian lattices
and some other related lattices. The result is expressed as a very simple
trichotomy. When the rank of the underlined Coxeter group is at most 2, the
lattices are of finite representation type. When the Coxeter group is a
reducible group of type A 3 1 , the lattices are of tame representation type.
In all the other cases they are of wild representation type.
",0,0,1,0,0,0
20786,Random Projections For Large-Scale Regression,"  Fitting linear regression models can be computationally very expensive in
large-scale data analysis tasks if the sample size and the number of variables
are very large. Random projections are extensively used as a dimension
reduction tool in machine learning and statistics. We discuss the applications
of random projections in linear regression problems, developed to decrease
computational costs, and give an overview of the theoretical guarantees of the
generalization error. It can be shown that the combination of random
projections with least squares regression leads to similar recovery as ridge
regression and principal component regression. We also discuss possible
improvements when averaging over multiple random projections, an approach that
lends itself easily to parallel implementation.
",0,0,1,1,0,0
20787,Properties of linear groups with restricted unipotent elements,"  We consider linear groups which do not contain unipotent elements of infinite
order, which includes all linear groups in positive characteristic, and show
that this class of groups has good properties which resemble those held by
groups of non positive curvature and which do not hold for arbitrary
characteristic zero linear groups. In particular if such a linear group is
finitely generated then centralisers virtually split and all finitely generated
abelian subgroups are undistorted. If further the group is virtually torsion
free (which always holds in characteristic zero) then we have a strong property
on small subgroups: any subgroup either contains a non abelian free group or is
finitely generated and virtually abelian, hence also undistorted. We present
applications, including that the mapping class group of a surface having genus
at least 3 has no faithful linear representation which is complex unitary or
over any field of positive characteristic.
",0,0,1,0,0,0
20788,Sparse Approximation of 3D Meshes using the Spectral Geometry of the Hamiltonian Operator,"  The discrete Laplace operator is ubiquitous in spectral shape analysis, since
its eigenfunctions are provably optimal in representing smooth functions
defined on the surface of the shape. Indeed, subspaces defined by its
eigenfunctions have been utilized for shape compression, treating the
coordinates as smooth functions defined on the given surface. However, surfaces
of shapes in nature often contain geometric structures for which the general
smoothness assumption may fail to hold. At the other end, some explicit mesh
compression algorithms utilize the order by which vertices that represent the
surface are traversed, a property which has been ignored in spectral
approaches. Here, we incorporate the order of vertices into an operator that
defines a novel spectral domain. We propose a method for representing 3D meshes
using the spectral geometry of the Hamiltonian operator, integrated within a
sparse approximation framework. We adapt the concept of a potential function
from quantum physics and incorporate vertex ordering information into the
potential, yielding a novel data-dependent operator. The potential function
modifies the spectral geometry of the Laplacian to focus on regions with finer
details of the given surface. By sparsely encoding the geometry of the shape
using the proposed data-dependent basis, we improve compression performance
compared to previous results that use the standard Laplacian basis and spectral
graph wavelets.
",1,0,0,0,0,0
20789,Improved Convergence Rates for Distributed Resource Allocation,"  In this paper, we develop a class of decentralized algorithms for solving a
convex resource allocation problem in a network of $n$ agents, where the agent
objectives are decoupled while the resource constraints are coupled. The agents
communicate over a connected undirected graph, and they want to collaboratively
determine a solution to the overall network problem, while each agent only
communicates with its neighbors. We first study the connection between the
decentralized resource allocation problem and the decentralized consensus
optimization problem. Then, using a class of algorithms for solving consensus
optimization problems, we propose a novel class of decentralized schemes for
solving resource allocation problems in a distributed manner. Specifically, we
first propose an algorithm for solving the resource allocation problem with an
$o(1/k)$ convergence rate guarantee when the agents' objective functions are
generally convex (could be nondifferentiable) and per agent local convex
constraints are allowed; We then propose a gradient-based algorithm for solving
the resource allocation problem when per agent local constraints are absent and
show that such scheme can achieve geometric rate when the objective functions
are strongly convex and have Lipschitz continuous gradients. We have also
provided scalability/network dependency analysis. Based on these two
algorithms, we have further proposed a gradient projection-based algorithm
which can handle smooth objective and simple constraints more efficiently.
Numerical experiments demonstrates the viability and performance of all the
proposed algorithms.
",1,0,1,0,0,0
20790,Sensory Metrics of Neuromechanical Trust,"  Today digital sources supply an unprecedented component of human sensorimotor
data, the consumption of which is correlated with poorly understood maladies
such as Internet Addiction Disorder and Internet Gaming Disorder. This paper
offers a mathematical understanding of human sensorimotor processing as
multiscale, continuous-time vibratory interaction. We quantify human
informational needs using the signal processing metrics of entropy, noise,
dimensionality, continuity, latency, and bandwidth. Using these metrics, we
define the trust humans experience as a primitive statistical algorithm
processing finely grained sensorimotor data from neuromechanical interaction.
This definition of neuromechanical trust implies that artificial sensorimotor
inputs and interactions that attract low-level attention through frequent
discontinuities and enhanced coherence will decalibrate a brain's
representation of its world over the long term by violating the implicit
statistical contract for which self-calibration evolved. This approach allows
us to model addiction in general as the result of homeostatic regulation gone
awry in novel environments and digital dependency as a sub-case in which the
decalibration caused by digital sensorimotor data spurs yet more consumption of
them. We predict that institutions can use these sensorimotor metrics to
quantify media richness to improve employee well-being; that dyads and
family-size groups will bond and heal best through low-latency, high-resolution
multisensory interaction such as shared meals and reciprocated touch; and that
individuals can improve sensory and sociosensory resolution through deliberate
sensory reintegration practices. We conclude that we humans are the victims of
our own success, our hands so skilled they fill the world with captivating
things, our eyes so innocent they follow eagerly.
",0,1,0,0,0,0
20791,Quantum algorithms for training Gaussian Processes,"  Gaussian processes (GPs) are important models in supervised machine learning.
Training in Gaussian processes refers to selecting the covariance functions and
the associated parameters in order to improve the outcome of predictions, the
core of which amounts to evaluating the logarithm of the marginal likelihood
(LML) of a given model. LML gives a concrete measure of the quality of
prediction that a GP model is expected to achieve. The classical computation of
LML typically carries a polynomial time overhead with respect to the input
size. We propose a quantum algorithm that computes the logarithm of the
determinant of a Hermitian matrix, which runs in logarithmic time for sparse
matrices. This is applied in conjunction with a variant of the quantum linear
system algorithm that allows for logarithmic time computation of the form
$\mathbf{y}^TA^{-1}\mathbf{y}$, where $\mathbf{y}$ is a dense vector and $A$ is
the covariance matrix. We hence show that quantum computing can be used to
estimate the LML of a GP with exponentially improved efficiency under certain
conditions.
",0,0,0,1,0,0
20792,Detecting Oriented Text in Natural Images by Linking Segments,"  Most state-of-the-art text detection methods are specific to horizontal Latin
text and are not fast enough for real-time applications. We introduce Segment
Linking (SegLink), an oriented text detection method. The main idea is to
decompose text into two locally detectable elements, namely segments and links.
A segment is an oriented box covering a part of a word or text line; A link
connects two adjacent segments, indicating that they belong to the same word or
text line. Both elements are detected densely at multiple scales by an
end-to-end trained, fully-convolutional neural network. Final detections are
produced by combining segments connected by links. Compared with previous
methods, SegLink improves along the dimensions of accuracy, speed, and ease of
training. It achieves an f-measure of 75.0% on the standard ICDAR 2015
Incidental (Challenge 4) benchmark, outperforming the previous best by a large
margin. It runs at over 20 FPS on 512x512 images. Moreover, without
modification, SegLink is able to detect long lines of non-Latin text, such as
Chinese.
",1,0,0,0,0,0
20793,Factorizable Module Algebras,"  The aim of this paper is to introduce and study a large class of
$\mathfrak{g}$-module algebras which we call factorizable by generalizing the
Gauss factorization of (square or rectangular) matrices. This class includes
coordinate algebras of corresponding reductive groups $G$, their parabolic
subgroups, basic affine spaces and many others. It turns out that tensor
products of factorizable algebras are also factorizable and it is easy to
create a factorizable algebra out of virtually any $\mathfrak{g}$-module
algebra. We also have quantum versions of all these constructions in the
category of $U_q(\mathfrak{g})$-module algebras. Quite surprisingly, our
quantum factorizable algebras are naturally acted on by the quantized
enveloping algebra $U_q(\mathfrak{g}^*)$ of the dual Lie bialgebra
$\mathfrak{g}^*$ of $\mathfrak{g}$.
",0,0,1,0,0,0
20794,Simultaneous Feature and Body-Part Learning for Real-Time Robot Awareness of Human Behaviors,"  Robot awareness of human actions is an essential research problem in robotics
with many important real-world applications, including human-robot
collaboration and teaming. Over the past few years, depth sensors have become a
standard device widely used by intelligent robots for 3D perception, which can
also offer human skeletal data in 3D space. Several methods based on skeletal
data were designed to enable robot awareness of human actions with satisfactory
accuracy. However, previous methods treated all body parts and features equally
important, without the capability to identify discriminative body parts and
features. In this paper, we propose a novel simultaneous Feature And Body-part
Learning (FABL) approach that simultaneously identifies discriminative body
parts and features, and efficiently integrates all available information
together to enable real-time robot awareness of human behaviors. We formulate
FABL as a regression-like optimization problem with structured
sparsity-inducing norms to model interrelationships of body parts and features.
We also develop an optimization algorithm to solve the formulated problem,
which possesses a theoretical guarantee to find the optimal solution. To
evaluate FABL, three experiments were performed using public benchmark
datasets, including the MSR Action3D and CAD-60 datasets, as well as a Baxter
robot in practical assistive living applications. Experimental results show
that our FABL approach obtains a high recognition accuracy with a processing
speed of the order-of-magnitude of 10e4 Hz, which makes FABL a promising method
to enable real-time robot awareness of human behaviors in practical robotics
applications.
",1,0,0,0,0,0
20795,Off-diagonal estimates of some Bergman-type operators on tube domains over symmetric cones,"  We obtain some necessary and sufficient conditions for the boundedness of a
family of positive operators defined on symmetric cones, we then deduce
off-diagonal boundedness of associated Bergman-type operators in tube domains
over symmetric cones.
",0,0,1,0,0,0
20796,Provenance and Pseudo-Provenance for Seeded Learning-Based Automated Test Generation,"  Many methods for automated software test generation, including some that
explicitly use machine learning (and some that use ML more broadly conceived)
derive new tests from existing tests (often referred to as seeds). Often, the
seed tests from which new tests are derived are manually constructed, or at
least simpler than the tests that are produced as the final outputs of such
test generators. We propose annotation of generated tests with a provenance
(trail) showing how individual generated tests of interest (especially failing
tests) derive from seed tests, and how the population of generated tests
relates to the original seed tests. In some cases, post-processing of generated
tests can invalidate provenance information, in which case we also propose a
method for attempting to construct ""pseudo-provenance"" describing how the tests
could have been (partly) generated from seeds.
",1,0,0,1,0,0
20797,Learning Solving Procedure for Artificial Neural Network,"  It is expected that progress toward true artificial intelligence will be
achieved through the emergence of a system that integrates representation
learning and complex reasoning (LeCun et al. 2015). In response to this
prediction, research has been conducted on implementing the symbolic reasoning
of a von Neumann computer in an artificial neural network (Graves et al. 2016;
Graves et al. 2014; Reed et al. 2015). However, these studies have many
limitations in realizing neural-symbolic integration (Jaeger. 2016). Here, we
present a new learning paradigm: a learning solving procedure (LSP) that learns
the procedure for solving complex problems. This is not accomplished merely by
learning input-output data, but by learning algorithms through a solving
procedure that obtains the output as a sequence of tasks for a given input
problem. The LSP neural network system not only learns simple problems of
addition and multiplication, but also the algorithms of complicated problems,
such as complex arithmetic expression, sorting, and Hanoi Tower. To realize
this, the LSP neural network structure consists of a deep neural network and
long short-term memory, which are recursively combined. Through
experimentation, we demonstrate the efficiency and scalability of LSP and its
validity as a mechanism of complex reasoning.
",1,0,0,0,0,0
20798,On primordial black holes from an inflection point,"  Recently, it has been claimed that inflationary models with an inflection
point in the scalar potential can produce a large resonance in the power
spectrum of curvature perturbation. In this paper however we show that the
previous analyses are incorrect. The reason is twofold: firstly, the inflaton
is over-shot from a stage of standard inflation and so deviates from the
slow-roll attractor before reaching the inflection. Secondly, on the (or close
to) the inflection point, the ultra-slow-roll trajectory supersede the
slow-roll one and thus, the slow-roll approximations used in the literature
cannot be used. We then reconsider the model and provide a recipe for how to
produce nevertheless a large peak in the matter power spectrum via fine-tuning
of parameters.
",0,1,0,0,0,0
20799,Dropout as a Low-Rank Regularizer for Matrix Factorization,"  Regularization for matrix factorization (MF) and approximation problems has
been carried out in many different ways. Due to its popularity in deep
learning, dropout has been applied also for this class of problems. Despite its
solid empirical performance, the theoretical properties of dropout as a
regularizer remain quite elusive for this class of problems. In this paper, we
present a theoretical analysis of dropout for MF, where Bernoulli random
variables are used to drop columns of the factors. We demonstrate the
equivalence between dropout and a fully deterministic model for MF in which the
factors are regularized by the sum of the product of squared Euclidean norms of
the columns. Additionally, we inspect the case of a variable sized
factorization and we prove that dropout achieves the global minimum of a convex
approximation problem with (squared) nuclear norm regularization. As a result,
we conclude that dropout can be used as a low-rank regularizer with data
dependent singular-value thresholding.
",1,0,0,1,0,0
20800,Introduction to a Temporal Graph Benchmark,"  A temporal graph is a data structure, consisting of nodes and edges in which
the edges are associated with time labels. To analyze the temporal graph, the
first step is to find a proper graph dataset/benchmark. While many temporal
graph datasets exist online, none could be found that used the interval labels
in which each edge is associated with a starting and ending time. Therefore we
create a temporal graph data based on Wikipedia reference graph for temporal
analysis. This report aims to provide more details of this graph benchmark to
those who are interested in using it.
",1,1,0,0,0,0
20801,Orbifold equivalence: structure and new examples,"  Orbifold equivalence is a notion of symmetry that does not rely on group
actions. Among other applications, it leads to surprising connections between
hitherto unrelated singularities. While the concept can be defined in a very
general category-theoretic language, we focus on the most explicit setting in
terms of matrix factorisations, where orbifold equivalences arise from defects
with special properties. Examples are relatively difficult to construct, but we
uncover some structural features that distinguish orbifold equivalences -- most
notably a finite perturbation expansion. We use those properties to devise a
search algorithm, then present some new examples including Arnold
singularities.
",0,0,1,0,0,0
20802,Efficient Attention using a Fixed-Size Memory Representation,"  The standard content-based attention mechanism typically used in
sequence-to-sequence models is computationally expensive as it requires the
comparison of large encoder and decoder states at each time step. In this work,
we propose an alternative attention mechanism based on a fixed size memory
representation that is more efficient. Our technique predicts a compact set of
K attention contexts during encoding and lets the decoder compute an efficient
lookup that does not need to consult the memory. We show that our approach
performs on-par with the standard attention mechanism while yielding inference
speedups of 20% for real-world translation tasks and more for tasks with longer
sequences. By visualizing attention scores we demonstrate that our models learn
distinct, meaningful alignments.
",1,0,0,0,0,0
20803,Multiplicities of bifurcation sets of Pham singularities,"  The local multiplicities of the Maxwell sets in the spaces of versal
deformations of Pham holomorphic function singularities are calculated. A
similar calculation for some other bifurcation sets (generalized Stokes' sets)
defined by more complicated relations between the critical values is given.
Aplications to the complexity of algorithms enumerating topologically distinct
morsifications of complicated real function singularities are discussed.
",0,0,1,0,0,0
20804,Fast and scalable Gaussian process modeling with applications to astronomical time series,"  The growing field of large-scale time domain astronomy requires methods for
probabilistic data analysis that are computationally tractable, even with large
datasets. Gaussian Processes are a popular class of models used for this
purpose but, since the computational cost scales, in general, as the cube of
the number of data points, their application has been limited to small
datasets. In this paper, we present a novel method for Gaussian Process
modeling in one-dimension where the computational requirements scale linearly
with the size of the dataset. We demonstrate the method by applying it to
simulated and real astronomical time series datasets. These demonstrations are
examples of probabilistic inference of stellar rotation periods, asteroseismic
oscillation spectra, and transiting planet parameters. The method exploits
structure in the problem when the covariance function is expressed as a mixture
of complex exponentials, without requiring evenly spaced observations or
uniform noise. This form of covariance arises naturally when the process is a
mixture of stochastically-driven damped harmonic oscillators -- providing a
physical motivation for and interpretation of this choice -- but we also
demonstrate that it can be a useful effective model in some other cases. We
present a mathematical description of the method and compare it to existing
scalable Gaussian Process methods. The method is fast and interpretable, with a
range of potential applications within astronomical data analysis and beyond.
We provide well-tested and documented open-source implementations of this
method in C++, Python, and Julia.
",0,1,0,1,0,0
20805,Toward perfect reads: self-correction of short reads via mapping on de Bruijn graphs,"  Motivations Short-read accuracy is important for downstream analyses such as
genome assembly and hybrid long-read correction. Despite much work on
short-read correction, present-day correctors either do not scale well on large
data sets or consider reads as mere suites of k-mers, without taking into
account their full-length read information. Results We propose a new method to
correct short reads using de Bruijn graphs, and implement it as a tool called
Bcool. As a first st ep, Bcool constructs a compacted de Bruijn graph from the
reads. This graph is filtered on the basis of k-mer abundance then of unitig
abundance, thereby removing from most sequencing errors. The cleaned graph is
then used as a reference on which the reads are mapped to correct them. We show
that this approach yields more accurate reads than k-mer-spectrum correctors
while being scalable to human-size genomic datasets and beyond. Availability
and Implementation The implementation is open source and available at http:
//github.com/Malfoy/BCOOL under the Affero GPL license. Contact Antoine
Limasset antoine.limasset@gmail.com & Jean-François Flot jflot@ulb.ac.be &
Pierre Peterlongo pierre.peterlongo@inria.fr
",1,0,0,0,0,0
20806,Learning Pain from Action Unit Combinations: A Weakly Supervised Approach via Multiple Instance Learning,"  Patient pain can be detected highly reliably from facial expressions using a
set of facial muscle-based action units (AUs) defined by the Facial Action
Coding System (FACS). A key characteristic of facial expression of pain is the
simultaneous occurrence of pain-related AU combinations, whose automated
detection would be highly beneficial for efficient and practical pain
monitoring. Existing general Automated Facial Expression Recognition (AFER)
systems prove inadequate when applied specifically for detecting pain as they
either focus on detecting individual pain-related AUs but not on combinations
or they seek to bypass AU detection by training a binary pain classifier
directly on pain intensity data but are limited by lack of enough labeled data
for satisfactory training. In this paper, we propose a new approach that mimics
the strategy of human coders of decoupling pain detection into two consecutive
tasks: one performed at the individual video-frame level and the other at
video-sequence level. Using state-of-the-art AFER tools to detect single AUs at
the frame level, we propose two novel data structures to encode AU combinations
from single AU scores. Two weakly supervised learning frameworks namely
multiple instance learning (MIL) and multiple clustered instance learning
(MCIL) are employed corresponding to each data structure to learn pain from
video sequences. Experimental results show an 87% pain recognition accuracy
with 0.94 AUC (Area Under Curve) on the UNBC-McMaster Shoulder Pain Expression
dataset. Tests on long videos in a lung cancer patient video dataset
demonstrates the potential value of the proposed system for pain monitoring in
clinical settings.
",1,0,0,1,0,0
20807,A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking Interacting Objects,"  Tracking humans that are interacting with the other subjects or environment
remains unsolved in visual tracking, because the visibility of the human of
interests in videos is unknown and might vary over time. In particular, it is
still difficult for state-of-the-art human trackers to recover complete human
trajectories in crowded scenes with frequent human interactions. In this work,
we consider the visibility status of a subject as a fluent variable, whose
change is mostly attributed to the subject's interaction with the surrounding,
e.g., crossing behind another object, entering a building, or getting into a
vehicle, etc. We introduce a Causal And-Or Graph (C-AOG) to represent the
causal-effect relations between an object's visibility fluent and its
activities, and develop a probabilistic graph model to jointly reason the
visibility fluent change (e.g., from visible to invisible) and track humans in
videos. We formulate this joint task as an iterative search of a feasible
causal graph structure that enables fast search algorithm, e.g., dynamic
programming method. We apply the proposed method on challenging video sequences
to evaluate its capabilities of estimating visibility fluent changes of
subjects and tracking subjects of interests over time. Results with comparisons
demonstrate that our method outperforms the alternative trackers and can
recover complete trajectories of humans in complicated scenarios with frequent
human interactions.
",1,0,0,0,0,0
20808,Exact Affine Counter Automata,"  We introduce an affine generalization of counter automata, and analyze their
ability as well as affine finite automata. Our contributions are as follows. We
show that there is a language that can be recognized by exact realtime affine
counter automata but by neither 1-way deterministic pushdown automata nor
realtime deterministic k-counter automata. We also show that a certain promise
problem, which is conjectured not to be solved by two-way quantum finite
automata in polynomial time, can be solved by Las Vegas affine finite automata.
Lastly, we show that how a counter helps for affine finite automata by showing
that the language MANYTWINS, which is conjectured not to be recognized by
affine, quantum or classical finite state models in polynomial time, can be
recognized by affine counter automata with one-sided bounded-error in realtime.
",1,0,0,0,0,0
20809,Preorder characterizations of lower separation axioms and their applications to foliations and flows,"  In this paper, we characterize several lower separation axioms $C_0, C_D$,
$C_R$, $C_N$, $\lambda$-space, nested, $S_{YS}$, $S_{YY}$, $S_{YS}$, and
$S_{\delta}$ using pre-order. To analyze topological properties of (resp.
dynamical systems) foliations, we introduce notions of topology (resp.
dynamical systems) for foliations. Then proper (resp. compact, minimal,
recurrent) foliations are characterized by separation axioms. Conversely, lower
separation axioms are interpreted into the condition for foliations and several
relations of them are described. Moreover, we introduce some notions for
topologies from dynamical systems and foliation theory.
",0,0,1,0,0,0
20810,Convergence of row sequences of simultaneous Padé-Faber approximants,"  We consider row sequences of vector valued Padé-Faber approximants
(simultaneous Padé-Faber approximants) and prove a Montessus de Ballore
type theorem.
",0,0,1,0,0,0
20811,A Deep Convolutional Neural Network for Background Subtraction,"  In this work, we present a novel background subtraction system that uses a
deep Convolutional Neural Network (CNN) to perform the segmentation. With this
approach, feature engineering and parameter tuning become unnecessary since the
network parameters can be learned from data by training a single CNN that can
handle various video scenes. Additionally, we propose a new approach to
estimate background model from video. For the training of the CNN, we employed
randomly 5 percent video frames and their ground truth segmentations taken from
the Change Detection challenge 2014(CDnet 2014). We also utilized
spatial-median filtering as the post-processing of the network outputs. Our
method is evaluated with different data-sets, and the network outperforms the
existing algorithms with respect to the average ranking over different
evaluation metrics. Furthermore, due to the network architecture, our CNN is
capable of real time processing.
",1,0,0,0,0,0
20812,A second main theorem for holomorphic curve intersecting hypersurfaces,"  In this paper, we establish a second main theorem for holomorphic curve
intersecting hypersurfaces in general position in projective space with level
of truncation. As an application, we reduce the number hypersurfaces in
uniqueness problem for holomorphic curve of authors before.
",0,0,1,0,0,0
20813,Partially hyperbolic diffeomorphisms with one-dimensional neutral center on 3-manifolds,"  We prove that for any partially hyperbolic diffeomorphism with one
dimensional neutral center on a 3-manifold, the center stable and center
unstable foliations are complete; moreover, each leaf of center stable and
center unstable foliations is a cylinder, a M$\ddot{o}$bius band or a plane.
Further properties of the Bonatti-Parwani-Potrie type of partially hyperbolic
diffeomorphisms are studied. Such examples are obtained by composing the time
$m$-map (for $m>0$ large) of a non-transitive Anosov flow $\phi_t$ on an
orientable 3-manifold with Dehn twists along some transverse tori, and the
examples are partially hyperbolic with one-dimensional neutral center. We prove
that the center foliation gives a topologically Anosov flow which is
topologically equivalent to $\phi_t$. We also prove that for the precise
example constructed by Bonatti-Parwani-Potrie, the center stable and center
unstable foliations are robustly complete.
",0,0,1,0,0,0
20814,Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional Neural Network,"  Speech enhancement (SE) aims to reduce noise in speech signals. Most SE
techniques focus on addressing audio information only. In this work, inspired
by multimodal learning, which utilizes data from different modalities, and the
recent success of convolutional neural networks (CNNs) in SE, we propose an
audio-visual deep CNN (AVDCNN) SE model, which incorporates audio and visual
streams into a unified network model. In the proposed AVDCNN SE model, audio
and visual data are first processed using individual CNNs, and then, fused into
a joint network to generate enhanced speech at the output layer. The AVDCNN
model is trained in an end-to-end manner, and parameters are jointly learned
through back-propagation. We evaluate enhanced speech using five objective
criteria. Results show that the AVDCNN yields notably better performance,
compared with an audio-only CNN-based SE model and two conventional SE
approaches, confirming the effectiveness of integrating visual information into
the SE process.
",1,0,0,1,0,0
20815,"Finding structure in the dark: coupled dark energy, weak lensing, and the mildly nonlinear regime","  We reexamine interactions between the dark sectors of cosmology, with a focus
on robust constraints that can be obtained using only mildly nonlinear scales.
While it is well known that couplings between dark matter and dark energy can
be constrained to the percent level when including the full range of scales
probed by future optical surveys, calibrating matter power spectrum emulators
to all possible choices of potentials and couplings requires many
computationally expensive n-body simulations. Here we show that lensing and
clustering of galaxies in combination with the Cosmic Microwave Background
(CMB) is capable of probing the dark sector coupling to the few percent level
for a given class of models, using only linear and quasi-linear Fourier modes.
These scales can, in principle, be described by semi-analytical techniques such
as the effective field theory of large-scale structure.
",0,1,0,0,0,0
20816,Semantic Autoencoder for Zero-Shot Learning,"  Existing zero-shot learning (ZSL) models typically learn a projection
function from a feature space to a semantic embedding space (e.g.~attribute
space). However, such a projection function is only concerned with predicting
the training seen class semantic representation (e.g.~attribute prediction) or
classification. When applied to test data, which in the context of ZSL contains
different (unseen) classes without training data, a ZSL model typically suffers
from the project domain shift problem. In this work, we present a novel
solution to ZSL based on learning a Semantic AutoEncoder (SAE). Taking the
encoder-decoder paradigm, an encoder aims to project a visual feature vector
into the semantic space as in the existing ZSL models. However, the decoder
exerts an additional constraint, that is, the projection/code must be able to
reconstruct the original visual feature. We show that with this additional
reconstruction constraint, the learned projection function from the seen
classes is able to generalise better to the new unseen classes. Importantly,
the encoder and decoder are linear and symmetric which enable us to develop an
extremely efficient learning algorithm. Extensive experiments on six benchmark
datasets demonstrate that the proposed SAE outperforms significantly the
existing ZSL models with the additional benefit of lower computational cost.
Furthermore, when the SAE is applied to supervised clustering problem, it also
beats the state-of-the-art.
",1,0,0,0,0,0
20817,An Information-Theoretic Optimality Principle for Deep Reinforcement Learning,"  We methodologically address the problem of Q-value overestimation in deep
reinforcement learning to handle high-dimensional state spaces efficiently. By
adapting concepts from information theory, we introduce an intrinsic penalty
signal encouraging reduced Q-value estimates. The resultant algorithm
encompasses a wide range of learning outcomes containing deep Q-networks as a
special case. Different learning outcomes can be demonstrated by tuning a
Lagrange multiplier accordingly. We furthermore propose a novel scheduling
scheme for this Lagrange multiplier to ensure efficient and robust learning. In
experiments on Atari, our algorithm outperforms other algorithms (e.g. deep and
double deep Q-networks) in terms of both game-play performance and sample
complexity. These results remain valid under the recently proposed dueling
architecture.
",1,0,0,1,0,0
20818,Noise-synchronizability of opinion dynamics,"  With the analysis of noise-induced synchronization of opinion dynamics with
bounded confidence (BC), a natural and fundamental question is what opinion
structures can be synchronized by noise. In the traditional Hegselmann-Krause
(HK) model, each agent examines the opinion values of all the other ones and
then choose neighbors to update its own opinion according to the BC scheme. In
reality, people are more likely to interchange opinions with only some
individuals, resulting in a predetermined local discourse relationship as
introduced by the DeGroot model. In this paper, we consider an opinion dynamics
that combines the schemes of BC and local discourse topology and investigate
its synchronization induced by noise. The new model endows the heterogeneous HK
model with a time-varying discourse topology. With the proposed definition of
noise-synchronizability, it is shown that the compound noisy model is almost
surely noise-synchronizable if and only if the time-varying discourse graph is
uniformly jointly connected, taking the noise-induced synchronization of the
classical heterogeneous HK model as a special case. As a natural implication,
the result for the first time builds the equivalence between the connectivity
of discourse graph and the beneficial effect of noise for opinion consensus.
",1,0,0,0,0,0
20819,Conformer-selection by matter-wave interference,"  We establish that matter-wave interference at near-resonant ultraviolet
optical gratings can be used to spatially separate individual conformers of
complex molecules. Our calculations show that the conformational purity of the
prepared beam can be close to 100% and that all molecules remain in their
electronic ground state. The proposed technique is independent of the dipole
moment and the spin of the molecule and thus paves the way for
structure-sensitive experiments with hydrocarbons and biomolecules, such as
neurotransmitters and hormones, which evaded conformer-pure isolation so far
",0,1,0,0,0,0
20820,Building a Neural Machine Translation System Using Only Synthetic Parallel Data,"  Recent works have shown that synthetic parallel data automatically generated
by translation models can be effective for various neural machine translation
(NMT) issues. In this study, we build NMT systems using only synthetic parallel
data. As an efficient alternative to real parallel data, we also present a new
type of synthetic parallel corpus. The proposed pseudo parallel data are
distinct from previous works in that ground truth and synthetic examples are
mixed on both sides of sentence pairs. Experiments on Czech-German and
French-German translations demonstrate the efficacy of the proposed pseudo
parallel corpus, which shows not only enhanced results for bidirectional
translation tasks but also substantial improvement with the aid of a ground
truth real parallel corpus.
",1,0,0,0,0,0
20821,Learning to Predict Indoor Illumination from a Single Image,"  We propose an automatic method to infer high dynamic range illumination from
a single, limited field-of-view, low dynamic range photograph of an indoor
scene. In contrast to previous work that relies on specialized image capture,
user input, and/or simple scene models, we train an end-to-end deep neural
network that directly regresses a limited field-of-view photo to HDR
illumination, without strong assumptions on scene geometry, material
properties, or lighting. We show that this can be accomplished in a three step
process: 1) we train a robust lighting classifier to automatically annotate the
location of light sources in a large dataset of LDR environment maps, 2) we use
these annotations to train a deep neural network that predicts the location of
lights in a scene from a single limited field-of-view photo, and 3) we
fine-tune this network using a small dataset of HDR environment maps to predict
light intensities. This allows us to automatically recover high-quality HDR
illumination estimates that significantly outperform previous state-of-the-art
methods. Consequently, using our illumination estimates for applications like
3D object insertion, we can achieve results that are photo-realistic, which is
validated via a perceptual user study.
",1,0,0,1,0,0
20822,$H^\infty$-calculus for semigroup generators on BMO,"  We prove that the negative infinitesimal generator $L$ of a semigroup of
positive contractions on $L^\infty$ has a bounded $H^\infty(S_\eta^0)$-calculus
on BMO$(\sqrt L)$ for any angle $\eta>\pi/2$, provided the semigroup satisfies
Bakry-Emry's $\Gamma_2 $ criterion. Our arguments only rely on the properties
of the underlying semigroup and works well in the noncommutative setting. A key
ingredient of our argument is a quasi monotone property for the subordinated
semigroup $T_{t,\alpha}=e^{-tL^\alpha},0<\alpha<1$, that is proved in the first
half of the article.
",0,0,1,0,0,0
20823,A Bayesian Game without epsilon equilibria,"  We present a three player Bayesian game for which there is no epsilon
equilibria in Borel measurable strategies for small enough epsilon, however
there are non-measurable equilibria.
",1,0,1,0,0,0
20824,Towards Robust Interpretability with Self-Explaining Neural Networks,"  Most recent work on interpretability of complex machine learning models has
focused on estimating $\textit{a posteriori}$ explanations for previously
trained models around specific predictions. $\textit{Self-explaining}$ models
where interpretability plays a key role already during learning have received
much less attention. We propose three desiderata for explanations in general --
explicitness, faithfulness, and stability -- and show that existing methods do
not satisfy them. In response, we design self-explaining models in stages,
progressively generalizing linear classifiers to complex yet architecturally
explicit models. Faithfulness and stability are enforced via regularization
specifically tailored to such models. Experimental results across various
benchmark datasets show that our framework offers a promising direction for
reconciling model complexity and interpretability.
",0,0,0,1,0,0
20825,"Deep Learning Scaling is Predictable, Empirically","  Deep learning (DL) creates impactful advances following a virtuous recipe:
model architecture search, creating large training data sets, and scaling
computation. It is widely believed that growing training sets and models should
improve accuracy and result in better products. As DL application domains grow,
we would like a deeper understanding of the relationships between training set
size, computational scale, and model accuracy improvements to advance the
state-of-the-art.
This paper presents a large scale empirical characterization of
generalization error and model size growth as training sets grow. We introduce
a methodology for this measurement and test four machine learning domains:
machine translation, language modeling, image processing, and speech
recognition. Our empirical results show power-law generalization error scaling
across a breadth of factors, resulting in power-law exponents---the ""steepness""
of the learning curve---yet to be explained by theoretical work. Further, model
improvements only shift the error but do not appear to affect the power-law
exponent. We also show that model size scales sublinearly with data size. These
scaling relationships have significant implications on deep learning research,
practice, and systems. They can assist model debugging, setting accuracy
targets, and decisions about data set growth. They can also guide computing
system design and underscore the importance of continued computational scaling.
",1,0,0,1,0,0
20826,Coupled Self-Organized Hydrodynamics and Stokes models for suspensions of active particles,"  We derive macroscopic dynamics for self-propelled particles in a fluid. The
starting point is a coupled Vicsek-Stokes system. The Vicsek model describes
self-propelled agents interacting through alignment. It provides a
phenomenological description of hydrodynamic interactions between agents at
high density. Stokes equations describe a low Reynolds number fluid. These two
dynamics are coupled by the interaction between the agents and the fluid. The
fluid contributes to rotating the particles through Jeffery's equation.
Particle self-propulsion induces a force dipole on the fluid. After
coarse-graining we obtain a coupled Self-Organised Hydrodynamics (SOH)-Stokes
system. We perform a linear stability analysis for this system which shows that
both pullers and pushers have unstable modes. We conclude by providing
extensions of the Vicsek-Stokes model including short-distance repulsion,
finite particle inertia and finite Reynolds number fluid regime.
",0,1,1,0,0,0
20827,Tunable Spin-Orbit Torques in Cu-Ta Binary Alloy Heterostructures,"  The spin Hall effect (SHE) is found to be strong in heavy transition metals
(HM), such as Ta and W, in their amorphous and/or high resistivity form. In
this work, we show that by employing a Cu-Ta binary alloy as buffer layer in an
amorphous Cu$_{100-x}$Ta$_{x}$-based magnetic heterostructure with
perpendicular magnetic anisotropy (PMA), the SHE-induced damping-like
spin-orbit torque (DL-SOT) efficiency $|\xi_{DL}|$ can be linearly tuned by
adjusting the buffer layer resistivity. Current-induced SOT switching can also
be achieved in these Cu$_{100-x}$Ta$_{x}$-based magnetic heterostructures, and
we find the switching behavior better explained by a SOT-assisted domain wall
propagation picture. Through systematic studies on Cu$_{100-x}$Ta$_{x}$-based
samples with various compositions, we determine the lower bound of spin Hall
conductivity
$|\sigma_{SH}|\approx2.02\times10^{4}[\hbar/2e]\Omega^{-1}\cdot\operatorname{m}^{-1}$
in the Ta-rich regime. Based on the idea of resistivity tuning, we further
demonstrate that $|\xi_{DL}|$ can be enhanced from 0.087 for pure Ta to 0.152
by employing a resistive TaN buffer layer.
",0,1,0,0,0,0
20828,On Properties of Nests: Some Answers and Questions,"  By considering nests on a given space, we explore order-theoretical and
topological properties that are closely related to the structure of a nest. In
particular, we see how subbases given by two dual nests can be an indicator of
how close or far are the properties of the space from the structure of a
linearly ordered space. Having in mind that the term interlocking nest is a key
tool to a general solution of the orderability problem, we give a
characterization of interlocking nest via closed sets in the Alexandroff
topology and via lower sets, respectively. We also characterize bounded subsets
of a given set in terms of nests and, finally, we explore the possibility of
characterizing topological groups via properties of nests. All sections are
followed by a number of open questions, which may give new directions to the
orderability problem.
",0,0,1,0,0,0
20829,Differential Characters of Drinfeld Modules and de Rham Cohomology,"  We introduce differential characters of Drinfeld modules. These are
function-field analogues of Buium's p-adic differential characters of elliptic
curves and of Manin's differential characters of elliptic curves in
differential algebra, both of which have had notable Diophantine applications.
We determine the structure of the group of differential characters. This shows
the existence of a family of interesting differential modular functions on the
moduli of Drinfeld modules. It also leads to a canonical $F$-crystal equipped
with a map to the de Rham cohomology of the Drinfeld module. This $F$-crystal
is of a differential-algebraic nature, and the relation to the classical
cohomological realizations is presently not clear.
",0,0,1,0,0,0
20830,Strong submeasures and several applications,"  A strong submeasure on a compact metric space X is a sub-linear and bounded
operator on the space of continuous functions on X. A strong submeasure is
positive if it is non-decreasing. By Hahn-Banach theorem, a positive strong
submeasure is the supremum of a non-empty collection of measures whose masses
are uniformly bounded from above.
We give several applications of strong submeasures in various diverse topics,
thus illustrate the usefulness of this classical but largely overlooked notion.
The applications include:
- Pullback and pushforward of all measures by meromorphic selfmaps of compact
complex varieties.
- The existence of invariant positive strong submeasures for meromorphic maps
between compact complex varieties, a notion of entropy for such submeasures
(which coincide with the classical ones in good cases) and a version of the
Variation Principle.
- Intersection of every positive closed (1,1) currents on compact Kähler
manifolds. Explicit calculations are given for self-intersection of the current
of integration of some curves $C$ in a compact Kähler surface where the
self-intersection in cohomology is negative.
All of these points are new and have not been previously given in work by
other authors. In addition, we will apply the same ideas to entropy of
transcendental maps of $\mathbb{C}$ and $\mathbb{C}^2$.
",0,0,1,0,0,0
20831,Understanding Career Progression in Baseball Through Machine Learning,"  Professional baseball players are increasingly guaranteed expensive long-term
contracts, with over 70 deals signed in excess of \$90 million, mostly in the
last decade. These are substantial sums compared to a typical franchise
valuation of \$1-2 billion. Hence, the players to whom a team chooses to give
such a contract can have an enormous impact on both competitiveness and profit.
Despite this, most published approaches examining career progression in
baseball are fairly simplistic. We applied four machine learning algorithms to
the problem and soundly improved upon existing approaches, particularly for
batting data.
",1,0,0,1,0,0
20832,Testing the validity of the local and global GKLS master equations on an exactly solvable model,"  When deriving a master equation for a multipartite weakly-interacting open
quantum systems, dissipation is often addressed \textit{locally} on each
component, i.e. ignoring the coherent couplings, which are later added `by
hand'. Although simple, the resulting local master equation (LME) is known to
be thermodynamically inconsistent. Otherwise, one may always obtain a
consistent \textit{global} master equation (GME) by working on the energy basis
of the full interacting Hamiltonian. Here, we consider a two-node `quantum
wire' connected to two heat baths. The stationary solution of the LME and GME
are obtained and benchmarked against the exact result. Importantly, in our
model, the validity of the GME is constrained by the underlying secular
approximation. Whenever this breaks down (for resonant weakly-coupled nodes),
we observe that the LME, in spite of being thermodynamically flawed: (a)
predicts the correct steady state, (b) yields the exact asymptotic heat
currents, and (c) reliably reflects the correlations between the nodes. In
contrast, the GME fails at all three tasks. Nonetheless, as the inter-node
coupling grows, the LME breaks down whilst the GME becomes correct. Hence, the
global and local approach may be viewed as \textit{complementary} tools, best
suited to different parameter regimes.
",0,1,0,0,0,0
20833,Unsupervised Contact Learning for Humanoid Estimation and Control,"  This work presents a method for contact state estimation using fuzzy
clustering to learn contact probability for full, six-dimensional humanoid
contacts. The data required for training is solely from proprioceptive sensors
- endeffector contact wrench sensors and inertial measurement units (IMUs) -
and the method is completely unsupervised. The resulting cluster means are used
to efficiently compute the probability of contact in each of the six
endeffector degrees of freedom (DoFs) independently. This clustering-based
contact probability estimator is validated in a kinematics-based base state
estimator in a simulation environment with realistic added sensor noise for
locomotion over rough, low-friction terrain on which the robot is subject to
foot slip and rotation. The proposed base state estimator which utilizes these
six DoF contact probability estimates is shown to perform considerably better
than that which determines kinematic contact constraints purely based on
measured normal force.
",1,0,0,0,0,0
20834,Learning to Sequence Robot Behaviors for Visual Navigation,"  Recent literature in the robotics community has focused on learning robot
behaviors that abstract out lower-level details of robot control. To fully
leverage the efficacy of such behaviors, it is necessary to select and sequence
them to achieve a given task. In this paper, we present an approach to both
learn and sequence robot behaviors, applied to the problem of visual navigation
of mobile robots. We construct a layered representation of control policies
composed of low- level behaviors and a meta-level policy. The low-level
behaviors enable the robot to locomote in a particular environment while
avoiding obstacles, and the meta-level policy actively selects the low-level
behavior most appropriate for the current situation based purely on visual
feedback. We demonstrate the effectiveness of our method on three simulated
robot navigation tasks: a legged hexapod robot which must successfully traverse
varying terrain, a wheeled robot which must navigate a maze-like course while
avoiding obstacles, and finally a wheeled robot navigating in the presence of
dynamic obstacles. We show that by learning control policies in a layered
manner, we gain the ability to successfully traverse new compound environments
composed of distinct sub-environments, and outperform both the low-level
behaviors in their respective sub-environments, as well as a hand-crafted
selection of low-level policies on these compound environments.
",1,0,0,0,0,0
20835,"Evaluation complexity bounds for smooth constrained nonlinear optimisation using scaled KKT conditions, high-order models and the criticality measure $χ$","  Evaluation complexity for convexly constrained optimization is considered and
it is shown first that the complexity bound of $O(\epsilon^{-3/2})$ proved by
Cartis, Gould and Toint (IMAJNA 32(4) 2012, pp.1662-1695) for computing an
$\epsilon$-approximate first-order critical point can be obtained under
significantly weaker assumptions. Moreover, the result is generalized to the
case where high-order derivatives are used, resulting in a bound of
$O(\epsilon^{-(p+1)/p})$ evaluations whenever derivatives of order $p$ are
available. It is also shown that the bound of
$O(\epsilon_P^{-1/2}\epsilon_D^{-3/2})$ evaluations ($\epsilon_P$ and
$\epsilon_D$ being primal and dual accuracy thresholds) suggested by Cartis,
Gould and Toint (SINUM, 2015) for the general nonconvex case involving both
equality and inequality constraints can be generalized to a bound of
$O(\epsilon_P^{-1/p}\epsilon_D^{-(p+1)/p})$ evaluations under similarly
weakened assumptions. This paper is variant of a companion report (NTR-11-2015,
University of Namur, Belgium) which uses a different first-order criticality
measure to obtain the same complexity bounds.
",1,0,1,0,0,0
20836,One level density of low-lying zeros of quadratic and quartic Hecke $L$-functions,"  In this paper, we prove some one level density results for the low-lying
zeros of famliies of quadratic and quartic Hecke $L$-functions of the Gaussian
field. As corollaries, we deduce that, respectively, at least $94.27 \%$ and
$5\%$ of the members of the quadratic family and the quartic family do not
vanish at the central point.
",0,0,1,0,0,0
20837,An Online Convex Optimization Approach to Dynamic Network Resource Allocation,"  Existing approaches to online convex optimization (OCO) make sequential
one-slot-ahead decisions, which lead to (possibly adversarial) losses that
drive subsequent decision iterates. Their performance is evaluated by the
so-called regret that measures the difference of losses between the online
solution and the best yet fixed overall solution in hindsight. The present
paper deals with online convex optimization involving adversarial loss
functions and adversarial constraints, where the constraints are revealed after
making decisions, and can be tolerable to instantaneous violations but must be
satisfied in the long term. Performance of an online algorithm in this setting
is assessed by: i) the difference of its losses relative to the best dynamic
solution with one-slot-ahead information of the loss function and the
constraint (that is here termed dynamic regret); and, ii) the accumulated
amount of constraint violations (that is here termed dynamic fit). In this
context, a modified online saddle-point (MOSP) scheme is developed, and proved
to simultaneously yield sub-linear dynamic regret and fit, provided that the
accumulated variations of per-slot minimizers and constraints are sub-linearly
growing with time. MOSP is also applied to the dynamic network resource
allocation task, and it is compared with the well-known stochastic dual
gradient method. Under various scenarios, numerical experiments demonstrate the
performance gain of MOSP relative to the state-of-the-art.
",1,0,1,1,0,0
20838,Learning causal Bayes networks using interventional path queries in polynomial time and sample complexity,"  Causal discovery from empirical data is a fundamental problem in many
scientific domains. Observational data allows for identifiability only up to
Markov equivalence class. In this paper we first propose a polynomial time
algorithm for learning the exact correctly-oriented structure of the transitive
reduction of any causal Bayesian networks with high probability, by using
interventional path queries. Each path query takes as input an origin node and
a target node, and answers whether there is a directed path from the origin to
the target. This is done by intervening the origin node and observing samples
from the target node. We theoretically show the logarithmic sample complexity
for the size of interventional data per path query, for continuous and discrete
networks. We further extend our work to learn the transitive edges using
logarithmic sample complexity (albeit in time exponential in the maximum number
of parents for discrete networks). This allows us to learn the full network. We
also provide an analysis of imperfect interventions.
",1,0,0,1,0,0
20839,The Fredholm alternative for the $p$-Laplacian in exterior domains,"  We investigate the Fredholm alternative for the $p$-Laplacian in an exterior
domain which is the complement of the closed unit ball in $\mathbb{R}^N$
($N\geq 2$). By employing techniques of Calculus of Variations we obtain the
multiplicity of solutions. The striking difference between our case and the
entire space case is also discussed.
",0,0,1,0,0,0
20840,Thermodynamic Stabilization of Precipitates through Interface Segregation: Chemical Effects,"  Precipitation hardening, which relies on a high density of intermetallic
precipitates, is a commonly utilized technique for strengthening structural
alloys. Structural alloys are commonly strengthened through a high density of
small size intermetallic precipitates. At high temperatures, however, the
precipitates coarsen to reduce the excess energy of the interface, resulting in
a significant reduction in the strengthening provided by the precipitates. In
certain ternary alloys, the secondary solute segregates to the interface and
results in the formation of a high density of nanosize precipitates that
provide enhanced strength and are resistant to coarsening. To understand the
chemical effects involved, and to identify such systems, we develop a
thermodynamic model using the framework of the regular nanocrystalline solution
model. For various global compositions, temperatures and thermodynamic
parameters, equilibrium configuration of Mg-Sn-Zn alloy is evaluated by
minimizing the Gibbs free energy function with respect to the region-specific
(bulk solid-solution, interface and precipitate) concentrations and sizes. The
results show that Mg$_2$Sn precipitates can be stabilized to nanoscale sizes
through Zn segregation to Mg/Mg$_2$Sn interface, and the precipitates can be
stabilized against coarsening at high-temperatures by providing a larger Zn
concentration in the system. Together with the inclusion of elastic strain
energy effects and the input of computationally informed interface
thermodynamic parameters in the future, the model is expected to provide a more
realistic prediction of segregation and precipitate stabilization in ternary
alloys of structural importance.
",0,1,0,0,0,0
20841,Wavelength Does Not Equal Pressure: Vertical Contribution Functions and their Implications for Mapping Hot Jupiters,"  Multi-band phase variations in principle allow us to infer the longitudinal
temperature distributions of planets as a function of height in their
atmospheres. For example, 3.6 micron emission originates from deeper layers of
the atmosphere than 4.5 micron due to greater water vapor absorption at the
longer wavelength. Since heat transport efficiency increases with pressure, we
expect thermal phase curves at 3.6 micron to exhibit smaller amplitudes and
greater phase offsets than at 4.5 micron; this trend is not observed. Of the
seven hot Jupiters with full-orbit phase curves at 3.6 and 4.5 micron, all have
greater phase amplitude at 3.6 micron than at 4.5 micron, while four of seven
exhibit a greater phase offset at 3.6 micron. We use a 3D
radiative-hydrodynamic model to calculate theoretical phase curves of HD
189733b, assuming thermo-chemical equilibrium. The model exhibits temperature,
pressure, and wavelength dependent opacity, primarily driven by carbon
chemistry: CO is energetically favored on the dayside, while CH4 is favored on
the cooler nightside. Infrared opacity therefore changes by orders of magnitude
between day and night, producing dramatic vertical shifts in the
wavelength-specific photospheres, which would complicate eclipse or phase
mapping with spectral data. The model predicts greater relative phase amplitude
and greater phase offset at 3.6 micron than at 4.5 micron, in agreement with
the data. Our model qualitatively explains the observed phase curves, but is in
tension with current thermo-chemical kinetics models that predict zonally
uniform atmospheric composition due to transport of CO from the hot regions of
the atmosphere.
",0,1,0,0,0,0
20842,Supervised Learning of Labeled Pointcloud Differences via Cover-Tree Entropy Reduction,"  We introduce a new algorithm, called CDER, for supervised machine learning
that merges the multi-scale geometric properties of Cover Trees with the
information-theoretic properties of entropy. CDER applies to a training set of
labeled pointclouds embedded in a common Euclidean space. If typical
pointclouds corresponding to distinct labels tend to differ at any scale in any
sub-region, CDER can identify these differences in (typically) linear time,
creating a set of distributional coordinates which act as a feature extraction
mechanism for supervised learning. We describe theoretical properties and
implementation details of CDER, and illustrate its benefits on several
synthetic examples.
",1,0,0,1,0,0
20843,Design Considerations for Proposed Fermilab Integrable RCS,"  Integrable optics is an innovation in particle accelerator design that
provides strong nonlinear focusing while avoiding parametric resonances. One
promising application of integrable optics is to overcome the traditional
limits on accelerator intensity imposed by betatron tune-spread and collective
instabilities. The efficacy of high-intensity integrable accelerators will be
undergo comprehensive testing over the next several years at the Fermilab
Integrable Optics Test Accelerator (IOTA) and the University of Maryland
Electron Ring (UMER). We propose an integrable Rapid-Cycling Synchrotron (iRCS)
as a replacement for the Fermilab Booster to achieve multi-MW beam power for
the Fermilab high-energy neutrino program. We provide a overview of the machine
parameters and discuss an approach to lattice optimization. Integrable optics
requires arcs with integer-pi phase advance followed by drifts with matched
beta functions. We provide an example integrable lattice with features of a
modern RCS - long dispersion-free drifts, low momentum compaction,
superperiodicity, chromaticity correction, separate-function magnets, and
bounded beta functions.
",0,1,0,0,0,0
20844,Consistent Estimation in General Sublinear Preferential Attachment Trees,"  We propose an empirical estimator of the preferential attachment function $f$
in the setting of general preferential attachment trees. Using a supercritical
continuous-time branching process framework, we prove the almost sure
consistency of the proposed estimator. We perform simulations to study the
empirical properties of our estimators.
",0,0,1,1,0,0
20845,Learned Watershed: End-to-End Learning of Seeded Segmentation,"  Learned boundary maps are known to outperform hand- crafted ones as a basis
for the watershed algorithm. We show, for the first time, how to train
watershed computation jointly with boundary map prediction. The estimator for
the merging priorities is cast as a neural network that is con- volutional
(over space) and recurrent (over iterations). The latter allows learning of
complex shape priors. The method gives the best known seeded segmentation
results on the CREMI segmentation challenge.
",1,0,0,0,0,0
20846,MAGIC Contributions to the 35th International Cosmic Ray Conference (ICRC2017),"  MAGIC (Major Atmospheric Gamma Imaging Cherenkov) is a system of two 17 m
diameter, F/1.03 Imaging Atmospheric Cherenkov Telescopes (IACT). They are
dedicated to the observation of gamma rays from galactic and extragalactic
sources in the very high energy range (VHE, 30 GeV to 100 TeV). This submission
contains links to the proceedings for the 35th International Cosmic Ray
Conference (ICRC2017), held in Bexco, Busan, Korea from the 12th to the 17th of
July, 2017.
",0,1,0,0,0,0
20847,Efficient Hidden Vector Encryptions and Its Applications,"  Predicate encryption is a new paradigm of public key encryption that enables
searches on encrypted data. Using the predicate encryption, we can search
keywords or attributes on encrypted data without decrypting the ciphertexts. In
predicate encryption, a ciphertext is associated with attributes and a token
corresponds to a predicate. The token that corresponds to a predicate $f$ can
decrypt the ciphertext associated with attributes $x$ if and only if $f(x)=1$.
Hidden vector encryption (HVE) is a special kind of predicate encryption. In
this thesis, we consider the efficiency, the generality, and the security of
HVE schemes. The results of this thesis are described as follows.
The first results of this thesis are efficient HVE schemes where the token
consists of just four group elements and the decryption only requires four
bilinear map computations, independent of the number of attributes in the
ciphertext. The construction uses composite order bilinear groups and is
selectively secure under the well-known assumptions. The second results are
efficient HVE schemes that are secure under any kind of pairing types. To
achieve our goals, we proposed a general framework that converts HVE schemes
from composite order bilinear groups to prime order bilinear groups. Using the
framework, we convert the previous HVE schemes from composite order bilinear
groups to prime order bilinear groups. The third results are fully secure HVE
schemes with short tokens. Previous HVE schemes were proven to be secure only
in the selective security model where the capabilities of the adversaries are
severely restricted. Using the dual system encryption techniques, we construct
fully secure HVE schemes with match revealing property in composite order
groups.
",1,0,0,0,0,0
20848,The Galaxy Clustering Crisis in Abundance Matching,"  Galaxy clustering on small scales is significantly under-predicted by
sub-halo abundance matching (SHAM) models that populate (sub-)haloes with
galaxies based on peak halo mass, $M_{\rm peak}$. SHAM models based on the peak
maximum circular velocity, $V_{\rm peak}$, have had much better success. The
primary reason $M_{\rm peak}$ based models fail is the relatively low abundance
of satellite galaxies produced in these models compared to those based on
$V_{\rm peak}$. Despite success in predicting clustering, a simple $V_{\rm
peak}$ based SHAM model results in predictions for galaxy growth that are at
odds with observations. We evaluate three possible remedies that could ""save""
mass-based SHAM: (1) SHAM models require a significant population of ""orphan""
galaxies as a result of artificial disruption/merging of sub-haloes in modern
high resolution dark matter simulations; (2) satellites must grow significantly
after their accretion; and (3) stellar mass is significantly affected by halo
assembly history. No solution is entirely satisfactory. However, regardless of
the particulars, we show that popular SHAM models based on $M_{\rm peak}$
cannot be complete physical models as presented. Either $V_{\rm peak}$ truly is
a better predictor of stellar mass at $z\sim 0$ and it remains to be seen how
the correlation between stellar mass and $V_{\rm peak}$ comes about, or SHAM
models are missing vital component(s) that significantly affect galaxy
clustering.
",0,1,0,0,0,0
20849,Supplying Dark Energy from Scalar Field Dark Matter,"  We consider the hypothesis that dark matter and dark energy consists of
ultra-light self-interacting scalar particles. It is found that the
Klein-Gordon equation with only two free parameters (mass and self-coupling) on
a Schwarzschild background, at the galactic length-scales has the solution
which corresponds to Bose-Einstein condensate, behaving as dark matter, while
the constant solution at supra-galactic scales can explain dark energy.
",0,1,0,0,0,0
20850,GHz-Band Integrated Magnetic Inductors,"  The demand on mobile electronics to continue to shrink in size while increase
in efficiency drives the demand on the internal passive components to do the
same. Power amplifiers require inductors with small form factors, high quality
factors, and high operating frequency in the single-digit GHz range. This work
explores the use of magnetic materials to satisfy the needs of power amplifier
inductor applications. This paper discusses the optimization choices regarding
material selection, device design, and fabrication methodology. The inductors
achieved here present the best performance to date for an integrated magnetic
core inductor at high frequencies with a 1 nH inductance and peak quality
factor of 4 at ~3 GHz. Such compact inductors show potential for efficiently
meeting the need of mobile electronics in the future.
",0,1,0,0,0,0
20851,Acylindrical actions on projection complexes,"  We simplify the construction of projection complexes due to
Bestvina-Bromberg-Fujiwara. To do so, we introduce a sharper version of the
Behrstock inequality, and show that it can always be enforced. Furthermore, we
use the new setup to prove acylindricity results for the action on the
projection complexes. We also treat quasi-trees of metric spaces associated to
projection complexes, and prove an acylindricity criterion in that context as
well.
",0,0,1,0,0,0
20852,Introducing Geometric Algebra to Geometric Computing Software Developers: A Computational Thinking Approach,"  Designing software systems for Geometric Computing applications can be a
challenging task. Software engineers typically use software abstractions to
hide and manage the high complexity of such systems. Without the presence of a
unifying algebraic system to describe geometric models, the use of software
abstractions alone can result in many design and maintenance problems.
Geometric Algebra (GA) can be a universal abstract algebraic language for
software engineering geometric computing applications. Few sources, however,
provide enough information about GA-based software implementations targeting
the software engineering community. In particular, successfully introducing GA
to software engineers requires quite different approaches from introducing GA
to mathematicians or physicists. This article provides a high-level
introduction to the abstract concepts and algebraic representations behind the
elegant GA mathematical structure. The article focuses on the conceptual and
representational abstraction levels behind GA mathematics with sufficient
references for more details. In addition, the article strongly recommends
applying the methods of Computational Thinking in both introducing GA to
software engineers, and in using GA as a mathematical language for developing
Geometric Computing software systems.
",1,0,0,0,0,0
20853,Recovering Nonuniform Planted Partitions via Iterated Projection,"  In the planted partition problem, the $n$ vertices of a random graph are
partitioned into $k$ ""clusters,"" and edges between vertices in the same cluster
and different clusters are included with constant probability $p$ and $q$,
respectively (where $0 \le q < p \le 1$). We give an efficient spectral
algorithm that recovers the clusters with high probability, provided that the
sizes of any two clusters are either very close or separated by $\geq
\Omega(\sqrt n)$. We also discuss a generalization of planted partition in
which the algorithm's input is not a random graph, but a random real symmetric
matrix with independent above-diagonal entries.
Our algorithm is an adaptation of a previous algorithm for the uniform case,
i.e., when all clusters are size $n / k \geq \Omega(\sqrt n)$. The original
algorithm recovers the clusters one by one via iterated projection: it
constructs the orthogonal projection operator onto the dominant $k$-dimensional
eigenspace of the random graph's adjacency matrix, uses it to recover one of
the clusters, then deletes it and recurses on the remaining vertices. We show
herein that a similar algorithm works in the nonuniform case.
",1,0,0,0,0,0
20854,Data-driven Analytics for Business Architectures: Proposed Use of Graph Theory,"  Business Architecture (BA) plays a significant role in helping organizations
understand enterprise structures and processes, and align them with strategic
objectives. However, traditional BAs are represented in fixed structure with
static model elements and fail to dynamically capture business insights based
on internal and external data. To solve this problem, this paper introduces the
graph theory into BAs with aim of building extensible data-driven analytics and
automatically generating business insights. We use IBM's Component Business
Model (CBM) as an example to illustrate various ways in which graph theory can
be leveraged for data-driven analytics, including what and how business
insights can be obtained. Future directions for applying graph theory to
business architecture analytics are discussed.
",0,0,0,1,0,0
20855,Beyond Sparsity: Tree Regularization of Deep Models for Interpretability,"  The lack of interpretability remains a key barrier to the adoption of deep
models in many applications. In this work, we explicitly regularize deep models
so human users might step through the process behind their predictions in
little time. Specifically, we train deep time-series models so their
class-probability predictions have high accuracy while being closely modeled by
decision trees with few nodes. Using intuitive toy examples as well as medical
tasks for treating sepsis and HIV, we demonstrate that this new tree
regularization yields models that are easier for humans to simulate than
simpler L1 or L2 penalties without sacrificing predictive power.
",1,0,0,1,0,0
20856,Phase-type distributions in population genetics,"  Probability modelling for DNA sequence evolution is well established and
provides a rich framework for understanding genetic variation between samples
of individuals from one or more populations. We show that both classical and
more recent models for coalescence (with or without recombination) can be
described in terms of the so-called phase-type theory, where complicated and
tedious calculations are circumvented by the use of matrices. The application
of phase-type theory consists of describing the stochastic model as a Markov
model by appropriately setting up a state space and calculating the
corresponding intensity and reward matrices. Formulae of interest are then
expressed in terms of these aforementioned matrices. We illustrate this by a
few examples calculating the mean, variance and even higher order moments of
the site frequency spectrum in the multiple merger coalescent models, and by
analysing the mean and variance for the number of segregating sites for
multiple samples in the two-locus ancestral recombination graph. We believe
that phase-type theory has great potential as a tool for analysing probability
models in population genetics. The compact matrix notation is useful for
clarification of current models, in particular their formal manipulation
(calculation), but also for further development or extensions.
",0,0,0,1,1,0
20857,Robust Wald-type test in GLM with random design based on minimum density power divergence estimators,"  We consider the problem of robust inference under the important generalized
linear model (GLM) with stochastic covariates. We derive the properties of the
minimum density power divergence estimator of the parameters in GLM with random
design and used this estimator to propose a robust Wald-type test for testing
any general composite null hypothesis about the GLM. The asymptotic and
robustness properties of the proposed test are also examined for the GLM with
random design. Application of the proposed robust inference procedures to the
popular Poisson regression model for analyzing count data is discussed in
detail both theoretically and numerically with some interesting real data
examples.
",0,0,0,1,0,0
20858,Locally Smoothed Neural Networks,"  Convolutional Neural Networks (CNN) and the locally connected layer are
limited in capturing the importance and relations of different local receptive
fields, which are often crucial for tasks such as face verification, visual
question answering, and word sequence prediction. To tackle the issue, we
propose a novel locally smoothed neural network (LSNN) in this paper. The main
idea is to represent the weight matrix of the locally connected layer as the
product of the kernel and the smoother, where the kernel is shared over
different local receptive fields, and the smoother is for determining the
importance and relations of different local receptive fields. Specifically, a
multi-variate Gaussian function is utilized to generate the smoother, for
modeling the location relations among different local receptive fields.
Furthermore, the content information can also be leveraged by setting the mean
and precision of the Gaussian function according to the content. Experiments on
some variant of MNIST clearly show our advantages over CNN and locally
connected layer.
",1,0,0,1,0,0
20859,Asymptotic properties of a componentwise ARH(1) plug-in predictor,"  This paper presents new results on prediction of linear processes in function
spaces. The autoregressive Hilbertian process framework of order one (ARH(1)
process framework) is adopted. A componentwise estimator of the autocorrelation
operator is formulated, from the moment-based estimation of its diagonal
coefficients, with respect to the orthogonal eigenvectors of the
auto-covariance operator, which are assumed to be known. Mean-square
convergence to the theoretical autocorrelation operator, in the space of
Hilbert-Schmidt operators, is proved. Consistency then follows in that space.
For the associated ARH(1) plug-in predictor, mean absolute convergence to the
corresponding conditional expectation, in the considered Hilbert space, is
obtained. Hence, consistency in that space also holds. A simulation study is
undertaken to illustrate the finite-large sample behavior of the formulated
componentwise estimator and predictor. The performance of the presented
approach is compared with alternative approaches in the previous and current
ARH(1) framework literature, including the case of unknown eigenvectors.
",0,0,1,1,0,0
20860,The Effect of Population Control Policies on Societal Fragmentation,"  Population control policies are proposed and in some places employed as a
means towards curbing population growth. This paper is concerned with a
disturbing side-effect of such policies, namely, the potential risk of societal
fragmentation due to changes in the distribution of family sizes. This effect
is illustrated in some simple settings and demonstrated by simulation. In
addition, the dependence of societal fragmentation on family size distribution
is analyzed. In particular, it is shown that under the studied model, any
population control policy that disallows families of 3 or more children incurs
the possible risk of societal fragmentation.
",1,1,0,0,0,0
20861,Optimizing Beam Transport in Rapidly Compressing Beams on the Neutralized Drift Compression Experiment - II,"  The Neutralized Drift Compression Experiment-II (NDCX-II) is an induction
linac that generates intense pulses of 1.2 MeV helium ions for heating matter
to extreme conditions. Here, we present recent results on optimizing beam
transport. The NDCX-II beamline includes a 1-meter-long drift section
downstream of the last transport solenoid, which is filled with
charge-neutralizing plasma that enables rapid longitudinal compression of an
intense ion beam against space-charge forces. The transport section on NDCX-II
consists of 28 solenoids. Finding optimal field settings for a group of
solenoids requires knowledge of the envelope parameters of the beam. Imaging
the beam on scintillator gives the radius of the beam, but the envelope angle
dr/dz is not measured directly. We demonstrate how the parameters of the beam
envelope (r, dr/dz, and emittance) can be reconstructed from a series of images
taken at varying B-field strengths of a solenoid upstream of the scintillator.
We use this technique to evaluate emittance at several points in the NDCX-II
beamline and for optimizing the trajectory of the beam at the entry of the
plasma-filled drift section.
",0,1,0,0,0,0
20862,Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations,"  Many structured prediction problems (particularly in vision and language
domains) are ambiguous, with multiple outputs being correct for an input - e.g.
there are many ways of describing an image, multiple ways of translating a
sentence; however, exhaustively annotating the applicability of all possible
outputs is intractable due to exponentially large output spaces (e.g. all
English sentences). In practice, these problems are cast as multi-class
prediction, with the likelihood of only a sparse set of annotations being
maximized - unfortunately penalizing for placing beliefs on plausible but
unannotated outputs. We make and test the following hypothesis - for a given
input, the annotations of its neighbors may serve as an additional supervisory
signal. Specifically, we propose an objective that transfers supervision from
neighboring examples. We first study the properties of our developed method in
a controlled toy setup before reporting results on multi-label classification
and two image-grounded sequence modeling tasks - captioning and question
generation. We evaluate using standard task-specific metrics and measures of
output diversity, finding consistent improvements over standard maximum
likelihood training and other baselines.
",0,0,0,1,0,0
20863,Direct and indirect seismic inversion: interpretation of certain mathematical theorems,"  Quantitative methods are more familiar to most geophysicists with direct
inversion or indirect inversion. We will discuss seismic inversion in a high
level sense without getting into the actual algorithms. We will stay with
meta-equations and argue pros and cons based on certain mathematical theorems.
",0,1,0,0,0,0
20864,Kan's combinatorial spectra and their sheaves revisited,"  We define a right Cartan-Eilenberg structure on the category of Kan's
combinatorial spectra, and the category of sheaves of such spectra, assuming
some conditions. In both structures, we use the geometric concept of homotopy
equivalence as the strong equivalence. In the case of sheaves, we use local
equivalence as the weak equivalence. This paper is the first step in a
larger-scale program of investigating sheaves of spectra from a geometric
viewpoint.
",0,0,1,0,0,0
20865,Adiabatic Quantum Computing for Binary Clustering,"  Quantum computing for machine learning attracts increasing attention and
recent technological developments suggest that especially adiabatic quantum
computing may soon be of practical interest. In this paper, we therefore
consider this paradigm and discuss how to adopt it to the problem of binary
clustering. Numerical simulations demonstrate the feasibility of our approach
and illustrate how systems of qubits adiabatically evolve towards a solution.
",0,0,0,1,0,0
20866,Similarity Search Over Graphs Using Localized Spectral Analysis,"  This paper provides a new similarity detection algorithm. Given an input set
of multi-dimensional data points, where each data point is assumed to be
multi-dimensional, and an additional reference data point for similarity
finding, the algorithm uses kernel method that embeds the data points into a
low dimensional manifold. Unlike other kernel methods, which consider the
entire data for the embedding, our method selects a specific set of kernel
eigenvectors. The eigenvectors are chosen to separate between the data points
and the reference data point so that similar data points can be easily
identified as being distinct from most of the members in the dataset.
",1,0,0,0,0,0
20867,"Reminiscences of Julian Schwinger: Late Harvard, Early UCLA Years (1968-1981)","  These are reminiscences of my interactions with Julian Schwinger from 1968
through 1981 and beyond.
",0,1,0,0,0,0
20868,Site-resolved imaging of a bosonic Mott insulator using ytterbium atoms,"  We demonstrate site-resolved imaging of a strongly correlated quantum system
without relying on laser-cooling techniques during fluorescence imaging. We
observed the formation of Mott shells in the insulating regime and realized
thermometry on the atomic cloud. This work proves the feasibility of the
noncooled approach and opens the door to extending the detection technology to
new atomic species.
",0,1,0,0,0,0
20869,"A unified continuum and variational multiscale formulation for fluids, solids, and fluid-structure interaction","  We develop a unified continuum modeling framework for viscous fluids and
hyperelastic solids using the Gibbs free energy as the thermodynamic potential.
This framework naturally leads to a pressure primitive variable formulation for
the continuum body, which is well-behaved in both compressible and
incompressible regimes. Our derivation also provides a rational justification
of the isochoric-volumetric additive split of free energies in nonlinear
continuum mechanics. The variational multiscale analysis is performed for the
continuum model to construct a foundation for numerical discretization. We
first consider the continuum body instantiated as a hyperelastic material and
develop a variational multiscale formulation for the hyper-elastodynamic
problem. The generalized-alpha method is applied for temporal discretization. A
segregated algorithm for the nonlinear solver is designed and carefully
analyzed. Second, we apply the new formulation to construct a novel unified
formulation for fluid-solid coupled problems. The variational multiscale
formulation is utilized for spatial discretization in both fluid and solid
subdomains. The generalized-alpha method is applied for the whole continuum
body, and optimal high-frequency dissipation is achieved in both fluid and
solid subproblems. A new predictor multi-corrector algorithm is developed based
on the segregated algorithm to attain a good balance between robustness and
efficiency. The efficacy of the new formulations is examined in several
benchmark problems. The results indicate that the proposed modeling and
numerical methodologies constitute a promising technology for biomedical and
engineering applications, particularly those necessitating incompressible
models.
",0,1,0,0,0,0
20870,Time Assignment System and Its Performance aboard the Hitomi Satellite,"  Fast timing capability in X-ray observation of astrophysical objects is one
of the key properties for the ASTRO-H (Hitomi) mission. Absolute timing
accuracies of 350 micro second or 35 micro second are required to achieve
nominal scientific goals or to study fast variabilities of specific sources.
The satellite carries a GPS receiver to obtain accurate time information, which
is distributed from the central onboard computer through the large and complex
SpaceWire network. The details on the time system on the hardware and software
design are described. In the distribution of the time information, the
propagation delays and jitters affect the timing accuracy. Six other items
identified within the timing system will also contribute to absolute time
error. These error items have been measured and checked on ground to ensure the
time error budgets meet the mission requirements. The overall timing
performance in combination with hardware performance, software algorithm, and
the orbital determination accuracies, etc, under nominal conditions satisfies
the mission requirements of 35 micro second. This work demonstrates key points
for space-use instruments in hardware and software designs and calibration
measurements for fine timing accuracy on the order of microseconds for
mid-sized satellites using the SpaceWire (IEEE1355) network.
",0,1,0,0,0,0
20871,Common fixed points via $λ$-sequences in $G$-metric spaces,"  In this article, we use $\lambda$-sequences to derive common fixed points for
a family of self-mappings defined on a complete $G$-metric space. We imitate
some existing techniques in our proofs and show that the tools emlyed can be
used at a larger scale. These results generalise well known results in the
literature.
",0,0,1,0,0,0
20872,Bidirectional Nested Weighted Automata,"  Nested weighted automata (NWA) present a robust and convenient
automata-theoretic formalism for quantitative specifications. Previous works
have considered NWA that processed input words only in the forward direction.
It is natural to allow the automata to process input words backwards as well,
for example, to measure the maximal or average time between a response and the
preceding request. We therefore introduce and study bidirectional NWA that can
process input words in both directions. First, we show that bidirectional NWA
can express interesting quantitative properties that are not expressible by
forward-only NWA. Second, for the fundamental decision problems of emptiness
and universality, we establish decidability and complexity results for the new
framework which match the best-known results for the special case of
forward-only NWA. Thus, for NWA, the increased expressiveness of
bidirectionality is achieved at no additional computational complexity. This is
in stark contrast to the unweighted case, where bidirectional finite automata
are no more expressive but exponentially more succinct than their forward-only
counterparts.
",1,0,0,0,0,0
20873,Uniform Shapiro-Lopatinski conditions and boundary value problems on manifolds with bounded geometry,"  We study the regularity of the solutions of second order boundary value
problems on manifolds with boundary and bounded geometry. We first show that
the regularity property of a given boundary value problem $(P, C)$ is
equivalent to the uniform regularity of the natural family $(P_x, C_x)$ of
associated boundary value problems in local coordinates. We verify that this
property is satisfied for the Dirichlet boundary conditions and strongly
elliptic operators via a compactness argument. We then introduce a uniform
Shapiro-Lopatinski regularity condition, which is a modification of the
classical one, and we prove that it characterizes the boundary value problems
that satisfy the usual regularity property. We also show that the natural Robin
boundary conditions always satisfy the uniform Shapiro-Lopatinski regularity
condition, provided that our operator satisfies the strong Legendre condition.
This is achieved by proving that ""well-posedness implies regularity"" via a
modification of the classical ""Nirenberg trick"". When combining our regularity
results with the Poincaré inequality of (Ammann-Grosse-Nistor, preprint
2015), one obtains the usual well-posedness results for the classical boundary
value problems in the usual scale of Sobolev spaces, thus extending these
important, well-known theorems from smooth, bounded domains, to manifolds with
boundary and bounded geometry. As we show in several examples, these results do
not hold true anymore if one drops the bounded geometry assumption. We also
introduce a uniform Agmon condition and show that it is equivalent to the
coerciveness. Consequently, we prove a well-posedness result for parabolic
equations whose elliptic generator satisfies the uniform Agmon condition.
",0,0,1,0,0,0
20874,A Fourier-Chebyshev Spectral Method for Cavitation Computation in Nonlinear Elasticity,"  A Fourier-Chebyshev spectral method is proposed in this paper for solving the
cavitation problem in nonlinear elasticity. The interpolation error for the
cavitation solution is analyzed, the elastic energy error estimate for the
discrete cavitation solution is obtained, and the convergence of the method is
proved. An algorithm combined a gradient type method with a damped quasi-Newton
method is applied to solve the discretized nonlinear equilibrium equations.
Numerical experiments show that the Fourier-Chebyshev spectral method is
efficient and capable of producing accurate numerical cavitation solutions.
",0,0,1,0,0,0
20875,Learning Criticality in an Embodied Boltzmann Machine,"  Many biological and cognitive systems do not operate deep into one or other
regime of activity. Instead, they exploit critical surfaces poised at
transitions in their parameter space. The pervasiveness of criticality in
natural systems suggests that there may be general principles inducing this
behaviour. However, there is a lack of conceptual models explaining how
embodied agents propel themselves towards these critical points. In this paper,
we present a learning model driving an embodied Boltzmann Machine towards
critical behaviour by maximizing the heat capacity of the network. We test and
corroborate the model implementing an embodied agent in the mountain car
benchmark, controlled by a Boltzmann Machine that adjust its weights according
to the model. We find that the neural controller reaches a point of
criticality, which coincides with a transition point of the behaviour of the
agent between two regimes of behaviour, maximizing the synergistic information
between its sensors and the hidden and motor neurons. Finally, we discuss the
potential of our learning model to study the contribution of criticality to the
behaviour of embodied living systems in scenarios not necessarily constrained
by biological restrictions of the examples of criticality we find in nature.
",1,1,0,0,0,0
20876,A contemporary look at Hermann Hankel's 1861 pioneering work on Lagrangian fluid dynamics,"  The present paper is a companion to the paper by Villone and Rampf (2017),
titled ""Hermann Hankel's On the general theory of motion of fluids, an essay
including an English translation of the complete Preisschrift from 1861""
together with connected documents. Here we give a critical assessment of
Hankel's work, which covers many important aspects of fluid dynamics considered
from a Lagrangian-coordinates point of view: variational formulation in the
spirit of Hamilton for elastic (barotropic) fluids, transport (we would now say
Lie transport) of vorticity, the Lagrangian significance of Clebsch variables,
etc. Hankel's work is also put in the perspective of previous and future work.
Hence, the action spans about two centuries: from Lagrange's 1760-1761 Turin
paper on variational approaches to mechanics and fluid mechanics problems to
Arnold's 1966 founding paper on the geometrical/variational formulation of
incompressible flow. The 22-year old Hankel - who was to die 12 years later -
emerges as a highly innovative master of mathematical fluid dynamics, fully
deserving Riemann's assessment that his Preisschrift contains ""all manner of
good things.""
",0,1,1,0,0,0
20877,A Dynamic Edge Exchangeable Model for Sparse Temporal Networks,"  We propose a dynamic edge exchangeable network model that can capture sparse
connections observed in real temporal networks, in contrast to existing models
which are dense. The model achieved superior link prediction accuracy on
multiple data sets when compared to a dynamic variant of the blockmodel, and is
able to extract interpretable time-varying community structures from the data.
In addition to sparsity, the model accounts for the effect of social influence
on vertices' future behaviours. Compared to the dynamic blockmodels, our model
has a smaller latent space. The compact latent space requires a smaller number
of parameters to be estimated in variational inference and results in a
computationally friendly inference algorithm.
",0,0,0,1,0,0
20878,Current-mode Memristor Crossbars for Neuromemristive Systems,"  Motivated by advantages of current-mode design, this brief contribution
explores the implementation of weight matrices in neuromemristive systems via
current-mode memristor crossbar circuits. After deriving theoretical results
for the range and distribution of weights in the current-mode design, it is
shown that any weight matrix based on voltage-mode crossbars can be mapped to a
current-mode crossbar if the voltage-mode weights are carefully bounded. Then,
a modified gradient descent rule is derived for the current-mode design that
can be used to perform backpropagation training. Behavioral simulations on the
MNIST dataset indicate that both voltage and current-mode designs are able to
achieve similar accuracy and have similar defect tolerance. However, analysis
of trained weight distributions reveals that current-mode and voltage-mode
designs may use different feature representations.
",1,0,0,1,0,0
20879,Incomplete Gauss sums modulo primes,"  We obtain a new bound for incomplete Gauss sums modulo primes. Our argument
falls under the framework of Vinogradov's method which we use to reduce the
problem under consideration to bounding the number of solutions to two distinct
systems of congruences. The first is related to Vinogradov's mean value
theorem, although the second does not appear to have been considered before.
Our bound improves on current results in the range $N\ge
q^{2k^{-1/2}+O(k^{-3/2})}$.
",0,0,1,0,0,0
20880,FAST Adaptive Smoothing and Thresholding for Improved Activation Detection in Low-Signal fMRI,"  Functional Magnetic Resonance Imaging is a noninvasive tool used to study
brain function. Detecting activation is challenged by many factors, and even
more so in low-signal scenarios that arise in the performance of high-level
cognitive tasks. We provide a fully automated and fast adaptive smoothing and
thresholding (FAST) algorithm that uses smoothing and extreme value theory on
correlated statistical parametric maps for thresholding. Performance on
experiments spanning a range of low-signal settings is very encouraging. The
methodology also performs well in a study to identify the cerebral regions that
perceive only-auditory-reliable and only-visual-reliable speech stimuli as well
as those that perceive one but not the other.
",0,0,1,1,0,0
20881,Improper multiferroicity and colossal dielectric constants in Bi$_{2}$CuO$_{4}$,"  The layered cuprate Bi$_{2}$CuO$_{4}$ is investigated using magnetic,
dielectric and pyroelectric measurements. This system is observed to be an
improper multiferroic, with a robust ferroelectric state being established near
the magnetic transition. Magnetic and dielectric measurements indicate the
presence of a region above the antiferromagnetic Neel temperature with
concomitant polar and magnetic short range order. Bi$_{2}$CuO$_{4}$ is also
seen to exhibit colossal dielectric constants at higher temperatures with
clearly distinguishable grain and grain boundary contributions, both of which
exhibit non-Debye relaxation.
",0,1,0,0,0,0
20882,Suppression of plasma echoes and Landau damping in Sobolev spaces by weak collisions in a Vlasov-Fokker-Planck equation,"  In this paper, we study Landau damping in the weakly collisional limit of a
Vlasov-Fokker-Planck equation with nonlinear collisions in the phase-space
$(x,v) \in \mathbb T_x^n \times \mathbb R^n_v$. The goal is four-fold: (A) to
understand how collisions suppress plasma echoes and enable Landau damping in
agreement with linearized theory in Sobolev spaces, (B) to understand how phase
mixing accelerates collisional relaxation, (C) to understand better how the
plasma returns to global equilibrium during Landau damping, and (D) to rule out
that collision-driven nonlinear instabilities dominate. We give an estimate for
the scaling law between Knudsen number and the maximal size of the perturbation
necessary for linear theory to be accurate in Sobolev regularity. We conjecture
this scaling to be sharp (up to logarithmic corrections) due to potential
nonlinear echoes in the collisionless model.
",0,0,1,0,0,0
20883,Deep Learning for Semantic Segmentation on Minimal Hardware,"  Deep learning has revolutionised many fields, but it is still challenging to
transfer its success to small mobile robots with minimal hardware.
Specifically, some work has been done to this effect in the RoboCup humanoid
football domain, but results that are performant and efficient and still
generally applicable outside of this domain are lacking. We propose an approach
conceptually different from those taken previously. It is based on semantic
segmentation and does achieve these desired properties. In detail, it is being
able to process full VGA images in real-time on a low-power mobile processor.
It can further handle multiple image dimensions without retraining, it does not
require specific domain knowledge for achieving a high frame rate and it is
applicable on a minimal mobile hardware.
",1,0,0,1,0,0
20884,"Overpartition $M2$-rank differences, class number relations, and vector-valued mock Eisenstein series","  We prove that the generating function of overpartition $M2$-rank differences
is, up to coefficient signs, a component of the vector-valued mock Eisenstein
series attached to a certain quadratic form. We use this to compute analogs of
the class number relations for $M2$-rank differences. As applications we split
the Kronecker-Hurwitz relation into its ""even"" and ""odd"" parts and calculate
sums over Hurwitz class numbers of the form $\sum_{r \in \mathbb{Z}} H(n -
2r^2)$.
",0,0,1,0,0,0
20885,Communication-Efficient and Decentralized Multi-Task Boosting while Learning the Collaboration Graph,"  We study the decentralized machine learning scenario where many users
collaborate to learn personalized models based on (i) their local datasets and
(ii) a similarity graph over the users' learning tasks. Our approach trains
nonlinear classifiers in a multi-task boosting manner without exchanging
personal data and with low communication costs. When background knowledge about
task similarities is not available, we propose to jointly learn the
personalized models and a sparse collaboration graph through an alternating
optimization procedure. We analyze the convergence rate, memory consumption and
communication complexity of our decentralized algorithms, and demonstrate the
benefits of our approach compared to competing techniques on synthetic and real
datasets.
",1,0,0,1,0,0
20886,On the well-posedness of SPDEs with singular drift in divergence form,"  We prove existence and uniqueness of strong solutions for a class of
second-order stochastic PDEs with multiplicative Wiener noise and drift of the
form $\operatorname{div} \gamma(\nabla \cdot)$, where $\gamma$ is a maximal
monotone graph in $\mathbb{R}^n \times \mathbb{R}^n$ obtained as the
subdifferential of a convex function satisfying very mild assumptions on its
behavior at infinity. The well-posedness result complements the corresponding
one in our recent work arXiv:1612.08260 where, under the additional assumption
that $\gamma$ is single-valued, a solution with better integrability and
regularity properties is constructed. The proof given here, however, is
self-contained.
",0,0,1,0,0,0
20887,Trace norm regularization and faster inference for embedded speech recognition RNNs,"  We propose and evaluate new techniques for compressing and speeding up dense
matrix multiplications as found in the fully connected and recurrent layers of
neural networks for embedded large vocabulary continuous speech recognition
(LVCSR). For compression, we introduce and study a trace norm regularization
technique for training low rank factored versions of matrix multiplications.
Compared to standard low rank training, we show that our method leads to good
accuracy versus number of parameter trade-offs and can be used to speed up
training of large models. For speedup, we enable faster inference on ARM
processors through new open sourced kernels optimized for small batch sizes,
resulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond
LVCSR, we expect our techniques and kernels to be more generally applicable to
embedded neural networks with large fully connected or recurrent layers.
",1,0,0,1,0,0
20888,Scalable and Robust Sparse Subspace Clustering Using Randomized Clustering and Multilayer Graphs,"  Sparse subspace clustering (SSC) is one of the current state-of-the-art
methods for partitioning data points into the union of subspaces, with strong
theoretical guarantees. However, it is not practical for large data sets as it
requires solving a LASSO problem for each data point, where the number of
variables in each LASSO problem is the number of data points. To improve the
scalability of SSC, we propose to select a few sets of anchor points using a
randomized hierarchical clustering method, and, for each set of anchor points,
solve the LASSO problems for each data point allowing only anchor points to
have a non-zero weight (this reduces drastically the number of variables). This
generates a multilayer graph where each layer corresponds to a different set of
anchor points. Using the Grassmann manifold of orthogonal matrices, the shared
connectivity among the layers is summarized within a single subspace. Finally,
we use $k$-means clustering within that subspace to cluster the data points,
similarly as done by spectral clustering in SSC. We show on both synthetic and
real-world data sets that the proposed method not only allows SSC to scale to
large-scale data sets, but that it is also much more robust as it performs
significantly better on noisy data and on data with close susbspaces and
outliers, while it is not prone to oversegmentation.
",0,0,0,1,0,0
20889,Deep Health Care Text Classification,"  Health related social media mining is a valuable apparatus for the early
recognition of the diverse antagonistic medicinal conditions. Mostly, the
existing methods are based on machine learning with knowledge-based learning.
This working note presents the Recurrent neural network (RNN) and Long
short-term memory (LSTM) based embedding for automatic health text
classification in the social media mining. For each task, two systems are built
and that classify the tweet at the tweet level. RNN and LSTM are used for
extracting features and non-linear activation function at the last layer
facilitates to distinguish the tweets of different categories. The experiments
are conducted on 2nd Social Media Mining for Health Applications Shared Task at
AMIA 2017. The experiment results are considerable; however the proposed method
is appropriate for the health text classification. This is primarily due to the
reason that, it doesn't rely on any feature engineering mechanisms.
",1,0,0,0,0,0
20890,"Study of cost functionals for ptychographic phase retrieval to improve the robustness against noise, and a proposal for another noise-robust ptychographic phase retrieval scheme","  Recently, efforts have been made to improve ptychography phase retrieval
algorithms so that they are more robust against noise. Often the algorithm is
adapted by changing the cost functional that needs to be minimized. In
particular, it has been suggested that the cost functional should be obtained
using a maximum-likelihood approach that takes the noise statistics into
account. Here, we consider the different choices of cost functional, and to how
they affect the reconstruction results. We find that seemingly the only
consistently reliable way to improve reconstruction results in the presence of
noise is to reduce the step size of the update function. In addition, a
noise-robust ptychographic reconstruction method has been proposed that relies
on adapting the intensity constraints
",1,1,0,0,0,0
20891,Predicting Native Language from Gaze,"  A fundamental question in language learning concerns the role of a speaker's
first language in second language acquisition. We present a novel methodology
for studying this question: analysis of eye-movement patterns in second
language reading of free-form text. Using this methodology, we demonstrate for
the first time that the native language of English learners can be predicted
from their gaze fixations when reading English. We provide analysis of
classifier uncertainty and learned features, which indicates that differences
in English reading are likely to be rooted in linguistic divergences across
native languages. The presented framework complements production studies and
offers new ground for advancing research on multilingualism.
",1,0,0,0,0,0
20892,A form of Schwarz's lemma and a bound for the Kobayashi metric on convex domains,"  We present a form of Schwarz's lemma for holomorphic maps between convex
domains $D_1$ and $D_2$. This result provides a lower bound on the distance
between the images of relatively compact subsets of $D_1$ and the boundary of
$D_2$. This is a natural improvement of an old estimate by Bernal-González
that takes into account the geometry of $\partial{D_1}$. We also provide a new
estimate for the Kobayashi metric on bounded convex domains.
",0,0,1,0,0,0
20893,The COM-negative binomial distribution: modeling overdispersion and ultrahigh zero-inflated count data,"  In this paper, we focus on the COM-type negative binomial distribution with
three parameters, which belongs to COM-type $(a,b,0)$ class distributions and
family of equilibrium distributions of arbitrary birth-death process. Besides,
we show abundant distributional properties such as overdispersion and
underdispersion, log-concavity, log-convexity (infinite divisibility), pseudo
compound Poisson, stochastic ordering and asymptotic approximation. Some
characterizations including sum of equicorrelated geometrically distributed
random variables, conditional distribution, limit distribution of COM-negative
hypergeometric distribution, and Stein's identity are given for theoretical
properties. COM-negative binomial distribution was applied to overdispersion
and ultrahigh zero-inflated data sets. With the aid of ratio regression, we
employ maximum likelihood method to estimate the parameters and the
goodness-of-fit are evaluated by the discrete Kolmogorov-Smirnov test.
",0,0,1,1,0,0
20894,Efficient Contextual Bandits in Non-stationary Worlds,"  Most contextual bandit algorithms minimize regret against the best fixed
policy, a questionable benchmark for non-stationary environments that are
ubiquitous in applications. In this work, we develop several efficient
contextual bandit algorithms for non-stationary environments by equipping
existing methods for i.i.d. problems with sophisticated statistical tests so as
to dynamically adapt to a change in distribution.
We analyze various standard notions of regret suited to non-stationary
environments for these algorithms, including interval regret, switching regret,
and dynamic regret. When competing with the best policy at each time, one of
our algorithms achieves regret $\mathcal{O}(\sqrt{ST})$ if there are $T$ rounds
with $S$ stationary periods, or more generally
$\mathcal{O}(\Delta^{1/3}T^{2/3})$ where $\Delta$ is some non-stationarity
measure. These results almost match the optimal guarantees achieved by an
inefficient baseline that is a variant of the classic Exp4 algorithm. The
dynamic regret result is also the first one for efficient and fully adversarial
contextual bandit.
Furthermore, while the results above require tuning a parameter based on the
unknown quantity $S$ or $\Delta$, we also develop a parameter free algorithm
achieving regret $\min\{S^{1/4}T^{3/4}, \Delta^{1/5}T^{4/5}\}$. This improves
and generalizes the best existing result $\Delta^{0.18}T^{0.82}$ by Karnin and
Anava (2016) which only holds for the two-armed bandit problem.
",1,0,0,1,0,0
20895,Search Engine Drives the Evolution of Social Networks,"  The search engine is tightly coupled with social networks and is primarily
designed for users to acquire interested information. Specifically, the search
engine assists the information dissemination for social networks, i.e.,
enabling users to access interested contents with keywords-searching and
promoting the process of contents-transferring from the source users directly
to potential interested users. Accompanying such processes, the social network
evolves as new links emerge between users with common interests. However, there
is no clear understanding of such a ""chicken-and-egg"" problem, namely, new
links encourage more social interactions, and vice versa. In this paper, we aim
to quantitatively characterize the social network evolution phenomenon driven
by a search engine. First, we propose a search network model for social network
evolution. Second, we adopt two performance metrics, namely, degree
distribution and network diameter. Theoretically, we prove that the degree
distribution follows an intensified power-law, and the network diameter
shrinks. Third, we quantitatively show that the search engine accelerates the
rumor propagation in social networks. Finally, based on four real-world data
sets (i.e., CDBLP, Facebook, Weibo Tweets, P2P), we verify our theoretical
findings. Furthermore, we find that the search engine dramatically increases
the speed of rumor propagation.
",1,1,0,0,0,0
20896,End-to-End Learning of Semantic Grasping,"  We consider the task of semantic robotic grasping, in which a robot picks up
an object of a user-specified class using only monocular images. Inspired by
the two-stream hypothesis of visual reasoning, we present a semantic grasping
framework that learns object detection, classification, and grasp planning in
an end-to-end fashion. A ""ventral stream"" recognizes object class while a
""dorsal stream"" simultaneously interprets the geometric relationships necessary
to execute successful grasps. We leverage the autonomous data collection
capabilities of robots to obtain a large self-supervised dataset for training
the dorsal stream, and use semi-supervised label propagation to train the
ventral stream with only a modest amount of human supervision. We
experimentally show that our approach improves upon grasping systems whose
components are not learned end-to-end, including a baseline method that uses
bounding box detection. Furthermore, we show that jointly training our model
with auxiliary data consisting of non-semantic grasping data, as well as
semantically labeled images without grasp actions, has the potential to
substantially improve semantic grasping performance.
",1,0,0,1,0,0
20897,Von Neumann Regular Cellular Automata,"  For any group $G$ and any set $A$, a cellular automaton (CA) is a
transformation of the configuration space $A^G$ defined via a finite memory set
and a local function. Let $\text{CA}(G;A)$ be the monoid of all CA over $A^G$.
In this paper, we investigate a generalisation of the inverse of a CA from the
semigroup-theoretic perspective. An element $\tau \in \text{CA}(G;A)$ is von
Neumann regular (or simply regular) if there exists $\sigma \in \text{CA}(G;A)$
such that $\tau \circ \sigma \circ \tau = \tau$ and $\sigma \circ \tau \circ
\sigma = \sigma$, where $\circ$ is the composition of functions. Such an
element $\sigma$ is called a generalised inverse of $\tau$. The monoid
$\text{CA}(G;A)$ itself is regular if all its elements are regular. We
establish that $\text{CA}(G;A)$ is regular if and only if $\vert G \vert = 1$
or $\vert A \vert = 1$, and we characterise all regular elements in
$\text{CA}(G;A)$ when $G$ and $A$ are both finite. Furthermore, we study
regular linear CA when $A= V$ is a vector space over a field $\mathbb{F}$; in
particular, we show that every regular linear CA is invertible when $G$ is
torsion-free elementary amenable (e.g. when $G=\mathbb{Z}^d, \ d \in
\mathbb{N}$) and $V=\mathbb{F}$, and that every linear CA is regular when $V$
is finite-dimensional and $G$ is locally finite with $\text{Char}(\mathbb{F})
\nmid o(g)$ for all $g \in G$.
",1,0,1,0,0,0
20898,A Distance Between Filtered Spaces Via Tripods,"  We present a simplified treatment of stability of filtrations on finite
spaces. Interestingly, we can lift the stability result for combinatorial
filtrations from [CSEM06] to the case when two filtrations live on different
spaces without directly invoking the concept of interleaving. We then prove
that this distance is intrinsic by constructing explicit geodesics between any
pair of filtered spaces. Finally we use this construction to obtain a
strengthening of the stability result.
",1,0,1,0,0,0
20899,Robust Shape Estimation for 3D Deformable Object Manipulation,"  Existing shape estimation methods for deformable object manipulation suffer
from the drawbacks of being off-line, model dependent, noise-sensitive or
occlusion-sensitive, and thus are not appropriate for manipulation tasks
requiring high precision. In this paper, we present a real-time shape
estimation approach for autonomous robotic manipulation of 3D deformable
objects. Our method fulfills all the requirements necessary for the
high-quality deformable object manipulation in terms of being real-time,
model-free and robust to noise and occlusion. These advantages are accomplished
using a joint tracking and reconstruction framework, in which we track the
object deformation by aligning a reference shape model with the stream input
from the RGB-D camera, and simultaneously upgrade the reference shape model
according to the newly captured RGB-D data. We have evaluated the quality and
robustness of our real-time shape estimation pipeline on a set of deformable
manipulation tasks implemented on physical robots. Videos are available at
this https URL
",1,0,0,0,0,0
20900,Beyond Winning and Losing: Modeling Human Motivations and Behaviors Using Inverse Reinforcement Learning,"  In recent years, reinforcement learning (RL) methods have been applied to
model gameplay with great success, achieving super-human performance in various
environments, such as Atari, Go, and Poker. However, those studies mostly focus
on winning the game and have largely ignored the rich and complex human
motivations, which are essential for understanding different players' diverse
behaviors. In this paper, we present a novel method called Multi-Motivation
Behavior Modeling (MMBM) that takes the multifaceted human motivations into
consideration and models the underlying value structure of the players using
inverse RL. Our approach does not require the access to the dynamic of the
system, making it feasible to model complex interactive environments such as
massively multiplayer online games. MMBM is tested on the World of Warcraft
Avatar History dataset, which recorded over 70,000 users' gameplay spanning
three years period. Our model reveals the significant difference of value
structures among different player groups. Using the results of motivation
modeling, we also predict and explain their diverse gameplay behaviors and
provide a quantitative assessment of how the redesign of the game environment
impacts players' behaviors.
",0,0,0,1,0,0
20901,Genetic Algorithms for Mentor-Assisted Evaluation Function Optimization,"  In this paper we demonstrate how genetic algorithms can be used to reverse
engineer an evaluation function's parameters for computer chess. Our results
show that using an appropriate mentor, we can evolve a program that is on par
with top tournament-playing chess programs, outperforming a two-time World
Computer Chess Champion. This performance gain is achieved by evolving a
program with a smaller number of parameters in its evaluation function to mimic
the behavior of a superior mentor which uses a more extensive evaluation
function. In principle, our mentor-assisted approach could be used in a wide
range of problems for which appropriate mentors are available.
",1,0,0,1,0,0
20902,Universal Constraints on the Location of Extrema of Eigenfunctions of Non-Local Schrödinger Operators,"  We derive a lower bound on the location of global extrema of eigenfunctions
for a large class of non-local Schrödinger operators in convex domains under
Dirichlet exterior conditions, featuring the symbol of the kinetic term, the
strength of the potential, and the corresponding eigenvalue, and involving a
new universal constant. We show a number of probabilistic and spectral
geometric implications, and derive a Faber-Krahn type inequality for non-local
operators. Our study also extends to potentials with compact support, and we
establish bounds on the location of extrema relative to the boundary edge of
the support or level sets around minima of the potential.
",0,0,1,0,0,0
20903,InScript: Narrative texts annotated with script information,"  This paper presents the InScript corpus (Narrative Texts Instantiating Script
structure). InScript is a corpus of 1,000 stories centered around 10 different
scenarios. Verbs and noun phrases are annotated with event and participant
types, respectively. Additionally, the text is annotated with coreference
information. The corpus shows rich lexical variation and will serve as a unique
resource for the study of the role of script knowledge in natural language
processing.
",1,0,0,0,0,0
20904,Semimetallic and charge-ordered $α$-(BEDT-TTF)$_2$I$_3$: on the role of disorder in dc transport and dielectric properties,"  $\alpha$-(BEDT-TTF)$_2$I$_3$ is a prominent example of charge ordering among
organic conductors. In this work we explore the details of transport within the
charge-ordered as well as semimetallic phase at ambient pressure. In the
high-temperature semimetallic phase, the mobilities and concentrations of both
electrons and holes conspire in such a way to create an almost
temperature-independent conductivity as well as a low Hall effect. We explain
these phenomena as a consequence of a predominantly inter-pocket scattering
which equalizes mobilities of the two types of charge carriers. At low
temperatures, within the insulating charge-ordered phase two channels of
conduction can be discerned: a temperature-dependent activation which follows
the mean-field behavior, and a nearest-neighbor hopping contribution. Together
with negative magnetoresistance, the latter relies on the presence of disorder.
The charge-ordered phase also features a prominent dielectric peak which bears
a similarity to relaxor ferroelectrics. Its dispersion is determined by
free-electron screening and pushed by disorder well below the transition
temperature. The source of this disorder can be found in the anion layers which
randomly perturb BEDT-TTF molecules through hydrogen bonds.
",0,1,0,0,0,0
20905,Robust Photometric Stereo Using Learned Image and Gradient Dictionaries,"  Photometric stereo is a method for estimating the normal vectors of an object
from images of the object under varying lighting conditions. Motivated by
several recent works that extend photometric stereo to more general objects and
lighting conditions, we study a new robust approach to photometric stereo that
utilizes dictionary learning. Specifically, we propose and analyze two
approaches to adaptive dictionary regularization for the photometric stereo
problem. First, we propose an image preprocessing step that utilizes an
adaptive dictionary learning model to remove noise and other non-idealities
from the image dataset before estimating the normal vectors. We also propose an
alternative model where we directly apply the adaptive dictionary
regularization to the normal vectors themselves during estimation. We study the
practical performance of both methods through extensive simulations, which
demonstrate the state-of-the-art performance of both methods in the presence of
noise.
",0,0,0,1,0,0
20906,Toward Low-Flying Autonomous MAV Trail Navigation using Deep Neural Networks for Environmental Awareness,"  We present a micro aerial vehicle (MAV) system, built with inexpensive
off-the-shelf hardware, for autonomously following trails in unstructured,
outdoor environments such as forests. The system introduces a deep neural
network (DNN) called TrailNet for estimating the view orientation and lateral
offset of the MAV with respect to the trail center. The DNN-based controller
achieves stable flight without oscillations by avoiding overconfident behavior
through a loss function that includes both label smoothing and entropy reward.
In addition to the TrailNet DNN, the system also utilizes vision modules for
environmental awareness, including another DNN for object detection and a
visual odometry component for estimating depth for the purpose of low-level
obstacle detection. All vision systems run in real time on board the MAV via a
Jetson TX1. We provide details on the hardware and software used, as well as
implementation details. We present experiments showing the ability of our
system to navigate forest trails more robustly than previous techniques,
including autonomous flights of 1 km.
",1,0,0,0,0,0
20907,Origin of Charge Separation at Organic Photovoltaic Heterojunctions: A Mesoscale Quantum Mechanical View,"  The high efficiency of charge generation within organic photovoltaic blends
apparently contrasts with the strong ""classical"" attraction between newly
formed electron-hole pairs. Several factors have been identified as possible
facilitators of charge dissociation, such as quantum mechanical coherence and
delocalization, structural and energetic disorder, built-in electric fields,
nanoscale intermixing of the donor and acceptor components of the blends. Our
mesoscale quantum-chemical model allows an unbiased assessment of their
relative importance, through excited-state calculations on systems containing
thousands of donor and acceptor sites. The results on several model
heterojunctions confirm that the classical model severely overestimates the
binding energy of the electron-hole pairs, produced by vertical excitation from
the electronic ground state. Using physically sensible parameters for the
individual materials, we find that the quantum mechanical energy difference
between the lowest interfacial charge transfer states and the fully separated
electron and hole is of the order of the thermal energy.
",0,1,0,0,0,0
20908,Spectral Decimation for Families of Self-Similar Symmetric Laplacians on the Sierpinski Gasket,"  We construct a one-parameter family of Laplacians on the Sierpinski Gasket
that are symmetric and self-similar for the 9-map iterated function system
obtained by iterating the standard 3-map iterated function system. Our main
result is the fact that all these Laplacians satisfy a version of spectral
decimation that builds a precise catalog of eigenvalues and eigenfunctions for
any choice of the parameter. We give a number of applications of this spectral
decimation. We also prove analogous results for fractal Laplacians on the unit
Interval, and this yields an analogue of the classical Sturm-Liouville theory
for the eigenfunctions of these one-dimensional Laplacians.
",0,0,1,0,0,0
20909,Identification of multi-object dynamical systems: consistency and Fisher information,"  Learning the model parameters of a multi-object dynamical system from partial
and perturbed observations is a challenging task. Despite recent numerical
advancements in learning these parameters, theoretical guarantees are extremely
scarce. In this article, we study the identifiability of these parameters and
the consistency of the corresponding maximum likelihood estimate (MLE) under
assumptions on the different components of the underlying multi-object system.
In order to understand the impact of the various sources of observation noise
on the ability to learn the model parameters, we study the asymptotic variance
of the MLE through the associated Fisher information matrix. For example, we
show that specific aspects of the multi-target tracking (MTT) problem such as
detection failures and unknown data association lead to a loss of information
which is quantified in special cases of interest.
",0,0,1,1,0,0
20910,Elliptic curves maximal over extensions of finite base fields,"  Given an elliptic curve $E$ over a finite field $\mathbb{F}_q$ we study the
finite extensions $\mathbb{F}_{q^n}$ of $\mathbb{F}_q$ such that the number of
$\mathbb{F}_{q^n}$-rational points on $E$ attains the Hasse upper bound. We
obtain an upper bound on the degree $n$ for $E$ ordinary using an estimate for
linear forms in logarithms, which allows us to compute the pairs of isogeny
classes of such curves and degree $n$ for small $q$. Using a consequence of
Schmidt's Subspace Theorem, we improve the upper bound to $n\leq 11$ for
sufficiently large $q$. We also show that there are infinitely many isogeny
classes of ordinary elliptic curves with $n=3$.
",0,0,1,0,0,0
20911,CURE: Curvature Regularization For Missing Data Recovery,"  Missing data recovery is an important and yet challenging problem in imaging
and data science. Successful models often adopt certain carefully chosen
regularization. Recently, the low dimension manifold model (LDMM) was
introduced by S.Osher et al. and shown effective in image inpainting. They
observed that enforcing low dimensionality on image patch manifold serves as a
good image regularizer. In this paper, we observe that having only the low
dimension manifold regularization is not enough sometimes, and we need
smoothness as well. For that, we introduce a new regularization by combining
the low dimension manifold regularization with a higher order Curvature
Regularization, and we call this new regularization CURE for short. The key
step of solving CURE is to solve a biharmonic equation on a manifold. We
further introduce a weighted version of CURE, called WeCURE, in a similar
manner as the weighted nonlocal Laplacian (WNLL) method. Numerical experiments
for image inpainting and semi-supervised learning show that the proposed CURE
and WeCURE significantly outperform LDMM and WNLL respectively.
",1,0,0,0,0,0
20912,Nonlinear parametric excitation effect induces stability transitions in swimming direction of flexible superparamagnetic microswimmers,"  Microscopic artificial swimmers have recently become highly attractive due to
their promising potential for biomedical applications. The pioneering work of
Dreyfus et al (2005) has demonstrated the motion of a microswimmer with an
undulating chain of superparamagnetic beads, which is actuated by an
oscillating external magnetic field. Interestingly, it has also been
theoretically predicted that the swimming direction of this swimmer will
undergo a $90^\circ$-transition when the magnetic field's oscillations
amplitude is increased above a critical value of $\sqrt{2}$. In this work, we
further investigate this transition both theoretically and experimentally by
using numerical simulations and presenting a novel flexible microswimmer with a
superparamagnetic head. We realize the $90^\circ$-transition in swimming
direction, prove that this effect depends on both frequency and amplitude of
the oscillating magnetic field, and demonstrate the existence of an optimal
amplitude, under which, maximal swimming speed can be achieved. By
asymptotically analyzing the dynamic motion of microswimmer with a minimal
two-link model, we reveal that the stability transitions representing the
changes in the swimming direction are induced by the effect of nonlinear
parametric excitation.
",0,1,0,0,0,0
20913,$L^p$ Mapping Properties for the Cauchy-Riemann Equations on Lipschitz Domains Admitting Subelliptic Estimates,"  We show that on bounded Lipschitz pseudoconvex domains that admit good weight
functions the $\overline{\partial}$-Neumann operators $N_q,
\overline{\partial}^* N_{q}$, and $\overline{\partial} N_{q}$ are bounded on
$L^p$ spaces for some values of $p$ greater than 2.
",0,0,1,0,0,0
20914,Fast dose optimization for rotating shield brachytherapy,"  Purpose: To provide a fast computational method, based on the proximal graph
solver (POGS) - a convex optimization solver using the alternating direction
method of multipliers (ADMM), for calculating an optimal treatment plan in
rotating shield brachytherapy (RSBT). RSBT treatment planning has more degrees
of freedom than conventional high-dose-rate brachytherapy (HDR-BT) due to the
addition of emission direction, and this necessitates a fast optimization
technique to enable clinical usage. // Methods: The multi-helix RSBT (H-RSBT)
delivery technique was considered with five representative cervical cancer
patients. Treatment plans were generated for all patients using the POGS method
and the previously considered commercial solver IBM CPLEX. The rectum, bladder,
sigmoid, high-risk clinical target volume (HR-CTV), and HR-CTV boundary were
the structures considered in our optimization problem, called the asymmetric
dose-volume optimization with smoothness control. Dose calculation resolution
was 1x1x3 mm^3 for all cases. The H-RSBT applicator has 6 helices, with 33.3 mm
of translation along the applicator per helical rotation and 1.7 mm spacing
between dwell positions, yielding 17.5 degree emission angle spacing per 5 mm
along the applicator.// Results: For each patient, HR-CTV D90, HR-CTV D100,
rectum D2cc, sigmoid D2cc, and bladder D2cc matched within 1% for CPLEX and
POGS. Also, we obtained similar EQD2 figures between CPLEX and POGS. POGS was
around 18 times faster than CPLEX. Over all patients, total optimization times
were 32.1-65.4 seconds for CPLEX and 2.1-3.9 seconds for POGS. // Conclusions:
POGS substantially reduced treatment plan optimization time around 18 times for
RSBT with similar HR-CTV D90, OAR D2cc values, and EQD2 figure relative to
CPLEX, which is significant progress toward clinical translation of RSBT. POGS
is also applicable to conventional HDR-BT.
",0,1,1,0,0,0
20915,3D Modeling of Electric Fields in the LUX Detector,"  This work details the development of a three-dimensional (3D) electric field
model for the LUX detector. The detector took data during two periods of
searching for weakly interacting massive particle (WIMP) searches. After the
first period completed, a time-varying non-uniform negative charge developed in
the polytetrafluoroethylene (PTFE) panels that define the radial boundary of
the detector's active volume. This caused electric field variations in the
detector in time, depth and azimuth, generating an electrostatic
radially-inward force on electrons on their way upward to the liquid surface.
To map this behavior, 3D electric field maps of the detector's active volume
were built on a monthly basis. This was done by fitting a model built in COMSOL
Multiphysics to the uniformly distributed calibration data that were collected
on a regular basis. The modeled average PTFE charge density increased over the
course of the exposure from -3.6 to $-5.5~\mu$C/m$^2$. From our studies, we
deduce that the electric field magnitude varied while the mean value of the
field of $\sim200$~V/cm remained constant throughout the exposure. As a result
of this work the varying electric fields and their impact on event
reconstruction and discrimination were successfully modeled.
",0,1,0,0,0,0
20916,Optimal Communication Strategies in Networked Cyber-Physical Systems with Adversarial Elements,"  This paper studies optimal communication and coordination strategies in
cyber-physical systems for both defender and attacker within a game-theoretic
framework. We model the communication network of a cyber-physical system as a
sensor network which involves one single Gaussian source observed by many
sensors, subject to additive independent Gaussian observation noises. The
sensors communicate with the estimator over a coherent Gaussian multiple access
channel. The aim of the receiver is to reconstruct the underlying source with
minimum mean squared error. The scenario of interest here is one where some of
the sensors are captured by the attacker and they act as the adversary
(jammer): they strive to maximize distortion. The receiver (estimator) knows
the captured sensors but still cannot simply ignore them due to the multiple
access channel, i.e., the outputs of all sensors are summed to generate the
estimator input. We show that the ability of transmitter sensors to secretly
agree on a random event, that is ""coordination"", plays a key role in the
analysis...
",1,0,0,0,0,0
20917,First- and Second-Order Models of Recursive Arithmetics,"  We study a quadruple of interrelated subexponential subsystems of arithmetic
WKL$_0^-$, RCA$^-_0$, I$\Delta_0$, and $\Delta$RA$_1$, which complement the
similarly related quadruple WKL$_0$, RCA$_0$, I$\Sigma_1$, and PRA studied by
Simpson, and the quadruple WKL$_0^\ast$, RCA$_0^\ast$, I$\Delta_0$(exp), and
EFA studied by Simpson and Smith. We then explore the space of subexponential
arithmetic theories between I$\Delta_0$ and I$\Delta_0$(exp). We introduce and
study first- and second-order theories of recursive arithmetic $A$RA$_1$ and
$A$RA$_2$ capable of characterizing various computational complexity classes
and based on function algebras $A$, studied by Clote and others.
",1,0,0,0,0,0
20918,Land Cover Classification via Multi-temporal Spatial Data by Recurrent Neural Networks,"  Nowadays, modern earth observation programs produce huge volumes of satellite
images time series (SITS) that can be useful to monitor geographical areas
through time. How to efficiently analyze such kind of information is still an
open question in the remote sensing field. Recently, deep learning methods
proved suitable to deal with remote sensing data mainly for scene
classification (i.e. Convolutional Neural Networks - CNNs - on single images)
while only very few studies exist involving temporal deep learning approaches
(i.e Recurrent Neural Networks - RNNs) to deal with remote sensing time series.
In this letter we evaluate the ability of Recurrent Neural Networks, in
particular the Long-Short Term Memory (LSTM) model, to perform land cover
classification considering multi-temporal spatial data derived from a time
series of satellite images. We carried out experiments on two different
datasets considering both pixel-based and object-based classification. The
obtained results show that Recurrent Neural Networks are competitive compared
to state-of-the-art classifiers, and may outperform classical approaches in
presence of low represented and/or highly mixed classes. We also show that
using the alternative feature representation generated by LSTM can improve the
performances of standard classifiers.
",1,0,0,0,0,0
20919,Disentangling by Factorising,"  We define and address the problem of unsupervised learning of disentangled
representations on data generated from independent factors of variation. We
propose FactorVAE, a method that disentangles by encouraging the distribution
of representations to be factorial and hence independent across the dimensions.
We show that it improves upon $\beta$-VAE by providing a better trade-off
between disentanglement and reconstruction quality. Moreover, we highlight the
problems of a commonly used disentanglement metric and introduce a new metric
that does not suffer from them.
",0,0,0,1,0,0
20920,Symmetries and synchronization in multilayer random networks,"  In the light of the recently proposed scenario of asymmetry-induced
synchronization (AISync), in which dynamical uniformity and consensus in a
distributed system would demand certain asymmetries in the underlying network,
we investigate here the influence of some regularities in the interlayer
connection patterns on the synchronization properties of multilayer random
networks. More specifically, by considering a Stuart-Landau model of complex
oscillators with random frequencies, we report for multilayer networks a
dynamical behavior that could be also classified as a manifestation of AISync.
We show, namely, that the presence of certain symmetries in the interlayer
connection pattern tends to diminish the synchronization capability of the
whole network or, in other words, asymmetries in the interlayer connections
would enhance synchronization in such structured networks. Our results might
help the understanding not only of the AISync mechanism itself, but also its
possible role in the determination of the interlayer connection pattern of
multilayer and other structured networks with optimal synchronization
properties.
",0,1,0,0,0,0
20921,Application of Decision Rules for Handling Class Imbalance in Semantic Segmentation,"  As part of autonomous car driving systems, semantic segmentation is an
essential component to obtain a full understanding of the car's environment.
One difficulty, that occurs while training neural networks for this purpose, is
class imbalance of training data. Consequently, a neural network trained on
unbalanced data in combination with maximum a-posteriori classification may
easily ignore classes that are rare in terms of their frequency in the dataset.
However, these classes are often of highest interest. We approach such
potential misclassifications by weighting the posterior class probabilities
with the prior class probabilities which in our case are the inverse
frequencies of the corresponding classes in the training dataset. More
precisely, we adopt a localized method by computing the priors pixel-wise such
that the impact can be analyzed at pixel level as well. In our experiments, we
train one network from scratch using a proprietary dataset containing 20,000
annotated frames of video sequences recorded from street scenes. The evaluation
on our test set shows an increase of average recall with regard to instances of
pedestrians and info signs by $25\%$ and $23.4\%$, respectively. In addition,
we significantly reduce the non-detection rate for instances of the same
classes by $61\%$ and $38\%$.
",1,0,0,1,0,0
20922,Muchnik degrees and cardinal characteristics,"  We provide a pair of dual results, each stating the coincidence of highness
properties from computability theory. We provide an analogous pair of dual
results on the coincidence of cardinal characteristics within ZFC.
A mass problem is a set of functions on $\omega$. For mass problems $\mathcal
C, \mathcal D$, one says that $\mathcal C$ is Muchnik reducible to $\mathcal D$
if each function in $\mathcal D$ computes a function in $\mathcal C$. In this
paper we view highness properties as mass problems, and compare them with
respect to Muchnik reducibility and its uniform strengthening, Medvedev
reducibility.
Let $\mathcal D(p)$ be the mass problem of infinite bit sequences $y$ (i.e.,
0,1 valued functions) such that for each computable bit sequence $x$, the
asymptotic lower density $\underline \rho$ of the agreement bit sequence $x
\leftrightarrow y$ is at most $p$ (this sequence takes the value 1 at a bit
position iff $x$ and $y$ agree).
We show that all members of this family of mass problems parameterized by a
real $p$ with $0 < p<1/2 $ have the same complexity in the sense of Muchnik
reducibility. This also yields a new version of Monin's affirmative answer to
the ""Gamma question"", whether $\Gamma(A)< 1/2$ implies $\Gamma(A)=0$ for each
Turing oracle $A$.
We also show, together with Joseph Miller, that for any order function~$g$
there exists a faster growing order function $h $ such that $\mathrm{IOE}(g) $
is strictly Muchnik below $\mathrm{IOE}(h)$.
We study cardinal characteristics analogous to the highness properties above.
For instance, $\mathfrak d (p)$ is the least size of a set $G$ of bit sequences
so that for each bit sequence $x$ there is a bit sequence $y$ in $G$ so that
$\underline \rho (x \leftrightarrow y) >p$. We prove within ZFC all the
coincidences of cardinal characteristics that are the analogs of the results
above.
",0,0,1,0,0,0
20923,Existence of solutions for a semirelativistic Hartree equation with unbounded potentials,"  We prove the existence of a solution to the semirelativistic Hartree equation
$$\sqrt{-\Delta+m^2}u+ V(x) u = A(x)\left( W * |u|^p \right) |u|^{p-2}u $$
under suitable growth assumption on the potential functions $V$ and $A$. In
particular, both can be unbounded from above.
",0,0,1,0,0,0
20924,Lattice Operations on Terms over Similar Signatures,"  Unification and generalization are operations on two terms computing
respectively their greatest lower bound and least upper bound when the terms
are quasi-ordered by subsumption up to variable renaming (i.e., $t_1\preceq
t_2$ iff $t_1 = t_2\sigma$ for some variable substitution $\sigma$). When term
signatures are such that distinct functor symbols may be related with a fuzzy
equivalence (called a similarity), these operations can be formally extended to
tolerate mismatches on functor names and/or arity or argument order. We
reformulate and extend previous work with a declarative approach defining
unification and generalization as sets of axioms and rules forming a complete
constraint-normalization proof system. These include the Reynolds-Plotkin
term-generalization procedures, Maria Sessa's ""weak"" unification with partially
fuzzy signatures and its corresponding generalization, as well as novel
extensions of such operations to fully fuzzy signatures (i.e., similar functors
with possibly different arities). One advantage of this approach is that it
requires no modification of the conventional data structures for terms and
substitutions. This and the fact that these declarative specifications are
efficiently executable conditional Horn-clauses offers great practical
potential for fuzzy information-handling applications.
",1,0,0,0,0,0
20925,Towards Physically Safe Reinforcement Learning under Supervision,"  This paper addresses the question of how a previously available control
policy $\pi_s$ can be used as a supervisor to more quickly and safely train a
new learned control policy $\pi_L$ for a robot. A weighted average of the
supervisor and learned policies is used during trials, with a heavier weight
initially on the supervisor, in order to allow safe and useful physical trials
while the learned policy is still ineffective. During the process, the weight
is adjusted to favor the learned policy. As weights are adjusted, the learned
network must compensate so as to give safe and reasonable outputs under the
different weights. A pioneer network is introduced that pre-learns a policy
that performs similarly to the current learned policy under the planned next
step for new weights; this pioneer network then replaces the currently learned
network in the next set of trials. Experiments in OpenAI Gym demonstrate the
effectiveness of the proposed method.
",1,0,0,1,0,0
20926,Complex Valued Risk Diversification,"  Risk diversification is one of the dominant concerns for portfolio managers.
Various portfolio constructions have been proposed to minimize the risk of the
portfolio under some constrains including expected returns. We propose a
portfolio construction method that incorporates the complex valued principal
component analysis into the risk diversification portfolio construction. The
proposed method is verified to outperform the conventional risk parity and risk
diversification portfolio constructions.
",0,0,0,0,0,1
20927,An Overview on Application of Machine Learning Techniques in Optical Networks,"  Today's telecommunication networks have become sources of enormous amounts of
widely heterogeneous data. This information can be retrieved from network
traffic traces, network alarms, signal quality indicators, users' behavioral
data, etc. Advanced mathematical tools are required to extract meaningful
information from these data and take decisions pertaining to the proper
functioning of the networks from the network-generated data. Among these
mathematical tools, Machine Learning (ML) is regarded as one of the most
promising methodological approaches to perform network-data analysis and enable
automated network self-configuration and fault management. The adoption of ML
techniques in the field of optical communication networks is motivated by the
unprecedented growth of network complexity faced by optical networks in the
last few years. Such complexity increase is due to the introduction of a huge
number of adjustable and interdependent system parameters (e.g., routing
configurations, modulation format, symbol rate, coding schemes, etc.) that are
enabled by the usage of coherent transmission/reception technologies, advanced
digital signal processing and compensation of nonlinear effects in optical
fiber propagation. In this paper we provide an overview of the application of
ML to optical communications and networking. We classify and survey relevant
literature dealing with the topic, and we also provide an introductory tutorial
on ML for researchers and practitioners interested in this field. Although a
good number of research papers have recently appeared, the application of ML to
optical networks is still in its infancy: to stimulate further work in this
area, we conclude the paper proposing new possible research directions.
",0,0,0,1,0,0
20928,Study of Minor Actinides Transmutation in PWR MOX fuel,"  The management of long-lived radionuclides in spent fuel is a key issue to
achieve the closed nuclear fuel cycle and the sustainable development of
nuclear energy. Partitioning-Transmutation is supposed to be an efficient
method to treat the long-lived radionuclides in spent fuel. Some Minor
Actinides (MAs) have very long half-lives among the radionuclides in the spent
fuel. Accordingly, the study of MAs transmutation is a significant work for the
post-processing of spent fuel.
In the present work, the transmutations in Pressurized Water Reactor (PWR)
mixed oxide (MOX) fuel are investigated through the Monte Carlo based code RMC.
Two kinds of MAs, $^{237}$Np and five MAs ($^{237}$Np, $^{241}$Am, $^{243}$Am,
$^{244}$Cm and $^{245}$Cm) are incorporated homogeneously into the MOX fuel
assembly. The transmutation of MAs is simulated with different initial MOX
concentrations.
The results indicate an overall nice efficiency of transmutation in both
initial MOX concentrations, especially for the two kinds of MAs primarily
generated in the UOX fuel, $^{237}$Np and $^{241}$Am. In addition, the
inclusion of $^{237}$Np in MOX has no large influence for other MAs, while the
transmutation efficiency of $^{237}$Np is excellent. The transmutation of MAs
in MOX fuel depletion is expected to be a new, efficient nuclear spent fuel
management method for the future nuclear power generation.
",0,1,0,0,0,0
20929,Undesired parking spaces and contractible pieces of the noncrossing partition link,"  There are two natural simplicial complexes associated to the noncrossing
partition lattice: the order complex of the full lattice and the order complex
of the lattice with its bounding elements removed. The latter is a complex that
we call the noncrossing partition link because it is the link of an edge in the
former. The first author and his coauthors conjectured that various collections
of simplices of the noncrossing partition link (determined by the undesired
parking spaces in the corresponding parking functions) form contractible
subcomplexes. In this article we prove their conjecture by combining the fact
that the star of a simplex in a flag complex is contractible with the second
author's theory of noncrossing hypertrees.
",0,0,1,0,0,0
20930,Breaking the Nonsmooth Barrier: A Scalable Parallel Method for Composite Optimization,"  Due to their simplicity and excellent performance, parallel asynchronous
variants of stochastic gradient descent have become popular methods to solve a
wide range of large-scale optimization problems on multi-core architectures.
Yet, despite their practical success, support for nonsmooth objectives is still
lacking, making them unsuitable for many problems of interest in machine
learning, such as the Lasso, group Lasso or empirical risk minimization with
convex constraints.
In this work, we propose and analyze ProxASAGA, a fully asynchronous sparse
method inspired by SAGA, a variance reduced incremental gradient algorithm. The
proposed method is easy to implement and significantly outperforms the state of
the art on several nonsmooth, large-scale problems. We prove that our method
achieves a theoretical linear speedup with respect to the sequential version
under assumptions on the sparsity of gradients and block-separability of the
proximal term. Empirical benchmarks on a multi-core architecture illustrate
practical speedups of up to 12x on a 20-core machine.
",1,0,1,1,0,0
20931,Sparsity-promoting and edge-preserving maximum a posteriori estimators in non-parametric Bayesian inverse problems,"  We consider the inverse problem of recovering an unknown functional parameter
$u$ in a separable Banach space, from a noisy observation $y$ of its image
through a known possibly non-linear ill-posed map ${\mathcal G}$. The data $y$
is finite-dimensional and the noise is Gaussian. We adopt a Bayesian approach
to the problem and consider Besov space priors (see Lassas et al. 2009), which
are well-known for their edge-preserving and sparsity-promoting properties and
have recently attracted wide attention especially in the medical imaging
community.
Our key result is to show that in this non-parametric setup the maximum a
posteriori (MAP) estimates are characterized by the minimizers of a generalized
Onsager--Machlup functional of the posterior. This is done independently for
the so-called weak and strong MAP estimates, which as we show coincide in our
context. In addition, we prove a form of weak consistency for the MAP
estimators in the infinitely informative data limit. Our results are remarkable
for two reasons: first, the prior distribution is non-Gaussian and does not
meet the smoothness conditions required in previous research on non-parametric
MAP estimates. Second, the result analytically justifies existing uses of the
MAP estimate in finite but high dimensional discretizations of Bayesian inverse
problems with the considered Besov priors.
",0,0,1,1,0,0
20932,Non-LTE line formation of Fe in late-type stars IV: Modelling of the solar centre-to-limb variation in 3D,"  Our ability to model the shapes and strengths of iron lines in the solar
spectrum is a critical test of the accuracy of the solar iron abundance, which
sets the absolute zero-point of all stellar metallicities. We use an extensive
463-level Fe atom with new photoionisation cross-sections for FeI as well as
quantum mechanical calculations of collisional excitation and charge transfer
with neutral hydrogen; the latter effectively remove a free parameter that has
hampered all previous line formation studies of Fe in non-local thermodynamic
equilibrium (NLTE). For the first time, we use realistic 3D NLTE calculations
of Fe for a quantitative comparison to solar observations. We confront our
theoretical line profiles with observations taken at different viewing angles
across the solar disk with the Swedish 1-m Solar Telescope. We find that 3D
modelling well reproduces the observed centre-to-limb behaviour of spectral
lines overall, but highlight aspects that may require further work, especially
cross-sections for inelastic collisions with electrons. Our inferred solar iron
abundance is log(eps(Fe))=7.48+-0.04.
",0,1,0,0,0,0
20933,"Transmission clusters in the HIV-1 epidemic among men who have sex with men in Montreal, Quebec, Canada","  Background. Several studies have used phylogenetics to investigate Human
Immunodeficiency Virus (HIV) transmission among Men who have Sex with Men
(MSMs) in Montreal, Quebec, Canada, revealing many transmission clusters. The
Quebec HIV genotyping program sequence database now includes viral sequences
from close to 4,000 HIV-positive individuals classified as MSMs. In this paper,
we investigate clustering in those data by comparing results from several
methods: the conventional Bayesian and maximum likelihood-bootstrap methods,
and two more recent algorithms, DM-PhyClus, a Bayesian algorithm that produces
a measure of uncertainty for proposed partitions, and the Gap Procedure, a fast
distance-based approach. We estimate cluster growth by focusing on recent cases
in the Primary HIV Infection (PHI) stage. Results. The analyses reveal
considerable overlap between cluster estimates obtained from conventional
methods. The Gap Procedure and DM-PhyClus rely on different cluster definitions
and as a result, suggest moderately different partitions. All estimates lead to
similar conclusions about cluster expansion: several large clusters have
experienced sizeable growth, and a few new transmission clusters are likely
emerging. Conclusions. The lack of a gold standard measure for clustering
quality makes picking a best estimate among those proposed difficult. Work
aiming to refine clustering criteria would be required to improve estimates.
Nevertheless, the results unanimously stress the role that clusters play in
promoting HIV incidence among MSMs.
",0,0,0,1,0,0
20934,Conformal blocks attached to twisted groups,"  The aim of this paper is to generalize the notion of conformal blocks to the
situation in which the Lie algebra they are attached to is not defined over a
field, but depends on covering data of curves. The result will be a sheaf of
conformal blocks on the Hurwitz stack parametrizing Galois coverings of curves.
Many features of the classical sheaves of conformal blocks are proved to hold
in this more general setting, in particular the fusion rules, the propagation
of vacua and the WZW connection.
",0,0,1,0,0,0
20935,Statistical study on propagation characteristics of Omega signals (VLF) in magnetosphere detected by the Akebono satellite,"  This paper shows a statistical analysis of 10.2 kHz Omega broadcasts of an
artificial signal broadcast from ground stations, propagated in the
plasmasphere, and detected using an automatic detection method we developed. We
study the propagation patterns of the Omega signals to understand the
propagation characteristics that are strongly affected by plasmaspheric
electron density and the ambient magnetic field. We show the unique propagation
patterns of the Omega 10.2 kHz signal when it was broadcast from two
high-middle-latitude stations. We use about eight years of data captured by the
Poynting flux analyzer subsystem on board the Akebono satellite from October
1989 to September 1997. We demonstrate that the signals broadcast from almost
the same latitude (in geomagnetic coordinates) propagated differently depending
on the geographic latitude. We also study propagation characteristics as a
function of local time, season, and solar activity. The Omega signal tended to
propagate farther on the nightside than on the dayside and was more widely
distributed during winter than during summer. When solar activity was at
maximum, the Omega signal propagated at a lower intensity level. In contrast,
when solar activity was at minimum, the Omega signal propagated at a higher
intensity and farther from the transmitter station.
",0,1,0,0,0,0
20936,"Thermally induced stresses in boulders on airless body surfaces, and implications for rock breakdown","  This work investigates the macroscopic thermomechanical behavior of lunar
boulders by modeling their response to diurnal thermal forcing. Our results
reveal a bimodal, spatiotemporally-complex stress response. During sunrise,
stresses occur in the boulders' interiors that are associated with large-scale
temperature gradients developed due to overnight cooling. During sunset,
stresses occur at the boulders' exteriors due to the cooling and contraction of
the surface. Both kinds of stresses are on the order of 10 MPa in 1 m boulders
and decrease for smaller diameters, suggesting that larger boulders break down
more quickly. Boulders <30 cm exhibit a weak response to thermal forcing,
suggesting a threshold below which crack propagation may not occur. Boulders of
any size buried by regolith are shielded from thermal breakdown. As boulders
increase in size (>1 m), stresses increase to several 10s of MPa as the
behavior of their surfaces approaches that of an infinite halfspace. As the
thermal wave loses contact with the boulder interior, stresses become limited
to the near-surface. This suggests that the survival time of a boulder is not
only controlled by the amplitude of induced stress, but also by its diameter as
compared to the diurnal skin depth. While stresses on the order of 10 MPa are
enough to drive crack propagation in terrestrial environments, crack
propagation rates in vacuum are not well constrained. We explore the
relationship between boulder size, stress, and the direction of crack
propagation, and discuss the implications for the relative breakdown rates and
estimated lifetimes of boulders on airless body surfaces.
",0,1,0,0,0,0
20937,Some observations about generalized quantifiers in logics of imperfect information,"  We analyze the definitions of generalized quantifiers of imperfect
information that have been proposed by F.Engström. We argue that these
definitions are just embeddings of the first-order generalized quantifiers into
team semantics, and fail to capture an adequate notion of team-theoretical
generalized quantifier, save for the special cases in which the quantifiers are
applied to flat formulas. We also criticize the meaningfulness of the
monotone/nonmonotone distinction in this context. We make some proposals for a
more adequate definition of generalized quantifiers of imperfect information.
",0,0,1,0,0,0
20938,Predicting Demographics of High-Resolution Geographies with Geotagged Tweets,"  In this paper, we consider the problem of predicting demographics of
geographic units given geotagged Tweets that are composed within these units.
Traditional survey methods that offer demographics estimates are usually
limited in terms of geographic resolution, geographic boundaries, and time
intervals. Thus, it would be highly useful to develop computational methods
that can complement traditional survey methods by offering demographics
estimates at finer geographic resolutions, with flexible geographic boundaries
(i.e. not confined to administrative boundaries), and at different time
intervals. While prior work has focused on predicting demographics and health
statistics at relatively coarse geographic resolutions such as the county-level
or state-level, we introduce an approach to predict demographics at finer
geographic resolutions such as the blockgroup-level. For the task of predicting
gender and race/ethnicity counts at the blockgroup-level, an approach adapted
from prior work to our problem achieves an average correlation of 0.389
(gender) and 0.569 (race) on a held-out test dataset. Our approach outperforms
this prior approach with an average correlation of 0.671 (gender) and 0.692
(race).
",1,0,0,1,0,0
20939,Text Compression for Sentiment Analysis via Evolutionary Algorithms,"  Can textual data be compressed intelligently without losing accuracy in
evaluating sentiment? In this study, we propose a novel evolutionary
compression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),
which makes use of Parts-of-Speech tags to compress text in a way that
sacrifices minimal classification accuracy when used in conjunction with
sentiment analysis algorithms. An analysis of PARSEC with eight commercial and
non-commercial sentiment analysis algorithms on twelve English sentiment data
sets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss
in sentiment classification accuracy for (20%, 50%, 75%) data compression with
PARSEC using LingPipe, the most accurate of the sentiment algorithms. Other
sentiment analysis algorithms are more severely affected by compression. We
conclude that significant compression of text data is possible for sentiment
analysis depending on the accuracy demands of the specific application and the
specific sentiment analysis algorithm used.
",1,0,0,1,0,0
20940,Training large margin host-pathogen protein-protein interaction predictors,"  Detection of protein-protein interactions (PPIs) plays a vital role in
molecular biology. Particularly, infections are caused by the interactions of
host and pathogen proteins. It is important to identify host-pathogen
interactions (HPIs) to discover new drugs to counter infectious diseases.
Conventional wet lab PPI prediction techniques have limitations in terms of
large scale application and budget. Hence, computational approaches are
developed to predict PPIs. This study aims to develop large margin machine
learning models to predict interspecies PPIs with a special interest in
host-pathogen protein interactions (HPIs). Especially, we focus on seeking
answers to three queries that arise while developing an HPI predictor. 1) How
should we select negative samples? 2) What should be the size of negative
samples as compared to the positive samples? 3) What type of margin violation
penalty should be used to train the predictor? We compare two available methods
for negative sampling. Moreover, we propose a new method of assigning weights
to each training example in weighted SVM depending on the distance of the
negative examples from the positive examples. We have also developed a web
server for our HPI predictor called HoPItor (Host Pathogen Interaction
predicTOR) that can predict interactions between human and viral proteins. This
webserver can be accessed at the URL:
this http URL.
",1,0,0,1,0,0
20941,A Useful Solution of the Coupon Collector's Problem,"  The Coupon Collector's Problem is one of the few mathematical problems that
make news headlines regularly. The reasons for this are on one hand the immense
popularity of soccer albums (called Paninimania) and on the other hand that no
solution is known that is able to take into account all effects such as
replacement (limited purchasing of missing stickers) or swapping. In previous
papers we have proven that the classical assumptions are not fulfilled in
practice. Therefore we define new assumptions that match reality. Based on
these assumptions we are able to derive formulae for the mean number of
stickers needed (and the associated standard deviation) that are able to take
into account all effects that occur in practical collecting. Thus collectors
can estimate the average cost of completion of an album and its standard
deviation just based on elementary calculations. From a practical point of view
we consider the Coupon Collector's problem as solved.
-----
Das Sammelbilderproblem ist eines der wenigen mathematischen Probleme, die
regelmä{\ss}ig in den Schlagzeilen der Nachrichten vorkommen. Dies liegt
einerseits an der gro{\ss}en Popularität von Fu{\ss}ball-Sammelbildern
(Paninimania genannt) und andererseits daran, dass es bisher keine Lösung
gibt, die alle relevanten Effekte wie Nachkaufen oder Tauschen
berücksichtigt. Wir haben bereits nachgewiesen, dass die klassischen Annahmen
nicht der Realität entsprechen. Deshalb stellen wir neue Annahmen auf, die
die Praxis besser abbilden. Darauf aufbauend können wir Formeln für die
mittlere Anzahl benötigter Bilder (sowie deren Standardabweichung) ableiten,
die alle in der Praxis relevanten Effekte berücksichtigen. Damit können
Sammler die mittleren Kosten eines Albums sowie deren Standardabweichung nur
mit Hilfe von elementaren Rechnungen bestimmen. Für praktische Zwecke ist das
Sammelbilderproblem damit gelöst.
",0,0,1,0,0,0
20942,Accretion driven turbulence in filaments I: Non-gravitational accretion,"  We study accretion driven turbulence for different inflow velocities in star
forming filaments using the code ramses. Filaments are rarely isolated objects
and their gravitational potential will lead to radially dominated accretion. In
the non-gravitational case, accretion by itself can already provoke
non-isotropic, radially dominated turbulent motions responsible for the complex
structure and non-thermal line widths observed in filaments. We find that there
is a direct linear relation between the absolute value of the total density
weighted velocity dispersion and the infall velocity. The turbulent velocity
dispersion in the filaments is independent of sound speed or any net flow along
the filament. We show that the density weighted velocity dispersion acts as an
additional pressure term supporting the filament in hydrostatic equilibrium.
Comparing to observations, we find that the projected non-thermal line width
variation is generally subsonic independent of inflow velocity.
",0,1,0,0,0,0
20943,Contextual Outlier Interpretation,"  Outlier detection plays an essential role in many data-driven applications to
identify isolated instances that are different from the majority. While many
statistical learning and data mining techniques have been used for developing
more effective outlier detection algorithms, the interpretation of detected
outliers does not receive much attention. Interpretation is becoming
increasingly important to help people trust and evaluate the developed models
through providing intrinsic reasons why the certain outliers are chosen. It is
difficult, if not impossible, to simply apply feature selection for explaining
outliers due to the distinct characteristics of various detection models,
complicated structures of data in certain applications, and imbalanced
distribution of outliers and normal instances. In addition, the role of
contrastive contexts where outliers locate, as well as the relation between
outliers and contexts, are usually overlooked in interpretation. To tackle the
issues above, in this paper, we propose a novel Contextual Outlier
INterpretation (COIN) method to explain the abnormality of existing outliers
spotted by detectors. The interpretability for an outlier is achieved from
three aspects: outlierness score, attributes that contribute to the
abnormality, and contextual description of its neighborhoods. Experimental
results on various types of datasets demonstrate the flexibility and
effectiveness of the proposed framework compared with existing interpretation
approaches.
",1,0,0,1,0,0
20944,Game Theory for Secure Critical Interdependent Gas-Power-Water Infrastructure,"  A city's critical infrastructure such as gas, water, and power systems, are
largely interdependent since they share energy, computing, and communication
resources. This, in turn, makes it challenging to endow them with fool-proof
security solutions. In this paper, a unified model for interdependent
gas-power-water infrastructure is presented and the security of this model is
studied using a novel game-theoretic framework. In particular, a zero-sum
noncooperative game is formulated between a malicious attacker who seeks to
simultaneously alter the states of the gas-power-water critical infrastructure
to increase the power generation cost and a defender who allocates
communication resources over its attack detection filters in local areas to
monitor the infrastructure. At the mixed strategy Nash equilibrium of this
game, numerical results show that the expected power generation cost deviation
is 35\% lower than the one resulting from an equal allocation of resources over
the local filters. The results also show that, at equilibrium, the
interdependence of the power system on the natural gas and water systems can
motivate the attacker to target the states of the water and natural gas systems
to change the operational states of the power grid. Conversely, the defender
allocates a portion of its resources to the water and natural gas states of the
interdependent system to protect the grid from state deviations.
",1,0,0,0,0,0
20945,Implicit Entity Linking in Tweets,"  Over the years, Twitter has become one of the largest communication platforms
providing key data to various applications such as brand monitoring, trend
detection, among others. Entity linking is one of the major tasks in natural
language understanding from tweets and it associates entity mentions in text to
corresponding entries in knowledge bases in order to provide unambiguous
interpretation and additional con- text. State-of-the-art techniques have
focused on linking explicitly mentioned entities in tweets with reasonable
success. However, we argue that in addition to explicit mentions i.e. The movie
Gravity was more ex- pensive than the mars orbiter mission entities (movie
Gravity) can also be mentioned implicitly i.e. This new space movie is crazy.
you must watch it!. This paper introduces the problem of implicit entity
linking in tweets. We propose an approach that models the entities by
exploiting their factual and contextual knowledge. We demonstrate how to use
these models to perform implicit entity linking on a ground truth dataset with
397 tweets from two domains, namely, Movie and Book. Specifically, we show: 1)
the importance of linking implicit entities and its value addition to the
standard entity linking task, and 2) the importance of exploiting contextual
knowledge associated with an entity for linking their implicit mentions. We
also make the ground truth dataset publicly available to foster the research in
this new research area.
",1,0,0,0,0,0
20946,Non-cocompact Group Actions and $π_1$-Semistability at Infinity,"  A finitely presented 1-ended group $G$ has {\it semistable fundamental group
at infinity} if $G$ acts geometrically on a simply connected and locally
compact ANR $Y$ having the property that any two proper rays in $Y$ are
properly homotopic. This property of $Y$ captures a notion of connectivity at
infinity stronger than ""1-ended"", and is in fact a feature of $G$, being
independent of choices. It is a fundamental property in the homotopical study
of finitely presented groups. While many important classes of groups have been
shown to have semistable fundamental group at infinity, the question of whether
every $G$ has this property has been a recognized open question for nearly
forty years. In this paper we attack the problem by considering a proper {\it
but non-cocompact} action of a group $J$ on such an $Y$. This $J$ would
typically be a subgroup of infinite index in the geometrically acting
over-group $G$; for example $J$ might be infinite cyclic or some other subgroup
whose semistability properties are known. We divide the semistability property
of $G$ into a $J$-part and a ""perpendicular to $J$"" part, and we analyze how
these two parts fit together. Among other things, this analysis leads to a
proof (in a companion paper) that a class of groups previously considered to be
likely counter examples do in fact have the semistability property.
",0,0,1,0,0,0
20947,Robust Distributed Control of DC Microgrids with Time-Varying Power Sharing,"  This paper addresses the problem of output voltage regulation for multiple
DC/DC converters connected to a microgrid, and prescribes a scheme for sharing
power among different sources. This architecture is structured in such a way
that it admits quantifiable analysis of the closed-loop performance of the
network of converters; the analysis simplifies to studying closed-loop
performance of an equivalent {\em single-converter} system. The proposed
architecture allows for the proportion in which the sources provide power to
vary with time; thus overcoming limitations of our previous designs.
Additionally, the proposed control framework is suitable to both centralized
and decentralized implementations, i.e., the same control architecture can be
employed for voltage regulation irrespective of the availability of common
load-current (or power) measurement, without the need to modify controller
parameters. The performance becomes quantifiably better with better
communication of the demanded load to all the controllers at all the converters
(in the centralized case); however guarantees viability when such communication
is absent. Case studies comprising of battery, PV and generic sources are
presented and demonstrate the enhanced performance of prescribed optimal
controllers for voltage regulation and power sharing.
",1,0,1,0,0,0
20948,Quantum Lower Bounds for Tripartite Versions of the Hidden Shift and the Set Equality Problems,"  In this paper, we study quantum query complexity of the following rather
natural tripartite generalisations (in the spirit of the 3-sum problem) of the
hidden shift and the set equality problems, which we call the 3-shift-sum and
the 3-matching-sum problems.
The 3-shift-sum problem is as follows: given a table of $3\times n$ elements,
is it possible to circularly shift its rows so that the sum of the elements in
each column becomes zero? It is promised that, if this is not the case, then no
3 elements in the table sum up to zero. The 3-matching-sum problem is defined
similarly, but it is allowed to arbitrarily permute elements within each row.
For these problems, we prove lower bounds of $\Omega(n^{1/3})$ and
$\Omega(\sqrt n)$, respectively. The second lower bound is tight.
The lower bounds are proven by a novel application of the dual learning graph
framework and by using representation-theoretic tools.
",1,0,0,0,0,0
20949,A Parallel Direct Cut Algorithm for High-Order Overset Methods with Application to a Spinning Golf Ball,"  Overset methods are commonly employed to enable the effective simulation of
problems involving complex geometries and moving objects such as rotorcraft.
This paper presents a novel overset domain connectivity algorithm based upon
the direct cut approach suitable for use with GPU-accelerated solvers on
high-order curved grids. In contrast to previous methods it is capable of
exploiting the highly data-parallel nature of modern accelerators. Further, the
approach is also substantially more efficient at handling the curved grids
which arise within the context of high-order methods. An implementation of this
new algorithm is presented and combined with a high-order fluid dynamics code.
The algorithm is validated against several benchmark problems, including flow
over a spinning golf ball at a Reynolds number of 150,000.
",0,1,0,0,0,0
20950,A data assimilation algorithm: the paradigm of the 3D Leray-alpha model of turbulence,"  In this paper we survey the various implementations of a new data
assimilation (downscaling) algorithm based on spatial coarse mesh measurements.
As a paradigm, we demonstrate the application of this algorithm to the 3D
Leray-$\alpha$ subgrid scale turbulence model. Most importantly, we use this
paradigm to show that it is not always necessary that one has to collect coarse
mesh measurements of all the state variables, that are involved in the
underlying evolutionary system, in order to recover the corresponding exact
reference solution. Specifically, we show that in the case of the 3D
Leray$-\alpha$ model of turbulence the solutions of the algorithm, constructed
using only coarse mesh observations of any two components of the
three-dimensional velocity field, and without any information of the third
component, converge, at an exponential rate in time, to the corresponding exact
reference solution of the 3D Leray$-\alpha$ model. This study serves as an
addendum to our recent work on abridged continuous data assimilation for the 2D
Navier-Stokes equations. Notably, similar results have also been recently
established for the 3D viscous Planetary Geostrophic circulation model in which
we show that coarse mesh measurements of the temperature alone are sufficient
for recovering, through our data assimilation algorithm, the full solution;
viz. the three components of velocity vector field and the temperature.
Consequently, this proves the Charney conjecture for the 3D Planetary
Geostrophic model; namely, that the history of the large spatial scales of
temperature is sufficient for determining all the other quantities (state
variables) of the model.
",0,1,1,0,0,0
20951,Playing a true Parrondo's game with a three state coin on a quantum walk,"  Playing a Parrondo's game with a qutrit is the subject of this paper. We show
that a true quantum Parrondo's game can be played with a 3 state coin(qutrit)
in a 1D quantum walk in contrast to the fact that playing a true Parrondo's
game with a 2 state coin(qubit) in 1D quantum walk fails in the asymptotic
limits.
",1,1,0,0,0,0
20952,Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data,"  We analyse multimodal time-series data corresponding to weight, sleep and
steps measurements. We focus on predicting whether a user will successfully
achieve his/her weight objective. For this, we design several deep long
short-term memory (LSTM) architectures, including a novel cross-modal LSTM
(X-LSTM), and demonstrate their superiority over baseline approaches. The
X-LSTM improves parameter efficiency by processing each modality separately and
allowing for information flow between them by way of recurrent
cross-connections. We present a general hyperparameter optimisation technique
for X-LSTMs, which allows us to significantly improve on the LSTM and a prior
state-of-the-art cross-modal approach, using a comparable number of parameters.
Finally, we visualise the model's predictions, revealing implications about
latent variables in this task.
",1,0,0,1,0,0
20953,Spatial Variational Auto-Encoding via Matrix-Variate Normal Distributions,"  The key idea of variational auto-encoders (VAEs) resembles that of
traditional auto-encoder models in which spatial information is supposed to be
explicitly encoded in the latent space. However, the latent variables in VAEs
are vectors, which can be interpreted as multiple feature maps of size 1x1.
Such representations can only convey spatial information implicitly when
coupled with powerful decoders. In this work, we propose spatial VAEs that use
feature maps of larger size as latent variables to explicitly capture spatial
information. This is achieved by allowing the latent variables to be sampled
from matrix-variate normal (MVN) distributions whose parameters are computed
from the encoder network. To increase dependencies among locations on latent
feature maps and reduce the number of parameters, we further propose spatial
VAEs via low-rank MVN distributions. Experimental results show that the
proposed spatial VAEs outperform original VAEs in capturing rich structural and
spatial information.
",1,0,0,1,0,0
20954,Optimal Ramp Schemes and Related Combinatorial Objects,"  In 1996, Jackson and Martin proved that a strong ideal ramp scheme is
equivalent to an orthogonal array. However, there was no good characterization
of ideal ramp schemes that are not strong. Here we show the equivalence of
ideal ramp schemes to a new variant of orthogonal arrays that we term augmented
orthogonal arrays. We give some constructions for these new kinds of arrays,
and, as a consequence, we also provide parameter situations where ideal ramp
schemes exist but strong ideal ramp schemes do not exist.
",1,0,0,0,0,0
20955,Do Neural Nets Learn Statistical Laws behind Natural Language?,"  The performance of deep learning in natural language processing has been
spectacular, but the reasons for this success remain unclear because of the
inherent complexity of deep learning. This paper provides empirical evidence of
its effectiveness and of a limitation of neural networks for language
engineering. Precisely, we demonstrate that a neural language model based on
long short-term memory (LSTM) effectively reproduces Zipf's law and Heaps' law,
two representative statistical properties underlying natural language. We
discuss the quality of reproducibility and the emergence of Zipf's law and
Heaps' law as training progresses. We also point out that the neural language
model has a limitation in reproducing long-range correlation, another
statistical property of natural language. This understanding could provide a
direction for improving the architectures of neural networks.
",1,0,0,0,0,0
20956,Super-speeds with Zero-RAM: Next Generation Large-Scale Optimization in Your Laptop!,"  This article presents the novel breakthrough general purpose algorithm for
large scale optimization problems. The novel algorithm is capable of achieving
breakthrough speeds for very large-scale optimization on general purpose
laptops and embedded systems. Application of the algorithm to the Griewank
function was possible in up to 1 billion decision variables in double precision
took only 64485 seconds (~18 hours) to solve, while consuming 7,630 MB (7.6 GB)
or RAM on a single threaded laptop CPU. It shows that the algorithm is
computationally and memory (space) linearly efficient, and can find the optimal
or near-optimal solution in a fraction of the time and memory that many
conventional algorithms require. It is envisaged that this will open up new
possibilities of real-time large-scale problems on personal laptops and
embedded systems.
",1,0,0,0,0,0
20957,Recoverable Energy of Dissipative Electromagnetic Systems,"  Ambiguities in the definition of stored energy within distributed or
radiating electromagnetic systems motivate the discussion of the well-defined
concept of recoverable energy. This concept is commonly overlooked by the
community and the purpose of this communication is to recall its existence and
to discuss its relationship to fractional bandwidth. Using a rational function
approximation of a system's input impedance, the recoverable energy of lumped
and radiating systems is calculated in closed form and is related to stored
energy and fractional bandwidth. Lumped circuits are also used to demonstrate
the relationship between recoverable energy and the energy stored within
equivalent circuits produced by the minimum phase-shift Darlington's synthesis
procedure.
",0,1,0,0,0,0
20958,Elliptic Hall algebra on $\mathbb{F}_1$,"  We construct Hall algebra of elliptic curve over $\mathbb{F}_1$ using the
theory of monoidal scheme due to Deitmar and the theory of Hall algebra for
monoidal representations due to Szczesny. The resulting algebra is shown to be
a specialization of elliptic Hall algebra studied by Burban and Schiffmann.
Thus our algebra is isomorphic to the skein algebra for torus by the recent
work of Morton and Samuelson.
",0,0,1,0,0,0
20959,Approximate Bayesian inference with queueing networks and coupled jump processes,"  Queueing networks are systems of theoretical interest that give rise to
complex families of stochastic processes, and find widespread use in the
performance evaluation of interconnected resources. Yet, despite their
importance within applications, and in comparison to their counterpart
stochastic models in genetics or mathematical biology, there exist few relevant
approaches for transient inference and uncertainty quantification tasks in
these systems. This is a consequence of strong computational impediments and
distinctive properties of the Markov jump processes induced by queueing
networks. In this paper, we offer a comprehensive overview of the inferential
challenge and its comparison to analogue tasks within related mathematical
domains. We then discuss a model augmentation over an approximating network
system, and present a flexible and scalable variational Bayesian framework,
which is targeted at general-form open and closed queueing systems, with varied
service disciplines and priorities. The inferential procedure is finally
validated in a couple of uncertainty quantification tasks for network service
rates.
",1,0,0,1,0,0
20960,Universal features of price formation in financial markets: perspectives from Deep Learning,"  Using a large-scale Deep Learning approach applied to a high-frequency
database containing billions of electronic market quotes and transactions for
US equities, we uncover nonparametric evidence for the existence of a universal
and stationary price formation mechanism relating the dynamics of supply and
demand for a stock, as revealed through the order book, to subsequent
variations in its market price. We assess the model by testing its
out-of-sample predictions for the direction of price moves given the history of
price and order flow, across a wide range of stocks and time periods. The
universal price formation model is shown to exhibit a remarkably stable
out-of-sample prediction accuracy across time, for a wide range of stocks from
different sectors. Interestingly, these results also hold for stocks which are
not part of the training sample, showing that the relations captured by the
model are universal and not asset-specific.
The universal model --- trained on data from all stocks --- outperforms, in
terms of out-of-sample prediction accuracy, asset-specific linear and nonlinear
models trained on time series of any given stock, showing that the universal
nature of price formation weighs in favour of pooling together financial data
from various stocks, rather than designing asset- or sector-specific models as
commonly done. Standard data normalizations based on volatility, price level or
average spread, or partitioning the training data into sectors or categories
such as large/small tick stocks, do not improve training results. On the other
hand, inclusion of price and order flow history over many past observations is
shown to improve forecasting performance, showing evidence of path-dependence
in price dynamics.
",0,0,0,1,0,1
20961,A New Tracking Algorithm for Multiple Colloidal Particles Close to Contact,"  In this paper, we propose a new algorithm based on radial symmetry center
method to track colloidal particles close to contact, where the optical images
of the particles start to overlap in digital video microscopy. This overlapping
effect is important to observe the pair interaction potential in colloidal
studies and it appears as additional interaction in the measurement of the
interaction with conventional tracking analysis. The proposed algorithm in this
work is simple, fast and applicable for not only two particles but also three
and more particles without any modification. The algorithm uses gradient
vectors of the particle intensity distribution, which allows us to use a part
of the symmetric intensity distribution in the calculation of the actual
particle position. In this study, simulations are performed to see the
performance of the proposed algorithm for two and three particles, where the
simulation images are generated by using fitted curve to experimental particle
image for different sized particles. As a result, the algorithm yields the
maximum error smaller than 2 nm for 5.53 {\mu}m silica particles in contact
condition.
",0,1,0,0,0,0
20962,Critical Percolation Without Fine Tuning on the Surface of a Topological Superconductor,"  We present numerical evidence that most two-dimensional surface states of a
bulk topological superconductor (TSC) sit at an integer quantum Hall plateau
transition. We study TSC surface states in class CI with quenched disorder.
Low-energy (finite-energy) surface states were expected to be critically
delocalized (Anderson localized). We confirm the low-energy picture, but find
instead that finite-energy states are also delocalized, with universal
statistics that are independent of the TSC winding number, and consistent with
the spin quantum Hall plateau transition (percolation).
",0,1,0,0,0,0
20963,Low-luminosity stellar wind accretion onto neutron stars in HMXBs,"  Features and applications of quasi-spherical settling accretion onto rotating
magnetized neutron stars in high-mass X-ray binaries are discussed. The
settling accretion occurs in wind-fed HMXBs when the plasma cooling time is
longer than the free-fall time from the gravitational capture radius, which can
take place in low-luminosity HMXBs with $L_x\lesssim 4\times 10^{36}$ erg/s. We
briefly review the implications of the settling accretion, focusing on the SFXT
phenomenon, which can be related to instability of the quasi-spherical
convective shell above the neutron star magnetosphere due to magnetic
reconnection from fast temporarily magnetized winds from OB-supergiant. If a
young neutron star in a wind-fed HMXB is rapidly rotating, the propeller regime
in a quasi-spherical hot shell occurs. We show that X-ray spectral and temporal
properties of enigmatic $\gamma$ Cas Be-stars are consistent with failed
settling accretion regime onto a propelling neutron star. The subsequent
evolutionary stage of $\gamma$ Cas and its analogs should be the X Per-type
binaries comprising low-luminosity slowly rotating X-ray pulsars.
",0,1,0,0,0,0
20964,Faithful Inversion of Generative Models for Effective Amortized Inference,"  Inference amortization methods share information across multiple
posterior-inference problems, allowing each to be carried out more efficiently.
Generally, they require the inversion of the dependency structure in the
generative model, as the modeller must learn a mapping from observations to
distributions approximating the posterior. Previous approaches have involved
inverting the dependency structure in a heuristic way that fails to capture
these dependencies correctly, thereby limiting the achievable accuracy of the
resulting approximations. We introduce an algorithm for faithfully, and
minimally, inverting the graphical model structure of any generative model.
Such inverses have two crucial properties: (a) they do not encode any
independence assertions that are absent from the model and; (b) they are local
maxima for the number of true independencies encoded. We prove the correctness
of our approach and empirically show that the resulting minimally faithful
inverses lead to better inference amortization than existing heuristic
approaches.
",1,0,0,1,0,0
20965,A social Network Analysis of the Operations Research/Industrial Engineering Faculty Hiring Network,"  We study the U.S. Operations Research/Industrial-Systems Engineering (ORIE)
faculty hiring network, consisting of 1,179 faculty origin and destination data
together with attribute data from 83 ORIE departments. A social network
analysis of faculty hires can reveal important patterns in an academic field,
such as the existence of a hierarchy or sociological aspects such as the
presence of communities of departments. We first statistically test for the
existence of a linear hierarchy in the network and for its steepness. We find a
near linear hierarchical order of the departments, proposing a new index for
hiring networks, which we contrast with other indicators of hierarchy,
including published rankings. A single index is not capable to capture the full
structure of a complex network, however, so we next fit a latent exponential
random graph model (ERGM) to the network, which is able to reproduce its main
observed characteristics: high incidence of self-hiring, skewed out-degree
distribution, low density and clustering. Finally, we use the latent variables
in the ERGM to simplify the network to one where faculty hires take place among
three groups of departments. We contrast our findings with those reported for
other related disciplines, Computer Science and Business.
",1,0,0,1,0,0
20966,One-sample aggregate data meta-analysis of medians,"  An aggregate data meta-analysis is a statistical method that pools the
summary statistics of several selected studies to estimate the outcome of
interest. When considering a continuous outcome, typically each study must
report the same measure of the outcome variable and its spread (e.g., the
sample mean and its standard error). However, some studies may instead report
the median along with various measures of spread. Recently, the task of
incorporating medians in meta-analysis has been achieved by estimating the
sample mean and its standard error from each study that reports a median in
order to meta-analyze the means. In this paper, we propose two alternative
approaches to meta-analyze data that instead rely on medians. We systematically
compare these approaches via simulation study to each other and to methods that
transform the study-specific medians and spread into sample means and their
standard errors. We demonstrate that the proposed median-based approaches
perform better than the transformation-based approaches, especially when
applied to skewed data and data with high inter-study variance. In addition,
when meta-analyzing data that consists of medians, we show that the
median-based approaches perform considerably better than or comparably to the
best-case scenario for a transformation approach: conducting a meta-analysis
using the actual sample mean and standard error of the mean of each study.
Finally, we illustrate these approaches in a meta-analysis of patient delay in
tuberculosis diagnosis.
",0,0,0,1,0,0
20967,QuickCast: Fast and Efficient Inter-Datacenter Transfers using Forwarding Tree Cohorts,"  Large inter-datacenter transfers are crucial for cloud service efficiency and
are increasingly used by organizations that have dedicated wide area networks
between datacenters. A recent work uses multicast forwarding trees to reduce
the bandwidth needs and improve completion times of point-to-multipoint
transfers. Using a single forwarding tree per transfer, however, leads to poor
performance because the slowest receiver dictates the completion time for all
receivers. Using multiple forwarding trees per transfer alleviates this
concern--the average receiver could finish early; however, if done naively,
bandwidth usage would also increase and it is apriori unclear how best to
partition receivers, how to construct the multiple trees and how to determine
the rate and schedule of flows on these trees. This paper presents QuickCast, a
first solution to these problems. Using simulations on real-world network
topologies, we see that QuickCast can speed up the average receiver's
completion time by as much as $10\times$ while only using $1.04\times$ more
bandwidth; further, the completion time for all receivers also improves by as
much as $1.6\times$ faster at high loads.
",1,0,0,0,0,0
20968,Contemporary machine learning: a guide for practitioners in the physical sciences,"  Machine learning is finding increasingly broad application in the physical
sciences. This most often involves building a model relationship between a
dependent, measurable output and an associated set of controllable, but
complicated, independent inputs. We present a tutorial on current techniques in
machine learning -- a jumping-off point for interested researchers to advance
their work. We focus on deep neural networks with an emphasis on demystifying
deep learning. We begin with background ideas in machine learning and some
example applications from current research in plasma physics. We discuss
supervised learning techniques for modeling complicated functions, beginning
with familiar regression schemes, then advancing to more sophisticated deep
learning methods. We also address unsupervised learning and techniques for
reducing the dimensionality of input spaces. Along the way, we describe methods
for practitioners to help ensure that their models generalize from their
training data to as-yet-unseen test data. We describe classes of tasks --
predicting scalars, handling images, fitting time-series -- and prepare the
reader to choose an appropriate technique. We finally point out some
limitations to modern machine learning and speculate on some ways that
practitioners from the physical sciences may be particularly suited to help.
",1,1,0,0,0,0
20969,Uniform diamond coatings on WC-Co hard alloy cutting inserts deposited by a microwave plasma CVD,"  Polycrystalline diamond coatings have been grown on cemented carbide
substrates with different aspect ratios by a microwave plasma CVD in
methane-hydrogen gas mixtures. To protect the edges of the substrates from
non-uniform heating due to the plasma edge effect, a special plateholder with
pockets for group growth has been used. The difference in heights of the
substrates and plateholder, and its influence on the diamond film mean grain
size, growth rate, phase composition and stress was investigated. The substrate
temperature range, within which uniform diamond films are produced with good
adhesion, is determined. The diamond-coated cutting inserts produced at
optimized process exhibited a reduction of cutting force and wear resistance by
a factor of two, and cutting efficiency increase by 4.3 times upon turning A390
Al-Si alloy as compared to performance of uncoated tools.
",0,1,0,0,0,0
20970,Analysing Soccer Games with Clustering and Conceptors,"  We present a new approach for identifying situations and behaviours, which we
call ""moves"", from soccer games in the 2D simulation league. Being able to
identify key situations and behaviours are useful capabilities for analysing
soccer matches, anticipating opponent behaviours to aid selection of
appropriate tactics, and also as a prerequisite for automatic learning of
behaviours and policies. To support a wide set of strategies, our goal is to
identify situations from data, in an unsupervised way without making use of
pre-defined soccer specific concepts such as ""pass"" or ""dribble"". The recurrent
neural networks we use in our approach act as a high-dimensional projection of
the recent history of a situation on the field. Similar situations, i.e., with
similar histories, are found by clustering of network states. The same networks
are also used to learn so-called conceptors, that are lower-dimensional
manifolds that describe trajectories through a high-dimensional state space
that enable situation-specific predictions from the same neural network. With
the proposed approach, we can segment games into sequences of situations that
are learnt in an unsupervised way, and learn conceptors that are useful for the
prediction of the near future of the respective situation.
",1,0,0,0,0,0
20971,On the Efficient Simulation of the Left-Tail of the Sum of Correlated Log-normal Variates,"  The sum of Log-normal variates is encountered in many challenging
applications such as in performance analysis of wireless communication systems
and in financial engineering. Several approximation methods have been developed
in the literature, the accuracy of which is not ensured in the tail regions.
These regions are of primordial interest wherein small probability values have
to be evaluated with high precision. Variance reduction techniques are known to
yield accurate, yet efficient, estimates of small probability values. Most of
the existing approaches, however, have considered the problem of estimating the
right-tail of the sum of Log-normal random variables (RVS). In the present
work, we consider instead the estimation of the left-tail of the sum of
correlated Log-normal variates with Gaussian copula under a mild assumption on
the covariance matrix. We propose an estimator combining an existing
mean-shifting importance sampling approach with a control variate technique.
The main result is that the proposed estimator has an asymptotically vanishing
relative error which represents a major finding in the context of the left-tail
simulation of the sum of Log-normal RVs. Finally, we assess by various
simulation results the performances of the proposed estimator compared to
existing estimators.
",0,0,1,1,0,0
20972,Why optional stopping is a problem for Bayesians,"  Recently, optional stopping has been a subject of debate in the Bayesian
psychology community. Rouder (2014) argues that optional stopping is no problem
for Bayesians, and even recommends the use of optional stopping in practice, as
do Wagenmakers et al. (2012). This article addresses the question whether
optional stopping is problematic for Bayesian methods, and specifies under
which circumstances and in which sense it is and is not. By slightly varying
and extending Rouder's (2014) experiment, we illustrate that, as soon as the
parameters of interest are equipped with default or pragmatic priors - which
means, in most practical applications of Bayes Factor hypothesis testing -
resilience to optional stopping can break down. We distinguish between four
types of default priors, each having their own specific issues with optional
stopping, ranging from no-problem-at-all (Type 0 priors) to quite severe (Type
II and III priors).
",0,0,1,1,0,0